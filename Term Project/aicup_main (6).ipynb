{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "aicup_main",
      "provenance": [],
      "collapsed_sections": [
        "a6sIQ8wbXGnc",
        "cfh42ir6I9FM",
        "tpu1QT-5tYsi",
        "5rPf2heKjCd7"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c5cc60be20645c49327282cce722f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc3407cdbf2b4e13b8d9751c7d8a6999",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_817a36a3d86e4a2c9d1888f251877f3a",
              "IPY_MODEL_cb252ad43616482ab8aba6847392c7c4"
            ]
          }
        },
        "dc3407cdbf2b4e13b8d9751c7d8a6999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "817a36a3d86e4a2c9d1888f251877f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cbee36586a8d42e181d3004b4a203064",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_948fc68d85364c7da8cde632f1cbdc5a"
          }
        },
        "cb252ad43616482ab8aba6847392c7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0977a1d32e544c41b2b58b210179d453",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:00&lt;00:00, 2.76kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf2244ba44364aaab867fc1687fe311c"
          }
        },
        "cbee36586a8d42e181d3004b4a203064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "948fc68d85364c7da8cde632f1cbdc5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0977a1d32e544c41b2b58b210179d453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf2244ba44364aaab867fc1687fe311c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fd135e2c4eb43b79a2230d8ef657cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_149213a02a0c46d99a88714530bd9f82",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab59c31bcf7544a7a4a87dc41c8c8052",
              "IPY_MODEL_c946f5d1d9464ddfb1874855cc563ebf"
            ]
          }
        },
        "149213a02a0c46d99a88714530bd9f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab59c31bcf7544a7a4a87dc41c8c8052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ffc378b86824427ab5ea5e7c762e313",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411577189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411577189,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2329d13785234ad0b75b6be48b3d957b"
          }
        },
        "c946f5d1d9464ddfb1874855cc563ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efc1af31eed243e1affceb54ac9eaa68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412M/412M [00:05&lt;00:00, 76.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_572f44bb666c4630951163774da24b84"
          }
        },
        "4ffc378b86824427ab5ea5e7c762e313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2329d13785234ad0b75b6be48b3d957b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efc1af31eed243e1affceb54ac9eaa68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "572f44bb666c4630951163774da24b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk66K6AWaW1q"
      },
      "source": [
        "# !cp drive/MyDrive/python檔/aicup/run/dataset.py .\r\n",
        "# !cp drive/MyDrive/python檔/aicup/run "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GHLkq1bcEox",
        "outputId": "492ca250-6bef-4f27-f657-d41369ffdf9c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59rSMkbocYfI"
      },
      "source": [
        "import sys\r\n",
        "sys.path.insert(0,\"/content/drive/My Drive/python檔/aicup/run\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3D3ktlwcq1p",
        "outputId": "acba2462-9f5b-4901-856e-2d8aa3685982"
      },
      "source": [
        "pip install transformers==3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3) (20.7)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.1.94)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8.0rc4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6RsrpxBWe1H",
        "outputId": "d29f0827-45f3-4e94-94fc-03bd72fb3447"
      },
      "source": [
        "pip install pytorch-crf"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.6/dist-packages (0.7.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6eL0_ORc3lj",
        "outputId": "ee0daba8-40d5-44bb-fc89-7e052abdf30d"
      },
      "source": [
        "pip install pytorch_warmup"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_warmup in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_warmup) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNw4yCiwa1e2"
      },
      "source": [
        "# from dataset import bert_stc_dataset\r\n",
        "# from model2 import model_crf\r\n",
        "from train import train\r\n",
        "# from txt_preprocess2 import preprocess2\r\n",
        "import re\r\n",
        "\r\n",
        "from transformers import BertModel, BertTokenizer, get_cosine_schedule_with_warmup\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchsummary import summary\r\n",
        "from torchcrf import CRF\r\n",
        "import pytorch_warmup as warmup\r\n",
        "# from torch.autograd import Variable\r\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Qnou0tbJfb",
        "outputId": "6ba0960a-77d5-4a94-dbbe-5d9afc3a9733"
      },
      "source": [
        "file_path = '/content/drive/My Drive/python檔/aicup/run/data/train_input.data'\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "print('{} is being used'.format(device))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is being used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6sIQ8wbXGnc"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo2E2d2TU7dG"
      },
      "source": [
        "from torch.utils.data import Dataset\r\n",
        "import torch\r\n",
        "\r\n",
        "class bert_stc_dataset(Dataset):\r\n",
        "    \r\n",
        "    def __init__(self, stcs, labels, tokenizer, max_length):\r\n",
        "        \r\n",
        "        self.stcs = stcs\r\n",
        "        self.labels = labels\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        self.max_length = max_length\r\n",
        "        # self.pad_labels = []\r\n",
        "\r\n",
        "        #已經在preprocess2 做完label 0 padding\r\n",
        "        # for i in range(len(labels)):\r\n",
        "        #     temp_label = [0]*max_length\r\n",
        "        #     temp_label[:len(labels[i])] = labels[i]\r\n",
        "        #     self.pad_labels.append(temp_label)\r\n",
        "            \r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.stcs)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        \r\n",
        "        txt = str(self.stcs[idx])\r\n",
        "        \r\n",
        "        txt = ' '.join(list(txt))\r\n",
        "        # print(txt)\r\n",
        "        \r\n",
        "        encoding = self.tokenizer.encode_plus(\r\n",
        "            txt,\r\n",
        "#             truncation= True,\r\n",
        "            max_length= self.max_length,\r\n",
        "            padding = 'max_length',\r\n",
        "            add_special_tokens=False,\r\n",
        "#             pad_to_multiple_of=True,\r\n",
        "            return_attention_mask= True,\r\n",
        "            return_token_type_ids= False,\r\n",
        "            return_tensors='pt')\r\n",
        "        \r\n",
        "        return {\r\n",
        "            'input_ids': encoding['input_ids'].flatten(),\r\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\r\n",
        "            'labels' : torch.tensor(self.labels[idx], dtype= torch.long)\r\n",
        "        }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfh42ir6I9FM"
      },
      "source": [
        "# preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr4UxdsTI8Y-"
      },
      "source": [
        "class preprocess2():\r\n",
        "  def __init__(self, data):\r\n",
        "    self.data = data\r\n",
        "    self.article_id_list = list()\r\n",
        "    self.data_list= list()\r\n",
        "    data_list_tmp = list()\r\n",
        "    idx = 0\r\n",
        "\r\n",
        "    for row in data:\r\n",
        "      data_tuple = tuple()\r\n",
        "      if row == '\\n':\r\n",
        "        self.article_id_list.append(idx)\r\n",
        "        idx+=1\r\n",
        "        # data_list_tmp.append(('[SEP]','[SEP]'))\r\n",
        "        self.data_list.append(data_list_tmp)\r\n",
        "        # data_list_tmp = [('[CLS]','[CLS]')]\r\n",
        "        data_list_tmp = []\r\n",
        "\r\n",
        "      else:\r\n",
        "        row = row.strip('\\n').split(' ')\r\n",
        "\r\n",
        "        if row[0] in ['。', '？','！','～','：','，']:\r\n",
        "          self.article_id_list.append(idx)\r\n",
        "          self.data_list.append(data_list_tmp)\r\n",
        "          data_list_tmp= []\r\n",
        "        \r\n",
        "        elif row[0] in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']:\r\n",
        "          data_tuple = (row[0].lower(), row[1])\r\n",
        "          data_list_tmp.append(data_tuple)\r\n",
        "\r\n",
        "        elif row[0] not in ['摁','嗯','啦','喔','欸','啊','齁','嘿','…','...']:\r\n",
        "          data_tuple = (row[0], row[1])\r\n",
        "          data_list_tmp.append(data_tuple)\r\n",
        "        #data_list_tmp 儲存暫時的data_tuple(token,label)\r\n",
        "    if len(data_list_tmp) != 0:\r\n",
        "      self.data_list.append(data_list_tmp)\r\n",
        "\r\n",
        "    # print(len(self.data_list), len(self.article_id_list))\r\n",
        "    # print(self.data_list[0])\r\n",
        "    # traindata_list, testdata_list, traindata_article_id_list, testdata_article_id_list=train_test_split(self.data_list,self.article_id_list,test_size= 0.33)\r\n",
        "    # print('ex1 ',self.data_list[2])\r\n",
        "\r\n",
        "  def get_stc_label(self):\r\n",
        "    all_stcs = list()\r\n",
        "    all_labels = list()\r\n",
        "\r\n",
        "    for article_txt_tuple, article_id in zip(self.data_list, self.article_id_list):\r\n",
        "\r\n",
        "      txt_len = len(article_txt_tuple) #(文章數，每個文章對應的總字數) (word, label)\r\n",
        "      stc = str() #存字數= max_stc_len的字串\r\n",
        "      # labels = ['[CLS]'] # 存該字串對應的label # pytorch crf不需要\r\n",
        "      labels = []\r\n",
        "\r\n",
        "      for idx, (word, label) in enumerate(article_txt_tuple):\r\n",
        "\r\n",
        "        stc += word\r\n",
        "        labels.append(label)\r\n",
        "\r\n",
        "      # labels.append('[SEP]') # pytorch crf 不需要sep\r\n",
        "      \r\n",
        "      all_stcs.append(stc)\r\n",
        "      all_labels.append(labels)\r\n",
        "\r\n",
        "    all_stcs_clean = []\r\n",
        "    all_labels_clean = []\r\n",
        "\r\n",
        "    idx = 0\r\n",
        "    for stc, label in zip(all_stcs,all_labels): #前處理 & downsampling\r\n",
        "      \r\n",
        "      stc_clean = re.sub(r'(醫師)|(個管師)|(民眾)|(家屬)|(護理師)', '', stc)\r\n",
        "      # print(stc, stc_clean, label)\r\n",
        "      if (len(stc_clean)>=2) & (len(set(label)) >= 2):  \r\n",
        "        # print(stc_clean, stc)\r\n",
        "        all_stcs_clean.append(stc)\r\n",
        "        all_labels_clean.append(label)\r\n",
        "    \r\n",
        "      elif (len(stc_clean)>=2) & (((idx+1) % 5) == 0):\r\n",
        "        all_stcs_clean.append(stc)\r\n",
        "        all_labels_clean.append(label)\r\n",
        "      idx += 1\r\n",
        "\r\n",
        "    # 這一步就先把label 做 0 padding\r\n",
        "\r\n",
        "    max_length = len(max(all_stcs_clean, key=len)) \r\n",
        "    pad_labels = []\r\n",
        "\r\n",
        "    for i in range(len(all_labels_clean)):\r\n",
        "      temp_label = ['[PAD]']*max_length\r\n",
        "      temp_label[:len(all_labels_clean[i])] = all_labels_clean[i]\r\n",
        "      pad_labels.append(temp_label)\r\n",
        "\r\n",
        "    print('sentences總數: {}'.format(len(all_stcs_clean)))\r\n",
        "    print('labels總數: {}'.format(len(all_labels_clean)))\r\n",
        "    return all_stcs_clean, pad_labels\r\n",
        "\r\n",
        "  def tag2id(self, stcs_label):\r\n",
        "\r\n",
        "    all_label = list()\r\n",
        "    for stc_label in stcs_label:\r\n",
        "      for label in stc_label:\r\n",
        "        all_label.append(label)\r\n",
        "\r\n",
        "    labels_set = sorted(set(all_label))\r\n",
        "    tag2id_dict = {'[PAD]':0} #固定將PAD id設為0\r\n",
        "\r\n",
        "    labels_set.remove('[PAD]')\r\n",
        "\r\n",
        "    for idx, label in enumerate(labels_set):\r\n",
        "      tag2id_dict[label] = idx+1\r\n",
        "\r\n",
        "    # tag2id_dict['[CLS]'] = len(tag2id_dict) \r\n",
        "    # tag2id_dict['[SEP]'] = len(tag2id_dict)\r\n",
        "\r\n",
        "    return tag2id_dict\r\n",
        "\r\n",
        "  def label_to_ids(self, tag_to_id, raw_labels):\r\n",
        "\r\n",
        "    label2id = []\r\n",
        "    for stc_labels in raw_labels:\r\n",
        "      stc_label_ids = [tag_to_id[label] for label in stc_labels]\r\n",
        "      label2id.append(stc_label_ids)\r\n",
        "    return label2id\r\n",
        "\r\n",
        "  def get_stcs_label2ids(self):\r\n",
        "\r\n",
        "    stcs, labels = self.get_stc_label()\r\n",
        "    tag2id = self.tag2id(stcs_label= labels)\r\n",
        "    labels_ids= self.label_to_ids(tag_to_id= tag2id, raw_labels= labels)\r\n",
        "\r\n",
        "    return stcs, labels_ids"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpu1QT-5tYsi"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48kSvtOFtQRg"
      },
      "source": [
        "class model_crf(nn.Module):\r\n",
        "\tdef __init__(self, n_tags, hidden_dim=768, batchsize= 32):\r\n",
        "\t\tsuper(model_crf, self).__init__()\r\n",
        "\t\tself.n_tags = n_tags\r\n",
        "\t\tself.lstm =  nn.LSTM(bidirectional=True, num_layers=2, input_size=768, hidden_size=hidden_dim//2, dropout= 0.3, batch_first=True)\t\t\r\n",
        "\t\tself.hidden_dim = hidden_dim\r\n",
        "\t\tself.fc = nn.Linear(hidden_dim, self.n_tags)\r\n",
        "\t\tself.bert = BertModel.from_pretrained('bert-base-chinese')\r\n",
        "\t\t# self.bert.eval()  # 知用来取bert embedding\r\n",
        "\t\tself.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "\t\tself.CRF = CRF(n_tags, batch_first= True)\r\n",
        "\t\tself.hidden = self.init_hidden(batchsize)\r\n",
        "\r\n",
        "\tdef init_hidden(self, batch_size):\r\n",
        "\t\treturn (torch.randn(2*2, batch_size, self.hidden_dim // 2).to(self.device),\r\n",
        "\t\t\t\ttorch.randn(2*2, batch_size, self.hidden_dim // 2).to(self.device))\r\n",
        "\r\n",
        "\tdef forward(self, input_ids, attention_mask, tags):\r\n",
        "\r\n",
        "\t\tbatch_size = input_ids.size(0)\r\n",
        "\t\tmax_seq_len = input_ids.size(1)\r\n",
        "\t\tbert_output, _  = self.bert(input_ids.long(), attention_mask)\r\n",
        "\t\t\r\n",
        "\t\tseq_len = torch.sum(attention_mask, dim= 1).cpu().int()\r\n",
        "\t\t# print(seq_len)\r\n",
        "\t\tpack_input = pack_padded_sequence(input= bert_output, lengths= seq_len, batch_first= True, enforce_sorted= False)\r\n",
        "\t\tpacked_lstm_out, _ = self.lstm(pack_input,self.init_hidden(batch_size= batch_size))\r\n",
        "\t\tlstm_enc, _=  pad_packed_sequence(packed_lstm_out, batch_first=True, padding_value=0)\r\n",
        "\t\t# print(lstm_enc.size())\r\n",
        "\t\tlstm_feats = self.fc(lstm_enc)\r\n",
        "\r\n",
        "\t\tlstm_max_seq_len = lstm_feats.size(1)\r\n",
        "\t\tpad = torch.zeros(size=(batch_size, max_seq_len-lstm_max_seq_len, self.n_tags), dtype= torch.float).to(self.device)\r\n",
        "\t\tlstm_feats= torch.cat((lstm_feats, pad), dim= 1)\r\n",
        "  \r\n",
        "\t\tlstm_feats[:,:,1:-1] = lstm_feats[:,:,1:-1]*10\r\n",
        "\t\tloss = -self.CRF(lstm_feats, tags, attention_mask.bool(), reduction= 'token_mean')\r\n",
        "\t\tpred_seqs = self.CRF.decode(emissions= lstm_feats, mask= attention_mask.bool())\r\n",
        "  \r\n",
        "\t\treturn loss, pred_seqs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F72vtVN9tbhD"
      },
      "source": [
        "# 參數設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5c5cc60be20645c49327282cce722f3c",
            "dc3407cdbf2b4e13b8d9751c7d8a6999",
            "817a36a3d86e4a2c9d1888f251877f3a",
            "cb252ad43616482ab8aba6847392c7c4",
            "cbee36586a8d42e181d3004b4a203064",
            "948fc68d85364c7da8cde632f1cbdc5a",
            "0977a1d32e544c41b2b58b210179d453",
            "bf2244ba44364aaab867fc1687fe311c",
            "1fd135e2c4eb43b79a2230d8ef657cc4",
            "149213a02a0c46d99a88714530bd9f82",
            "ab59c31bcf7544a7a4a87dc41c8c8052",
            "c946f5d1d9464ddfb1874855cc563ebf",
            "4ffc378b86824427ab5ea5e7c762e313",
            "2329d13785234ad0b75b6be48b3d957b",
            "efc1af31eed243e1affceb54ac9eaa68",
            "572f44bb666c4630951163774da24b84"
          ]
        },
        "id": "zTvRlmOldMGf",
        "outputId": "f88790f2-adfe-4ed9-ef12-c40d4b358acc"
      },
      "source": [
        "# ---------------前處理---------------\r\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\r\n",
        "\tdata=f.readlines()#.encode('utf-8').decode('utf-8-sig')\r\n",
        "\r\n",
        "preprocessor = preprocess2(data)\r\n",
        "\r\n",
        "stcs, original_labels= preprocessor.get_stc_label()\r\n",
        "stcs, labels = preprocessor.get_stcs_label2ids()\r\n",
        "tag2id_dict = preprocessor.tag2id(original_labels)\r\n",
        "n_tags = len(tag2id_dict)\r\n",
        "print(tag2id_dict)\r\n",
        "print('tags數: {}'.format(n_tags))\r\n",
        "\r\n",
        "gt_tags = [tag for label in labels for tag in label]\r\n",
        "\r\n",
        "for tag in set(gt_tags):\r\n",
        "  print('{}|{}'.format(tag, gt_tags.count(tag)/len(gt_tags)))\r\n",
        "# plt.hist(gt_tags)\r\n",
        "plt.hist([len(stc) for stc in stcs])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\r\n",
        "# max_length = max([len(txt) for txt in stcs]) # [CLS] + [SEP]\r\n",
        "max_length = len(max(stcs, key=len)) \r\n",
        "print('max_stc_length', max_length)\r\n",
        "\r\n",
        "# ---------------模型---------------\r\n",
        "batchsize= 32\r\n",
        "model = model_crf(n_tags= n_tags, hidden_dim= 256, batchsize= batchsize).to(device)\r\n",
        "# print(summary(model,[(128, 300), (128,300)]))\r\n",
        "\r\n",
        "train_x, test_x, train_y, test_y = train_test_split(stcs, labels, test_size= 0.2, shuffle= True, random_state= 42)\r\n",
        "\r\n",
        "train_dataset = bert_stc_dataset(stcs= train_x, labels= train_y, tokenizer= tokenizer, max_length= max_length)\r\n",
        "print(train_x[0])\r\n",
        "print(train_dataset[0]['input_ids'])\r\n",
        "print(train_dataset[0]['labels'])\r\n",
        "test_dataset = bert_stc_dataset(stcs= test_x, labels= test_y, tokenizer= tokenizer, max_length= max_length)\r\n",
        "\r\n",
        "print('training stcs 總數: {}'.format(len(train_dataset)))\r\n",
        "train_dataloader = DataLoader(train_dataset, batch_size= batchsize, shuffle= True, num_workers= 4)\r\n",
        "test_dataloader = DataLoader(test_dataset, batch_size= batchsize, shuffle= False, num_workers= 4)\r\n",
        "\r\n",
        "num_epochs = 40\r\n",
        "num_iteration = len(train_dataloader)\r\n",
        "print('num_iteration',num_iteration)\r\n",
        "total_iter = num_iteration * num_epochs\r\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4, weight_decay= 0.001)\r\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=1000, num_training_steps=total_iter)\r\n",
        "# warmup_scheduler = warmup.ExponentialWarmup(optimizer, warmup_period=150)\r\n",
        "\r\n",
        "# ---------------訓練---------------\r\n",
        "# train_model = train(model= model, optimizer= optimizer, train_loader= train_dataloader, test_loader= 0, num_epochs= 5, device= device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentences總數: 6069\n",
            "labels總數: 6069\n",
            "sentences總數: 6069\n",
            "labels總數: 6069\n",
            "{'[PAD]': 0, 'B-ID': 1, 'B-clinical_event': 2, 'B-contact': 3, 'B-education': 4, 'B-family': 5, 'B-location': 6, 'B-med_exam': 7, 'B-money': 8, 'B-name': 9, 'B-organization': 10, 'B-profession': 11, 'B-time': 12, 'I-ID': 13, 'I-clinical_event': 14, 'I-contact': 15, 'I-education': 16, 'I-family': 17, 'I-location': 18, 'I-med_exam': 19, 'I-money': 20, 'I-name': 21, 'I-organization': 22, 'I-profession': 23, 'I-time': 24, 'O': 25}\n",
            "tags數: 26\n",
            "0|0.7983996011677672\n",
            "1|3.379934175781927e-05\n",
            "2|2.112458859863704e-05\n",
            "3|8.027343667482076e-05\n",
            "4|1.2674753159182225e-05\n",
            "5|0.0001056229429931852\n",
            "6|0.0006802117528761127\n",
            "7|0.0009252569806203025\n",
            "8|0.00032954358213873783\n",
            "9|0.0006886615883155675\n",
            "10|4.224917719727409e-06\n",
            "11|5.4923930356456306e-05\n",
            "12|0.006024732668331284\n",
            "13|6.337376579591112e-05\n",
            "14|6.337376579591112e-05\n",
            "15|0.00033376849985846524\n",
            "16|1.2674753159182225e-05\n",
            "17|0.00011829769615236744\n",
            "18|0.0010139802527345779\n",
            "19|0.0016308182398147796\n",
            "20|0.0008196340376271172\n",
            "21|0.001149177619765855\n",
            "22|8.449835439454817e-06\n",
            "23|0.00016899670878909632\n",
            "24|0.013278916393103244\n",
            "25|0.17397788678065496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "max_stc_length 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c5cc60be20645c49327282cce722f3c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fd135e2c4eb43b79a2230d8ef657cc4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411577189.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "還是天氣太熱\n",
            "tensor([6917, 3221, 1921, 3706, 1922, 4229,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0])\n",
            "tensor([25, 25, 25, 25, 25, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0])\n",
            "training stcs 總數: 4855\n",
            "num_iteration 152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPf2heKjCd7"
      },
      "source": [
        "# test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfjiko8GjBZD"
      },
      "source": [
        "def test(model, test_dataloader, device):\r\n",
        "\r\n",
        "  preds_epoch = []\r\n",
        "  gts_epoch = []\r\n",
        "  epoch_loss = 0\r\n",
        "  iteration = 0\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  for idx, batch_dict in enumerate(test_dataloader):\r\n",
        "\r\n",
        "    # print('idx: ',idx+1)\r\n",
        "    input_ids = batch_dict['input_ids'].to(device)\r\n",
        "    attention_mask = batch_dict['attention_mask'].to(device)\r\n",
        "    labels = batch_dict['labels'].to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      loss, pred_labels = model(input_ids, attention_mask.bool(), labels)\r\n",
        "\r\n",
        "    # mask gt labels \r\n",
        "    labels = batch_dict['labels'].numpy()\r\n",
        "    masks = batch_dict['attention_mask'].numpy()\r\n",
        "\r\n",
        "    labels_nopad = []\r\n",
        "    for label , seq_mask in zip(labels, masks):\r\n",
        "\r\n",
        "      seq = [tag for tag, mask in zip(label, seq_mask) if mask == 1]\r\n",
        "      labels_nopad.append(seq)\r\n",
        "\r\n",
        "    # one dim array \r\n",
        "    preds= [tag for seq in pred_labels for tag in seq]\r\n",
        "    gts= [tag for seq in labels_nopad for tag in seq]\r\n",
        "\r\n",
        "    preds_epoch += preds\r\n",
        "    gts_epoch += gts\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    iteration += 1\r\n",
        "\r\n",
        "  f1_macro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'macro')\r\n",
        "  f1_micro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'micro')\r\n",
        "  avg_loss = epoch_loss / iteration\r\n",
        "  \r\n",
        "  print('test_f1(macro, micro) ({:.2f},{:.2f}) | test_avg_loss {:.2f}'.format(f1_macro, f1_micro, avg_loss))\r\n",
        "\r\n",
        "  return f1_macro, f1_micro, avg_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTZoeeJLtl9K"
      },
      "source": [
        "# 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyZYZVdJhxFa"
      },
      "source": [
        "train_loss = {}\r\n",
        "test_loss = {}\r\n",
        "train_f1 = {}\r\n",
        "test_f1 = {}\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "\r\n",
        "  preds_epoch = []\r\n",
        "  gts_epoch = []\r\n",
        "  epoch_loss = 0\r\n",
        "  iteration = 0\r\n",
        "\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  for idx, batch_dict in enumerate(train_dataloader):\r\n",
        "\r\n",
        "    # print('idx: ',idx+1)\r\n",
        "    input_ids = batch_dict['input_ids'].to(device)\r\n",
        "    attention_mask = batch_dict['attention_mask'].to(device)\r\n",
        "    labels = batch_dict['labels'].to(device)\r\n",
        "\r\n",
        "    loss, pred_labels = model(input_ids, attention_mask.bool(), labels)\r\n",
        "\r\n",
        "    # loss = model.neg_log_likelihood(input_ids, attention_mask, labels)\r\n",
        "    loss.backward()\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\r\n",
        "\r\n",
        "    # if (idx+1) % 5 == 0:\r\n",
        "    optimizer.step()\r\n",
        "    scheduler.step()\r\n",
        "    # warmup_scheduler.dampen()\r\n",
        "    model.zero_grad()\r\n",
        "\r\n",
        "    # mask gt labels \r\n",
        "    labels = batch_dict['labels'].numpy()\r\n",
        "    masks = batch_dict['attention_mask'].numpy()\r\n",
        "    # masked_list = (labels*mask).numpy()\r\n",
        "\r\n",
        "    labels_nopad = []\r\n",
        "    for label , seq_mask in zip(labels, masks):\r\n",
        "\r\n",
        "      seq = [tag for tag, mask in zip(label, seq_mask) if mask == 1]\r\n",
        "      labels_nopad.append(seq)\r\n",
        "\r\n",
        "    # one dim array \r\n",
        "    preds= [tag for seq in pred_labels for tag in seq]\r\n",
        "    gts= [tag for seq in labels_nopad for tag in seq]\r\n",
        "\r\n",
        "    preds_epoch += preds\r\n",
        "    gts_epoch += gts\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    iteration += 1\r\n",
        "\r\n",
        "    # print('pred_labels', pred_labels)\r\n",
        "    # # print('preds:', preds)\r\n",
        "    # print('gts:',gts)\r\n",
        "    # print(round(f1_score(y_true= gts, y_pred= preds, average= 'macro'),2))\r\n",
        "    # # print(f1_score(y_true= gts, y_pred= preds, average= 'micro'))\r\n",
        "    # print(round(loss.item(),2))\r\n",
        "\r\n",
        "    # print('idx:{} loss:{}'.format(idx, loss))\r\n",
        "\r\n",
        "  f1 = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'macro')\r\n",
        "  f1_micro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'micro')\r\n",
        "  avg_loss = epoch_loss / iteration\r\n",
        "  \r\n",
        "\r\n",
        "  print('epoch {}/{} | train_f1(macro, micro) ({:.2f},{:.2f}) | train_epoch_avg_loss {:.2f}'.format(epoch+1, num_epochs, f1, f1_micro, avg_loss))\r\n",
        "\r\n",
        "  test_f1_macro, test_f1_micro, test_avg_loss = test(model= model, test_dataloader= test_dataloader, device= device)\r\n",
        "\r\n",
        "  train_loss[epoch+1] = avg_loss\r\n",
        "  test_loss[epoch+1] = test_avg_loss\r\n",
        "  train_f1[epoch+1] = f1\r\n",
        "  test_f1[epoch+1] = test_f1_macro\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pWa4TQhw5PI"
      },
      "source": [
        "# torch.save(model, 'ner_model_batch32_wup3000_lstmhd256_lre-4_40epoch.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAFcxDva2iGf"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows= 2, ncols= 1, figsize= (10,8), sharex= True)\r\n",
        "ax1.plot([*range(1, num_epochs+1)], list(train_loss.values()), label= 'train loss')\r\n",
        "ax1.plot([*range(1, num_epochs+1)], list(test_loss.values()), label= 'test loss')\r\n",
        "ax1.legend()\r\n",
        "\r\n",
        "ax2.plot([*range(1, num_epochs+1)], list(train_f1.values()), label= 'train f1 (macro)')\r\n",
        "ax2.plot([*range(1, num_epochs+1)], list(test_f1.values()), label= 'test f1 (macro)')\r\n",
        "ax2.legend()\r\n",
        "\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1UTlctlqT8g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Tutorial: Named Entity Recognition using a Bi-LSTM with the Conditional Random Field Algorithm\n",
    "\n",
    "Tutorial Link:  https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/PythonWorkshop/intro-to-nlp-with-pytorch/master/images/bilstm_flow.png\" width=\"80%\">\n",
    "\n",
    "The Bi-LSTM is trained on both past as well as future information from the given data as word embeddings or vectors representing the input words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "* Definitions\n",
    "\n",
    "    * Bi-LSTM\n",
    "    * CRF and potentials\n",
    "    * Viterbi\n",
    "\n",
    "* Helper Functions\n",
    "\n",
    "* Data\n",
    "\n",
    "* Create the Network\n",
    "\n",
    "* Train\n",
    "\n",
    "* Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Definitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bi-LSTM (Bidirectional-Long Short-Term Memory)\n",
    "\n",
    "As we saw, an LSTM addresses the vanishing gradient problem of the generic RNN by adding cell state and more non-linear activation function layers to pass on or attenuate signals to varying degrees.  However, the main limitation of an LSTM is that it can **only account for context from the past**, that is, the hidden state, h_t, takes only past information as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Named Entity Recognition Task\n",
    "\n",
    "For the task of **Named Entity Recognition (NER)** it is helpful to have context from past as well as the future, or left and right contexts.  This can be addressed with a Bi-LSTM which is two LSTMs, one processing information in a forward fashion as we have already seen and another LSTM that processes the sequences in a reverse fashion giving the future context.  _That second LSTM is just reading the sentence in reverse._  \n",
    "\n",
    "The hidden states from both LSTMs are then concatenated into a final output layer or vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional Random Field\n",
    "\n",
    "We don't have to stop at the output vector from the Bi-LSTM!  We're not at our tag for the entity, yet.  We need to understand costs of moving from one tag to the next (or staying put on a tag, even).\n",
    "\n",
    "In a CRF, we have the concept of a _transition matrix_ which is the costs associated with transitioning from one tag to another - a transition matrix is calculated/trained for each time step.  It is used in the determination of the best path through all potential sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Say **B** is the tag for the beginning of an entity, **I** signifies that we are inside an entity (will follow a **B**) and **O** means we are outside an entity. \n",
    "\n",
    "Next, is an example of B-I-O scheme labeling for finding nouns in a sentence (by the way, there are a myriad of other schemes out there - see [Referenes](#references) for some more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "| Word | Scheme Tag |\n",
    "| --- | --- |\n",
    "| She | B |\n",
    "| was | O |\n",
    "| born | O |\n",
    "| in | O |\n",
    "| North | B |\n",
    "| Carolina | I |\n",
    "| but | O |\n",
    "| grew | O |\n",
    "| up | O |\n",
    "| in | O |\n",
    "| Texas | B |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at the transition matrix for the costs of moving from one tag (using our B-I-O scheme) to the next (remember our Bi-LSTM is understanding both the forward and reverse ordering to get more accurate boundaries for the named entities)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/crf_transition_matrix.png\" width=\"60%\">\n",
    "\n",
    "The mathematical derivations for calculating this matrix and decoding it is beyond the scope of this notebook, however if you wish to learn more see [this](http://www.cs.columbia.edu/~mcollins/crf.pdf) article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Viterbi Algorithm\n",
    "\n",
    "If each Bi-LSTM instance (time step) has an associated output feature map and CRF transition and emission values, then each of these time step outputs will need to be decoded into a path through potential tags and a final score determined.  This is the purpose of the Viterbi algorithm, here, which is commonly used in conjunction with CRFs.\n",
    "\n",
    "Specifically, the Viterbi algorithm finds the optimal path through a sequence given a cost function by tracing backwards through a graph of all possible paths.  There are computational tricks to finding this path in the high dimensional space and we will see this in the code below (`_viterbi_decode`).\n",
    "\n",
    "Here, let's see a simple example of just the Viterbi algorithm.  The simplicity of Viterbi is that at each time step, it \"looks to the left\" to find that best path and then moves to the right, repeating this \"look to the left\" until a \"survivor path\" or optimal path is found with the last column being the possible tags.  The score may also be found by tracing backwards along this path and using the metric decided upon.\n",
    "\n",
    "In this example the optimal score (via a metric) is the lowest one, however, one could also look for the highest scoring path if another metric is used as is shown next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/PythonWorkshop/intro-to-nlp-with-pytorch/master/images/viterbi.png\" width=\"70%\">\n",
    "\n",
    "\n",
    "Getting more realistic...\n",
    "\n",
    "With regards to our NER work here, below is an example of a \"survivor\" path within the context of the linear-CRF where we are trying to find the highest scoring path through a sequence (giving us the tags and final score).  The transition matrix values are represented by the arrows and a sequence vector is shown as part of the overall cost function.\n",
    "\n",
    "<img src=\"../images/linear_crf_example.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Putting it All Together\n",
    "\n",
    "Here we have word embeddings as the data for the forward and reverse LSTMs.  The resulting forward vector (V_f) and backwards vector (V_b or Output layer, here) are concatenated into a final vector (V_o) that feeds into the CRF layer and is decoded via the Viterbi algorithm (part of CRF layer) into the optimal tag for that input.  Note, the initial values for the Hidden inputs for each LSTM (forward and reverse) are often a vector of random numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/PythonWorkshop/intro-to-nlp-with-pytorch/master/images/blstm_crf_details.png\" width=\"70%\">\n",
    "\n",
    "\n",
    "<div  align=\"right\"><a href=\"https://www.sciencedirect.com/science/article/pii/S1532046417300977\">Reference</a></div>\n",
    "\n",
    "> For a more in-depth discussion, see this excellent post describing the Bi-LSTM, CRF and usage of the Viterbi Algorithm (among other NER concepts and equations): [post](https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**:  What's wrong with the above diagram??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "{sys.executable}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure the PyTorch version here matches the `requirements.txt` file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Imports for this tutorial\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import jdc\n",
    "import json\n",
    "from collections import defaultdict, OrderedDict\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a CUDA capable GPU, let's use it!  Initialize an object `device` to use later on tensors and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE:  Fill in the missing \"blanks\" (`_____`) with the correct code in a new cell.\n",
    "\n",
    "```python\n",
    "def argmax(vec):\n",
    "    \"\"\"Return the argmax as a python int\"\"\"\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx._____()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        seq - the sequence (array)\n",
    "        to_ix - the indices to which seqence values are converted (dict)\n",
    "        \n",
    "    Output:\n",
    "        Numerical tensor\n",
    "        \"\"\"\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch._____(idxs, dtype=torch.long)\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    \"\"\"Compute log sum exp in a numerically stable way for \n",
    "    the forward algorithm\"\"\"\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score._____(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "The data for this notebook came from GitHub <a href=\"https://github.com/tensorflow/tensorflow/issues\" target=\"_blank\">issues for Tensorflow</a> and <a href=\"https://github.com/pytorch/pytorch/issues\" target=\"_blank\">issues for PyTorch</a>- sentences in which _inline_ code was found.\n",
    "\n",
    "**Problem statement**:  Predict in a corpus, what parts are Python code snippets - i.e. Python code is an entity we are trying to identify in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling data\n",
    "\n",
    "**Install notes (tested on Mac Mojave)**:\n",
    "\n",
    "* Install <a href=\"https://github.com/chakki-works/doccano#installation\" target=\"_blank\">doccano</a> into a Python environment (a <a href=\"https://docs.python.org/3.6/library/venv.html\" target=\"_blank\">virtual environment</a> for e.g.) (follow Option 2)\n",
    "  * Create the virtual environment (recommended) or use a conda environment/native (Python 3.6+)\n",
    "  * Make sure to _first_ install (before what's in `requirements.txt`:\n",
    "    * <a href=\"http://postgresapp.com\" target=\"blank\">Postgres app</a>\n",
    "    * `sudo pip install psycopg2` to install ps_config (needed by doccano install)\n",
    "  * Then proceed with rest of local install (Option 2)\n",
    "* Run the app according to the Usage instructions in the doccano Readme\n",
    "  * NOTE:  `python3` may have to be substituted for using `python` command for using a `venv`\n",
    "  * NOTE: there must not be any empty lines in import data\n",
    "  \n",
    "Labeled data in the `doccano` app will look similar to:\n",
    "\n",
    "![](../images/doccano_label.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `doccano` exported data to training data format\n",
    "\n",
    "`doccano` exports as `json` with one input datum plus labels per line where:\n",
    "* `id` is the datum or corpus numerical id\n",
    "* `text` is the issue snippet or corpus\n",
    "* `annotations` are the labels and indices of each word/element in the single corpus - the `start_offset` and `end_offset` are used to find the words in the sentence.  This will get the data in the correct for training.\n",
    "\n",
    "**Read the data file and print one line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read export file\n",
    "with open('doccano_export.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(json.loads(lines[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split out words and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numerical doccano label to actual label (B-I-O scheme)\n",
    "ix_to_label = {4: 'O', 3: 'I', 2: 'B'}\n",
    "    \n",
    "# train/test data\n",
    "data = []\n",
    "\n",
    "# Vocabulary\n",
    "vocab = set()\n",
    "    \n",
    "# Loop over each data point (a corpus of labeled text) to extract words\n",
    "for line in lines:\n",
    "    # An ordered dict will keep items in order for further manipulation\n",
    "    # so we initialize here\n",
    "    orddict = OrderedDict({})\n",
    "    # Lists to hold the words and labels\n",
    "    words = []\n",
    "    labels = []\n",
    "    # Convert line to json\n",
    "    injson = json.loads(line)\n",
    "    annots = injson['annotations']\n",
    "    text = injson['text']\n",
    "    \n",
    "    # Add each word annotation to OrderedDict\n",
    "    for ann in annots:\n",
    "        orddict[ann['start_offset']] = ann\n",
    "    \n",
    "    # Sort ordered dict because there's no guarantee reading json\n",
    "    # maintained order\n",
    "    orddict = sorted(orddict.items(), key=lambda x: x[1]['start_offset'])\n",
    "    \n",
    "    for item in orddict:\n",
    "        # the item is a tuple where second value is the actual value we want\n",
    "        ann = item[1]\n",
    "        # Subset text string\n",
    "        word = text[ann['start_offset']:(ann['end_offset'] + 1)].rstrip()\n",
    "        label = ix_to_label[ann['label']]\n",
    "        # Add to list for this datum/corpus\n",
    "        words.append(word)\n",
    "        labels.append(label)\n",
    "        vocab.add(word)\n",
    "    # Add to overall data containers\n",
    "    data.append((words, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = math.floor(len(data) * 0.8) # 80% to train\n",
    "training_data, test_data = data[:num_train], data[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tags and hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM = 4\n",
    "MINIBATCH_SIZE = 2\n",
    "LEARNING_WEIGHT = 5e-2\n",
    "WEIGHT_DECAY = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        \"\"\"Initialize network.\"\"\"\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to BiLSTM_CRF\n",
    "\n",
    "def init_hidden(self):\n",
    "    \"\"\"Two tensors to hold hidden states, one for each\n",
    "    LSTM direction with dimensions of (num_layers, \n",
    "    minibatch, hidden_dim)\"\"\"\n",
    "    # Minibatch small because small dataset below\n",
    "    return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
    "            torch.randn(2, 1, self.hidden_dim // 2).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to BiLSTM_CRF\n",
    "\n",
    "\n",
    "def _forward_alg(self, feats):\n",
    "    \"\"\"Core magic of the Conditional Random Field.  \n",
    "    \n",
    "    Input:\n",
    "        The word embeddeding vectors for a sentence\n",
    "    \n",
    "    Since we’re using PyTorch to compute gradients for us, \n",
    "    we technically only need the forward part of the forward-backward \n",
    "    algorithm \"\"\"\n",
    "    # Do the forward algorithm to compute the partition function\n",
    "    init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "    # START_TAG (\"<START>\") has all of the score.\n",
    "    init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "    forward_var = init_alphas\n",
    "\n",
    "    # Iterate through the sentence\n",
    "    for feat in feats:\n",
    "        alphas_t = []  # The forward tensors at this timestep\n",
    "        for next_tag in range(self.tagset_size):\n",
    "            # broadcast the emission score: it is the same regardless of\n",
    "            # the previous tag\n",
    "            emit_score = feat[next_tag].view(\n",
    "                1, -1).expand(1, self.tagset_size)\n",
    "            # the ith entry of trans_score is the score of transitioning to\n",
    "            # next_tag from i\n",
    "            trans_score = self.transitions[next_tag].view(1, -1)\n",
    "            # The ith entry of next_tag_var is the value for the\n",
    "            # edge (i -> next_tag) before we do log-sum-exp\n",
    "            next_tag_var = forward_var + trans_score + emit_score\n",
    "            # The forward variable for this tag is log-sum-exp of all the\n",
    "            # scores.\n",
    "            alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "        forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "    alpha = log_sum_exp(terminal_var)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to BiLSTM_CRF\n",
    "\n",
    "def _get_lstm_features(self, sentence):\n",
    "    \"\"\"Compute output vector of BiLSTM - used in \n",
    "    the forward pass of network\"\"\"\n",
    "    self.hidden = self.init_hidden()\n",
    "    embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "    lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "    lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "    # Map LSTM features into tag space\n",
    "    lstm_feats = self.hidden2tag(lstm_out)\n",
    "    return lstm_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to BiLSTM_CRF\n",
    "\n",
    "def _score_sentence(self, feats, tags):\n",
    "    \"\"\"Gives the score of a provided tag sequence\"\"\"\n",
    "    # Gives the score of a provided tag sequence\n",
    "    score = torch.zeros(1).to(device)\n",
    "    tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), \n",
    "                      tags])\n",
    "    for i, feat in enumerate(feats):\n",
    "        score = score + \\\n",
    "            self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "    score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to BiLSTM_CRF\n",
    "\n",
    "def _viterbi_decode(self, feats):\n",
    "    \"\"\"Implements Viterbi algorithm for finding most likely sequence of labels.\n",
    "    Used in the forward pass of the network.\n",
    "\n",
    "    We take the maximum over the previous states as opposed to the sum. \n",
    "    Input:\n",
    "        loglikelihoods: torch tensor.\n",
    "    Output:\n",
    "        tuple. The first entry is the loglikelihood of this sequence. The second is \n",
    "        the most likely sequence of labels. \n",
    "    \"\"\"\n",
    "    backpointers = []\n",
    "\n",
    "    # Initialize the viterbi variables in log space\n",
    "    init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
    "    init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "    # forward_var at step i holds the viterbi variables for step i-1\n",
    "    forward_var = init_vvars\n",
    "    for feat in feats:\n",
    "        bptrs_t = []  # holds the backpointers for this step\n",
    "        viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "        for next_tag in range(self.tagset_size):\n",
    "            # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "            # previous step, plus the score of transitioning\n",
    "            # from tag i to next_tag.\n",
    "            # We don't include the emission scores here because the max\n",
    "            # does not depend on them (we add them in below)\n",
    "            next_tag_var = forward_var + self.transitions[next_tag]\n",
    "            best_tag_id = argmax(next_tag_var)\n",
    "            bptrs_t.append(best_tag_id)\n",
    "            viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "        # Now add in the emission scores, and assign forward_var to the set\n",
    "        # of viterbi variables we just computed\n",
    "        forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1).to(device)\n",
    "        backpointers.append(bptrs_t)\n",
    "\n",
    "    # Transition to STOP_TAG\n",
    "    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "    best_tag_id = argmax(terminal_var)\n",
    "    path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "    # Follow the back pointers to decode the best path.\n",
    "    best_path = [best_tag_id]\n",
    "    for bptrs_t in reversed(backpointers):\n",
    "        best_tag_id = bptrs_t[best_tag_id]\n",
    "        best_path.append(best_tag_id)\n",
    "    # Pop off the start tag (we dont want to return that to the caller)\n",
    "    start = best_path.pop()\n",
    "    assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "    best_path.reverse()\n",
    "    return path_score, best_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function explains the calculation of the scoring..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to BiLSTM_CRF\n",
    "\n",
    "def neg_log_likelihood(self, sentence, tags):\n",
    "    \"\"\"Calculate the negative log likelihood given a sequence and labels.\n",
    "    This is used in training (only) because we don't need to create\n",
    "    and check the B-I-O tags themselves - only the score is important\n",
    "    here for calculating the loss.\"\"\"\n",
    "    feats = self._get_lstm_features(sentence)\n",
    "    forward_score = self._forward_alg(feats)\n",
    "    gold_score = self._score_sentence(feats, tags)\n",
    "    return forward_score - gold_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to BiLSTM_CRF\n",
    "\n",
    "def forward(self, sentence):\n",
    "    \"\"\"The forward pass function for training the network.\n",
    "    This is used in inference only.\"\"\"\n",
    "    # Get the emission scores (output layer) from the \n",
    "    # BiLSTM \n",
    "    lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "    # Find the best path, given the features.\n",
    "    score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "    return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    \"\"\"Remove punctuation from a piece of text\"\"\"\n",
    "    punct = list(\".,()-\")\n",
    "    for p in punct:\n",
    "        text = text.replace(p, '')\n",
    "    return text\n",
    "    \n",
    "text = remove_punct(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup dict for all possible words and record their index\n",
    "word_to_ix = {k: v for (k, v) in zip(vocab, range(len(vocab)))}\n",
    "tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "ix_to_tag = {0: \"B\", 1: \"I\", 2: \"O\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize model and optimizer for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_WEIGHT, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**:  Fill in the missing \"blanks\" (`_____`) with the correct code in a new cell.\n",
    "\n",
    "```python\n",
    "# Check predictions before training\n",
    "with torch._____():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    precheck_sent = precheck_sent.to(device)\n",
    "    pred =  model(precheck_sent)[1]\n",
    "    print('Prediction:   ', [ix_to_tag[idx] for idx in pred])\n",
    "    print('Ground truth: ', training_data[0][1])\n",
    "    print(training_data[0][0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model!\n",
    "\n",
    "IMPORTANT NOTE:  If at workshop, please keep the number of epochs at or below 100 to save on the shared GPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "# again, normally you would do more than 300 epochs, but we have\n",
    "# toy data\n",
    "\n",
    "losses = []\n",
    "for epoch in range(100):  \n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance of LSTM\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "        sentence_in, targets = sentence_in.to(device), targets.to(device)\n",
    "\n",
    "        # Step 3. A lot happens.  Run our forward pass to get features from BLSTM,\n",
    "        # run the CRF and get the negative log likelihoods and find the best \n",
    "        # \"path\" through sentence with the tags using the viterbi algorithm \n",
    "        # (also part of forward pass).\n",
    "        # BTW our dynamic computational graph is created with the forward pass\n",
    "        # Returns the forward score - ground truth score (our loss measure)\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "        # Step 4. Compute the loss, gradients (backprop), and update the \n",
    "        # parameters by calling optimizer.step() - optimizer here is \n",
    "        # SGD for our CRF\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(\"Epoch: {} Loss: {}\".format(epoch+1, np.mean(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model**\n",
    "\n",
    "Doc:  https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_0.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**:  Change the optimization algorithm and retrain.  E.g. try the Adam optimizer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check**\n",
    "\n",
    "You must call `model.eval()` to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Sanity check for predictions after training\n",
    "# No need to accumulate gradients because this is a validation\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[1][0], word_to_ix)\n",
    "    precheck_sent = precheck_sent.to(device)\n",
    "    pred =  model(precheck_sent)[1]\n",
    "    print('Prediction:   ', [ix_to_tag[idx] for idx in pred])\n",
    "    print('Ground truth: ', training_data[1][1])\n",
    "    print(training_data[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note**:  `with torch.no_grad()` is used so that gradients are not propagated which is important for when we are running predictions and scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluate\n",
    "\n",
    "Let's test our model on an unseen sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.eval() # set again just in case\n",
    "\n",
    "# Pick some test data\n",
    "test_datum = test_data[0][0]\n",
    "test_text = test_data[0][1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(test_datum, word_to_ix)\n",
    "    precheck_sent = precheck_sent.to(device)\n",
    "    pred =  model(precheck_sent)[1]\n",
    "    print('Prediction:   ', [ix_to_tag[idx] for idx in pred])\n",
    "    print('Ground truth: ', test_text)\n",
    "    print('Text: ', test_datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**:  Calculate the average accuracy for the prediction above on all test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**:   Select and print only the code snippets from above for the prediction as well as groud truth (actual labels) for a better picture of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the result wasn't very good, try more epochs to create a new trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "1. [Understanding Bidirectional RNN in PyTorch](https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66)\n",
    "2. [Conditional Random Field Tutorial in PyTorch](https://towardsdatascience.com/conditional-random-field-tutorial-in-pytorch-ca0d04499463)\n",
    "3. [Character-level neural network for biomedical named entity recognition](https://www.sciencedirect.com/science/article/pii/S1532046417300977)\n",
    "4.  [Other named entity tag schemes](https://lingpipe-blog.com/2009/10/14/coding-chunkers-as-taggers-io-bio-bmewo-and-bmewo/)\n",
    "5.  <a href=\"https://blog.algorithmia.com/introduction-to-optimizers/\" target=\"_blank\">Introduction to Optimizers</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**EXERCISE (Advanced)**:  collect copora (more GitHub issues?), label (with `doccano` or favorite tool) your own dataset and train and test (with code above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - PyTorch 1.1",
   "language": "python",
   "name": "pytorch_preview"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

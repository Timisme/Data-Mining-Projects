{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "aicup_main",
      "provenance": [],
      "collapsed_sections": [
        "LsnrmjRWrSmN",
        "-NSLpK9g7bp5"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d0bc1de2a6843c28a5b2676d6fee0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_017593c998e4464fb910d45f2329a692",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_727e02e6543d46ee86b5ae71b42dab72",
              "IPY_MODEL_885ae775bad84b9e8f1148f934dc1e49"
            ]
          }
        },
        "017593c998e4464fb910d45f2329a692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "727e02e6543d46ee86b5ae71b42dab72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c66c35d61794220a7e4ac06b861d780",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_382e477643334159b2d54faf38150cf4"
          }
        },
        "885ae775bad84b9e8f1148f934dc1e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4e8b31b3cb1415ab4a11c1706947c93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:00&lt;00:00, 376kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5499ca8e59d142cc8111fbfd9b3f37d1"
          }
        },
        "1c66c35d61794220a7e4ac06b861d780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "382e477643334159b2d54faf38150cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4e8b31b3cb1415ab4a11c1706947c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5499ca8e59d142cc8111fbfd9b3f37d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94846abe9eff42c18bad7f5e9ad4038f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_19d4db3c4c8a4b06a58136b0e3cf06d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1c86e2bbc594126a02fd0c726eaa95b",
              "IPY_MODEL_3d9135dd51f547bebee111c2b1971f77"
            ]
          }
        },
        "19d4db3c4c8a4b06a58136b0e3cf06d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1c86e2bbc594126a02fd0c726eaa95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60c24e5dd96848a993fa51f6eb68de05",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74a517912f5e4357b0191bfbb8bfdeba"
          }
        },
        "3d9135dd51f547bebee111c2b1971f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4d0ce05e747419f96ca64f8d87de0e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:00&lt;00:00, 3.04kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b041a469d11f4a079d3bad26dd91b4c8"
          }
        },
        "60c24e5dd96848a993fa51f6eb68de05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74a517912f5e4357b0191bfbb8bfdeba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4d0ce05e747419f96ca64f8d87de0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b041a469d11f4a079d3bad26dd91b4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "106875ae42374e82976ceb9563f244b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7f66b6a843d04c859a94502ee62a4c78",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3064fde93b9844bca5b26093ee01ae50",
              "IPY_MODEL_a0b1ba8c73304d58a34e9f37ba23c69f"
            ]
          }
        },
        "7f66b6a843d04c859a94502ee62a4c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3064fde93b9844bca5b26093ee01ae50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6768cc129aee4b5cabf69ac97453acf7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411577189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411577189,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0ab9c33d12b4323ba625336c5dd569a"
          }
        },
        "a0b1ba8c73304d58a34e9f37ba23c69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9eebc212e6349b98e84af7b6177a9ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412M/412M [00:10&lt;00:00, 38.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e2f595acb874f73bb0f09b17625f51a"
          }
        },
        "6768cc129aee4b5cabf69ac97453acf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0ab9c33d12b4323ba625336c5dd569a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9eebc212e6349b98e84af7b6177a9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e2f595acb874f73bb0f09b17625f51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk66K6AWaW1q"
      },
      "source": [
        "# !cp drive/MyDrive/python檔/aicup/run/dataset.py .\r\n",
        "# !cp drive/MyDrive/python檔/aicup/run "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsnrmjRWrSmN"
      },
      "source": [
        "# loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GHLkq1bcEox",
        "outputId": "a18e3b16-e9c7-4c28-e29f-64414ff5c604"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59rSMkbocYfI"
      },
      "source": [
        "import sys\r\n",
        "sys.path.insert(0,\"/content/drive/My Drive/python檔/aicup/run\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3D3ktlwcq1p",
        "outputId": "ce24ad3c-7fba-4fa1-a325-b0a0556f52a6"
      },
      "source": [
        "pip install transformers==3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 24.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3) (3.0.12)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3) (20.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=189babe9ff011bee1d6d23e60f6437adbbfe519e83fbb86c022e3465a3ce7e36\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6RsrpxBWe1H",
        "outputId": "7ba28dea-71e7-43af-b3ff-fb9e03a249b9"
      },
      "source": [
        "pip install pytorch-crf"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6eL0_ORc3lj",
        "outputId": "63fdce69-305f-4eee-8ac3-8e6da4a120b1"
      },
      "source": [
        "pip install pytorch_warmup"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_warmup\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/22/2fb600a06a1d1b493d54ac8fa6c41e96870985992fc504104e0620bc2ea4/pytorch_warmup-0.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_warmup) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (0.16.0)\n",
            "Installing collected packages: pytorch-warmup\n",
            "Successfully installed pytorch-warmup-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNw4yCiwa1e2"
      },
      "source": [
        "# from dataset import bert_stc_dataset\r\n",
        "# from model2 import model_crf\r\n",
        "from train import train\r\n",
        "# from txt_preprocess2 import preprocess2\r\n",
        "import re\r\n",
        "\r\n",
        "from transformers import BertModel, BertTokenizer, get_cosine_schedule_with_warmup\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchsummary import summary\r\n",
        "from torchcrf import CRF\r\n",
        "import pytorch_warmup as warmup\r\n",
        "# from torch.autograd import Variable\r\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Qnou0tbJfb",
        "outputId": "4a73cf95-f7f9-440c-fc12-5d1b7ae9b5e9"
      },
      "source": [
        "file_path = '/content/drive/My Drive/python檔/aicup/run/data/train_input.data'\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "print('{} is being used'.format(device))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is being used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6sIQ8wbXGnc"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo2E2d2TU7dG"
      },
      "source": [
        "from torch.utils.data import Dataset\r\n",
        "import torch\r\n",
        "\r\n",
        "class bert_stc_dataset(Dataset):\r\n",
        "    \r\n",
        "    def __init__(self, stcs, labels, tokenizer, max_length):\r\n",
        "        \r\n",
        "        self.stcs = stcs\r\n",
        "        self.labels = labels\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        self.max_length = max_length\r\n",
        "        self.pad_labels = []\r\n",
        "\r\n",
        "        # 已經在preprocess2 做完label 0 padding\r\n",
        "        for i in range(len(labels)):\r\n",
        "            temp_label = [0]*max_length\r\n",
        "            temp_label[:len(labels[i])] = labels[i]\r\n",
        "            self.pad_labels.append(temp_label)\r\n",
        "            \r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.stcs)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        \r\n",
        "        txt = str(self.stcs[idx])\r\n",
        "        \r\n",
        "        txt = ' '.join(list(txt))\r\n",
        "        # print(txt)\r\n",
        "        \r\n",
        "        encoding = self.tokenizer.encode_plus(\r\n",
        "            txt,\r\n",
        "#             truncation= True,\r\n",
        "            max_length= self.max_length,\r\n",
        "            padding = 'max_length',\r\n",
        "            add_special_tokens=False,\r\n",
        "#             pad_to_multiple_of=True,\r\n",
        "            return_attention_mask= True,\r\n",
        "            return_token_type_ids= False,\r\n",
        "            return_tensors='pt')\r\n",
        "        \r\n",
        "        return {\r\n",
        "            'input_ids': encoding['input_ids'].flatten(),\r\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\r\n",
        "            'labels' : torch.tensor(self.pad_labels[idx], dtype= torch.long)\r\n",
        "        }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfh42ir6I9FM"
      },
      "source": [
        "# preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr4UxdsTI8Y-"
      },
      "source": [
        "class preprocess2():\r\n",
        "  def __init__(self, data):\r\n",
        "    self.data = data\r\n",
        "    self.article_id_list = list()\r\n",
        "    self.data_list= list()\r\n",
        "    data_list_tmp = list()\r\n",
        "    idx = 0\r\n",
        "\r\n",
        "    for row in data:\r\n",
        "      data_tuple = tuple()\r\n",
        "      if row == '\\n':\r\n",
        "        self.article_id_list.append(idx)\r\n",
        "        idx+=1\r\n",
        "        self.data_list.append(data_list_tmp)\r\n",
        "        data_list_tmp = []\r\n",
        "\r\n",
        "      else:\r\n",
        "        row = row.strip('\\n').split(' ')\r\n",
        "\r\n",
        "        if (row[0] == '，') & (len(data_list_tmp) >= 96):\r\n",
        "          self.article_id_list.append(idx)\r\n",
        "          self.data_list.append(data_list_tmp)\r\n",
        "          data_list_tmp= []\r\n",
        "\r\n",
        "        elif row[0] in ['。', '？','！','～','：']:\r\n",
        "          self.article_id_list.append(idx)\r\n",
        "          self.data_list.append(data_list_tmp)\r\n",
        "          data_list_tmp= []\r\n",
        "        \r\n",
        "        elif row[0] in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']:\r\n",
        "          print(row[0])\r\n",
        "          data_tuple = (row[0].lower(), row[1])\r\n",
        "          data_list_tmp.append(data_tuple)\r\n",
        "\r\n",
        "        elif row[0] not in ['摁','嗯','啦','喔','欸','啊','齁','嘿','嘛','…','...','、','‧','，']:\r\n",
        "          data_tuple = (row[0], row[1])\r\n",
        "          data_list_tmp.append(data_tuple)\r\n",
        "        #data_list_tmp 儲存暫時的data_tuple(token,label)\r\n",
        "    if len(data_list_tmp) != 0:\r\n",
        "      self.data_list.append(data_list_tmp)\r\n",
        "\r\n",
        "  def get_stc_label(self):\r\n",
        "    all_stcs = list()\r\n",
        "    all_labels = list()\r\n",
        "\r\n",
        "    for article_txt_tuple, article_id in zip(self.data_list, self.article_id_list):\r\n",
        "\r\n",
        "      txt_len = len(article_txt_tuple) #(文章數，每個文章對應的總字數) (word, label)\r\n",
        "      stc = str() #存字數= max_stc_len的字串\r\n",
        "      # labels = ['[CLS]'] # 存該字串對應的label # pytorch crf不需要\r\n",
        "      labels = []\r\n",
        "\r\n",
        "      for idx, (word, label) in enumerate(article_txt_tuple):\r\n",
        "\r\n",
        "        stc += word\r\n",
        "        labels.append(label)\r\n",
        "\r\n",
        "      all_stcs.append(stc)\r\n",
        "      all_labels.append(labels)\r\n",
        "\r\n",
        "    all_stcs_clean = []\r\n",
        "    all_labels_clean = []\r\n",
        "\r\n",
        "    idx = 0\r\n",
        "    for stc, label in zip(all_stcs,all_labels): #前處理 & downsampling\r\n",
        "      \r\n",
        "      stc_clean = re.sub(r'(醫師)|(個管師)|(民眾)|(家屬)|(護理師)', '', stc)\r\n",
        "      # print(stc, stc_clean, label)\r\n",
        "      if (len(stc_clean)>=2) & (len(set(label)) >= 2):  \r\n",
        "        # print(stc_clean, stc)\r\n",
        "        all_stcs_clean.append(stc)\r\n",
        "        all_labels_clean.append(label)\r\n",
        "    \r\n",
        "      elif (len(stc_clean)>=2) & (((idx+1) % 2) == 0):\r\n",
        "        all_stcs_clean.append(stc)\r\n",
        "        all_labels_clean.append(label)\r\n",
        "      idx += 1\r\n",
        "\r\n",
        "    # 這一步就先把label 做 0 padding\r\n",
        "\r\n",
        "    # max_length = len(max(all_stcs_clean, key=len)) \r\n",
        "    # pad_labels = []\r\n",
        "\r\n",
        "    # for i in range(len(all_labels_clean)):\r\n",
        "    #   temp_label = [0]*max_length\r\n",
        "    #   temp_label[:len(all_labels_clean[i])] = all_labels_clean[i]\r\n",
        "    #   pad_labels.append(temp_label)\r\n",
        "\r\n",
        "    # print('sentences總數: {}'.format(len(all_stcs_clean)))\r\n",
        "    # print('labels總數: {}'.format(len(all_labels_clean)))\r\n",
        "    # return all_stcs_clean, pad_labels\r\n",
        "    return all_stcs_clean, all_labels_clean\r\n",
        "\r\n",
        "  def tag2id(self, stcs_label):\r\n",
        "\r\n",
        "    all_label = list()\r\n",
        "    for stc_label in stcs_label:\r\n",
        "      for label in stc_label:\r\n",
        "        all_label.append(label)\r\n",
        "\r\n",
        "    labels_set = sorted(set(all_label))\r\n",
        "    tag2id_dict = {}\r\n",
        "    # tag2id_dict = {'[PAD]':0} #固定將PAD id設為0\r\n",
        "\r\n",
        "    # labels_set.remove('[PAD]')\r\n",
        "\r\n",
        "    for idx, label in enumerate(labels_set):\r\n",
        "      tag2id_dict[label] = idx\r\n",
        "\r\n",
        "    return tag2id_dict\r\n",
        "\r\n",
        "  def label_to_ids(self, tag_to_id, raw_labels):\r\n",
        "\r\n",
        "    label2id = []\r\n",
        "    for stc_labels in raw_labels:\r\n",
        "      stc_label_ids = [tag_to_id[label] for label in stc_labels]\r\n",
        "      label2id.append(stc_label_ids)\r\n",
        "    return label2id\r\n",
        "\r\n",
        "  def get_stcs_label2ids(self):\r\n",
        "\r\n",
        "    stcs, labels = self.get_stc_label()\r\n",
        "    tag2id = self.tag2id(stcs_label= labels)\r\n",
        "    labels_ids= self.label_to_ids(tag_to_id= tag2id, raw_labels= labels)\r\n",
        "\r\n",
        "    return stcs, labels_ids"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpu1QT-5tYsi"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48kSvtOFtQRg"
      },
      "source": [
        "class model_crf(nn.Module):\r\n",
        "\tdef __init__(self, n_tags, hidden_dim=768, batchsize= 32):\r\n",
        "\t\tsuper(model_crf, self).__init__()\r\n",
        "\t\tself.n_tags = n_tags\r\n",
        "\t\tself.lstm =  nn.LSTM(bidirectional=True, num_layers=2, input_size=768, hidden_size=hidden_dim//2, dropout= 0.3, batch_first=True)\t\t\r\n",
        "\t\tself.hidden_dim = hidden_dim\r\n",
        "\t\tself.fc = nn.Linear(hidden_dim, self.n_tags)\r\n",
        "\t\tself.bert = BertModel.from_pretrained('bert-base-chinese')\r\n",
        "\r\n",
        "\t\t# for param in self.bert.parameters():\r\n",
        "\t\t# \tparam.requires_grad = False\r\n",
        "\t\t# self.bert.eval()  # 知用来取bert embedding\r\n",
        "\r\n",
        "\t\tself.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "\t\tself.CRF = CRF(n_tags, batch_first= True)\r\n",
        "\t\tself.hidden = self.init_hidden(batchsize)\r\n",
        "\r\n",
        "\tdef init_hidden(self, batch_size):\r\n",
        "\t\treturn (torch.randn(2*2, batch_size, self.hidden_dim // 2).to(self.device),\r\n",
        "\t\t\t\ttorch.randn(2*2, batch_size, self.hidden_dim // 2).to(self.device))\r\n",
        "\r\n",
        "\tdef forward(self, input_ids, attention_mask, tags):\r\n",
        "\r\n",
        "\t\tbatch_size = input_ids.size(0)\r\n",
        "\t\tmax_seq_len = input_ids.size(1)\r\n",
        "\t\tbert_output, _  = self.bert(input_ids.long(), attention_mask)\r\n",
        "\t\tprint(bert_output.size())\r\n",
        "\t\tprint(bert_output[-1].size())\r\n",
        "\t\tseq_len = torch.sum(attention_mask, dim= 1).cpu().int()\r\n",
        "\t\t# print(seq_len)\r\n",
        "\t\tpack_input = pack_padded_sequence(input= bert_output, lengths= seq_len, batch_first= True, enforce_sorted= False)\r\n",
        "\t\tpacked_lstm_out, _ = self.lstm(pack_input,self.init_hidden(batch_size= batch_size))\r\n",
        "\t\tlstm_enc, _=  pad_packed_sequence(packed_lstm_out, batch_first=True, padding_value=0)\r\n",
        "\t\t# print(lstm_enc.size())\r\n",
        "\t\tlstm_feats = self.fc(lstm_enc)\r\n",
        "\r\n",
        "\t\tlstm_max_seq_len = lstm_feats.size(1)\r\n",
        "\t\tpad = torch.zeros(size=(batch_size, max_seq_len-lstm_max_seq_len, self.n_tags), dtype= torch.float).to(self.device)\r\n",
        "\t\tlstm_feats= torch.cat((lstm_feats, pad), dim= 1)\r\n",
        "  \r\n",
        "\t\t# lstm_feats[:,:,:4] = lstm_feats[:,:,:5]*100\r\n",
        "\t\t# lstm_feats[:,:,5:9] = lstm_feats[:,:,5:9]*10\r\n",
        "\t\t# lstm_feats[:,:,9:11] = lstm_feats[:,:,9:11]*100\r\n",
        "\t\t# lstm_feats[:,:,11] = lstm_feats[:,:,11]*100\r\n",
        "\t\t# lstm_feats[:,:,12:17] = lstm_feats[:,:,12:17]*100\r\n",
        "\t\t# lstm_feats[:,:,17:21] = lstm_feats[:,:,17:21]*10\r\n",
        "\t\t# lstm_feats[:,:,21:23] = lstm_feats[:,:,21:23]*100\r\n",
        "\t\t# lstm_feats[:,:,23] = lstm_feats[:,:,23]*1\r\n",
        "\r\n",
        "\t\tlstm_feats[:,:,:23] = lstm_feats[:,:,:23]*100\r\n",
        "\t\tlstm_feats[:,:,23] = lstm_feats[:,:,23]*10\r\n",
        "\r\n",
        "\t\tloss = -self.CRF(lstm_feats, tags, attention_mask.bool(), reduction= 'token_mean')\r\n",
        "\t\tpred_seqs = self.CRF.decode(emissions= lstm_feats, mask= attention_mask.bool())\r\n",
        "  \r\n",
        "\t\treturn loss, pred_seqs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYEi_mFctfCR"
      },
      "source": [
        "# 載入stcs, tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWEzS06NtqJZ"
      },
      "source": [
        "# ---------------前處理---------------\r\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\r\n",
        "\tdata=f.readlines()#.encode('utf-8').decode('utf-8-sig')\r\n",
        "\r\n",
        "preprocessor = preprocess2(data)\r\n",
        "\r\n",
        "stcs, original_labels= preprocessor.get_stc_label()\r\n",
        "stcs, labels = preprocessor.get_stcs_label2ids()\r\n",
        "tag2id_dict = preprocessor.tag2id(original_labels)\r\n",
        "n_tags = len(tag2id_dict)\r\n",
        "print(tag2id_dict)\r\n",
        "print('tags數: {}'.format(n_tags))\r\n",
        "\r\n",
        "gt_tags = [tag for label in labels for tag in label]\r\n",
        "\r\n",
        "for tag in set(gt_tags):\r\n",
        "  print('{}|{}'.format(tag, gt_tags.count(tag)/len(gt_tags)))\r\n",
        "# plt.hist(gt_tags)\r\n",
        "plt.hist([len(stc) for stc in stcs])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\r\n",
        "max_length = len(max(stcs, key=len)) \r\n",
        "print('max_stc_length', max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F72vtVN9tbhD"
      },
      "source": [
        "# 參數設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6d0bc1de2a6843c28a5b2676d6fee0e2",
            "017593c998e4464fb910d45f2329a692",
            "727e02e6543d46ee86b5ae71b42dab72",
            "885ae775bad84b9e8f1148f934dc1e49",
            "1c66c35d61794220a7e4ac06b861d780",
            "382e477643334159b2d54faf38150cf4",
            "f4e8b31b3cb1415ab4a11c1706947c93",
            "5499ca8e59d142cc8111fbfd9b3f37d1",
            "94846abe9eff42c18bad7f5e9ad4038f",
            "19d4db3c4c8a4b06a58136b0e3cf06d6",
            "e1c86e2bbc594126a02fd0c726eaa95b",
            "3d9135dd51f547bebee111c2b1971f77",
            "60c24e5dd96848a993fa51f6eb68de05",
            "74a517912f5e4357b0191bfbb8bfdeba",
            "e4d0ce05e747419f96ca64f8d87de0e8",
            "b041a469d11f4a079d3bad26dd91b4c8",
            "106875ae42374e82976ceb9563f244b8",
            "7f66b6a843d04c859a94502ee62a4c78",
            "3064fde93b9844bca5b26093ee01ae50",
            "a0b1ba8c73304d58a34e9f37ba23c69f",
            "6768cc129aee4b5cabf69ac97453acf7",
            "e0ab9c33d12b4323ba625336c5dd569a",
            "a9eebc212e6349b98e84af7b6177a9ce",
            "4e2f595acb874f73bb0f09b17625f51a"
          ]
        },
        "id": "zTvRlmOldMGf",
        "outputId": "adc55a81-6e0e-4d77-ec23-14c92dcedfc4"
      },
      "source": [
        "# ---------------模型---------------\r\n",
        "batchsize= 64\r\n",
        "model = model_crf(n_tags= n_tags, hidden_dim= 256, batchsize= batchsize).to(device)\r\n",
        "# print(summary(model,[(128, 300), (128,300)]))\r\n",
        "\r\n",
        "train_x, test_x, train_y, test_y = train_test_split(stcs, labels, test_size= 0.2, shuffle= True, random_state= 42)\r\n",
        "\r\n",
        "train_dataset = bert_stc_dataset(stcs= train_x, labels= train_y, tokenizer= tokenizer, max_length= max_length)\r\n",
        "print(train_x[0:3])\r\n",
        "print(train_dataset[0:3]['input_ids'])\r\n",
        "print(train_dataset[0:3]['labels'])\r\n",
        "test_dataset = bert_stc_dataset(stcs= test_x, labels= test_y, tokenizer= tokenizer, max_length= max_length)\r\n",
        "\r\n",
        "print('training stcs 總數: {}'.format(len(train_dataset)))\r\n",
        "train_dataloader = DataLoader(train_dataset, batch_size= batchsize, shuffle= True, num_workers= 0)\r\n",
        "test_dataloader = DataLoader(test_dataset, batch_size= batchsize, shuffle= False, num_workers= 0)\r\n",
        "\r\n",
        "num_epochs = 40\r\n",
        "num_iteration = len(train_dataloader)\r\n",
        "print('num_iteration',num_iteration)\r\n",
        "total_iter = num_iteration * num_epochs\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay= 0.0001)\r\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=total_iter)\r\n",
        "# warmup_scheduler = warmup.ExponentialWarmup(optimizer, warmup_period=150)\r\n",
        "\r\n",
        "# ---------------訓練---------------\r\n",
        "# train_model = train(model= model, optimizer= optimizer, train_loader= train_dataloader, test_loader= 0, num_epochs= 5, device= device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q\n",
            "Q\n",
            "E\n",
            "B\n",
            "V\n",
            "C\n",
            "M\n",
            "V\n",
            "O\n",
            "K\n",
            "E\n",
            "B\n",
            "V\n",
            "C\n",
            "M\n",
            "V\n",
            "C\n",
            "R\n",
            "P\n",
            "G\n",
            "G\n",
            "A\n",
            "B\n",
            "S\n",
            "A\n",
            "B\n",
            "S\n",
            "A\n",
            "B\n",
            "S\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "T\n",
            "T\n",
            "T\n",
            "T\n",
            "T\n",
            "T\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "O\n",
            "K\n",
            "C\n",
            "D\n",
            "C\n",
            "D\n",
            "A\n",
            "P\n",
            "P\n",
            "C\n",
            "B\n",
            "H\n",
            "O\n",
            "K\n",
            "X\n",
            "X\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "N\n",
            "B\n",
            "H\n",
            "N\n",
            "H\n",
            "N\n",
            "O\n",
            "K\n",
            "M\n",
            "C\n",
            "M\n",
            "C\n",
            "M\n",
            "C\n",
            "A\n",
            "L\n",
            "T\n",
            "H\n",
            "D\n",
            "L\n",
            "O\n",
            "K\n",
            "B\n",
            "G\n",
            "O\n",
            "T\n",
            "G\n",
            "P\n",
            "T\n",
            "G\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "R\n",
            "D\n",
            "W\n",
            "R\n",
            "D\n",
            "W\n",
            "R\n",
            "D\n",
            "W\n",
            "M\n",
            "P\n",
            "V\n",
            "M\n",
            "P\n",
            "V\n",
            "M\n",
            "P\n",
            "V\n",
            "G\n",
            "M\n",
            "O\n",
            "K\n",
            "M\n",
            "M\n",
            "M\n",
            "T\n",
            "B\n",
            "T\n",
            "B\n",
            "L\n",
            "A\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "C\n",
            "D\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "C\n",
            "D\n",
            "L\n",
            "L\n",
            "T\n",
            "L\n",
            "L\n",
            "L\n",
            "C\n",
            "R\n",
            "P\n",
            "X\n",
            "X\n",
            "X\n",
            "X\n",
            "X\n",
            "X\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "S\n",
            "A\n",
            "R\n",
            "S\n",
            "T\n",
            "B\n",
            "T\n",
            "B\n",
            "T\n",
            "B\n",
            "T\n",
            "B\n",
            "T\n",
            "B\n",
            "T\n",
            "B\n",
            "X\n",
            "X\n",
            "C\n",
            "R\n",
            "P\n",
            "K\n",
            "K\n",
            "K\n",
            "K\n",
            "C\n",
            "O\n",
            "K\n",
            "C\n",
            "D\n",
            "C\n",
            "D\n",
            "C\n",
            "D\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "C\n",
            "V\n",
            "N\n",
            "A\n",
            "B\n",
            "C\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "X\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "T\n",
            "B\n",
            "X\n",
            "X\n",
            "X\n",
            "I\n",
            "R\n",
            "S\n",
            "D\n",
            "E\n",
            "X\n",
            "O\n",
            "N\n",
            "E\n",
            "C\n",
            "D\n",
            "E\n",
            "X\n",
            "O\n",
            "N\n",
            "E\n",
            "N\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "X\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "B\n",
            "C\n",
            "O\n",
            "K\n",
            "B\n",
            "A\n",
            "B\n",
            "C\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "D\n",
            "D\n",
            "O\n",
            "K\n",
            "S\n",
            "O\n",
            "K\n",
            "H\n",
            "O\n",
            "K\n",
            "A\n",
            "A\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "X\n",
            "X\n",
            "B\n",
            "X\n",
            "X\n",
            "O\n",
            "K\n",
            "X\n",
            "B\n",
            "C\n",
            "C\n",
            "C\n",
            "C\n",
            "B\n",
            "C\n",
            "C\n",
            "T\n",
            "M\n",
            "R\n",
            "I\n",
            "B\n",
            "B\n",
            "I\n",
            "C\n",
            "E\n",
            "A\n",
            "I\n",
            "I\n",
            "I\n",
            "I\n",
            "C\n",
            "E\n",
            "A\n",
            "C\n",
            "E\n",
            "A\n",
            "C\n",
            "E\n",
            "A\n",
            "C\n",
            "E\n",
            "A\n",
            "C\n",
            "E\n",
            "A\n",
            "C\n",
            "E\n",
            "A\n",
            "A\n",
            "C\n",
            "A\n",
            "C\n",
            "A\n",
            "C\n",
            "C\n",
            "E\n",
            "A\n",
            "C\n",
            "E\n",
            "A\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "B\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "B\n",
            "B\n",
            "H\n",
            "B\n",
            "H\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "P\n",
            "E\n",
            "P\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "H\n",
            "I\n",
            "V\n",
            "H\n",
            "I\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "Y\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "I\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "B\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "P\n",
            "E\n",
            "P\n",
            "U\n",
            "U\n",
            "U\n",
            "U\n",
            "U\n",
            "U\n",
            "U\n",
            "U\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "U\n",
            "U\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "H\n",
            "I\n",
            "V\n",
            "H\n",
            "I\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "L\n",
            "I\n",
            "N\n",
            "E\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "L\n",
            "I\n",
            "N\n",
            "E\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "L\n",
            "I\n",
            "N\n",
            "E\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "H\n",
            "V\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "H\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "U\n",
            "U\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "U\n",
            "U\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "S\n",
            "O\n",
            "S\n",
            "O\n",
            "S\n",
            "O\n",
            "S\n",
            "O\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "U\n",
            "U\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "U\n",
            "U\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "C\n",
            "D\n",
            "C\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "C\n",
            "O\n",
            "U\n",
            "R\n",
            "S\n",
            "E\n",
            "N\n",
            "O\n",
            "H\n",
            "P\n",
            "C\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "B\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "U\n",
            "U\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "U\n",
            "U\n",
            "O\n",
            "K\n",
            "U\n",
            "U\n",
            "U\n",
            "U\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "H\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "H\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "P\n",
            "V\n",
            "O\n",
            "K\n",
            "B\n",
            "B\n",
            "H\n",
            "P\n",
            "V\n",
            "O\n",
            "K\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "P\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "A\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "A\n",
            "P\n",
            "P\n",
            "G\n",
            "H\n",
            "G\n",
            "G\n",
            "G\n",
            "G\n",
            "O\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "B\n",
            "P\n",
            "B\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "C\n",
            "C\n",
            "C\n",
            "O\n",
            "K\n",
            "C\n",
            "O\n",
            "K\n",
            "C\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "B\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "H\n",
            "H\n",
            "G\n",
            "G\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "O\n",
            "K\n",
            "C\n",
            "S\n",
            "F\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "I\n",
            "V\n",
            "C\n",
            "C\n",
            "C\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "A\n",
            "B\n",
            "B\n",
            "B\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "A\n",
            "C\n",
            "B\n",
            "C\n",
            "B\n",
            "B\n",
            "C\n",
            "B\n",
            "O\n",
            "K\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "O\n",
            "K\n",
            "L\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "Y\n",
            "A\n",
            "P\n",
            "P\n",
            "A\n",
            "P\n",
            "P\n",
            "A\n",
            "P\n",
            "P\n",
            "A\n",
            "B\n",
            "C\n",
            "D\n",
            "A\n",
            "P\n",
            "P\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "B\n",
            "B\n",
            "O\n",
            "K\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "U\n",
            "U\n",
            "U\n",
            "U\n",
            "U\n",
            "U\n",
            "B\n",
            "U\n",
            "U\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "I\n",
            "V\n",
            "H\n",
            "I\n",
            "V\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "A\n",
            "P\n",
            "P\n",
            "A\n",
            "P\n",
            "P\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "P\n",
            "V\n",
            "A\n",
            "A\n",
            "A\n",
            "H\n",
            "P\n",
            "V\n",
            "A\n",
            "A\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "A\n",
            "H\n",
            "P\n",
            "V\n",
            "H\n",
            "P\n",
            "V\n",
            "O\n",
            "K\n",
            "H\n",
            "P\n",
            "V\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "B\n",
            "B\n",
            "S\n",
            "A\n",
            "R\n",
            "S\n",
            "B\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "P\n",
            "E\n",
            "P\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "A\n",
            "P\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "C\n",
            "P\n",
            "E\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "B\n",
            "B\n",
            "P\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "O\n",
            "K\n",
            "H\n",
            "I\n",
            "V\n",
            "O\n",
            "K\n",
            "{'B-ID': 0, 'B-clinical_event': 1, 'B-contact': 2, 'B-education': 3, 'B-family': 4, 'B-location': 5, 'B-med_exam': 6, 'B-money': 7, 'B-name': 8, 'B-organization': 9, 'B-profession': 10, 'B-time': 11, 'I-ID': 12, 'I-clinical_event': 13, 'I-contact': 14, 'I-education': 15, 'I-family': 16, 'I-location': 17, 'I-med_exam': 18, 'I-money': 19, 'I-name': 20, 'I-organization': 21, 'I-profession': 22, 'I-time': 23, 'O': 24}\n",
            "tags數: 25\n",
            "0|8.156024753535126e-05\n",
            "1|5.097515470959454e-05\n",
            "2|0.00019370558789645926\n",
            "3|3.0585092825756724e-05\n",
            "4|0.0002548757735479727\n",
            "5|0.0016413999816489444\n",
            "6|0.00224290680722216\n",
            "7|0.0007952124134696748\n",
            "8|0.001692375136358539\n",
            "9|1.0195030941918908e-05\n",
            "10|0.00013253540224494582\n",
            "11|0.014619674370711716\n",
            "12|0.00015292546412878363\n",
            "13|0.00015292546412878363\n",
            "14|0.0008054074444115937\n",
            "15|3.0585092825756724e-05\n",
            "16|0.00028546086637372945\n",
            "17|0.002446807426060538\n",
            "18|0.00392508691263878\n",
            "19|0.001977836002732268\n",
            "20|0.0028342186018534567\n",
            "21|2.0390061883837816e-05\n",
            "22|0.0004078012376767563\n",
            "23|0.0319206418791481\n",
            "24|0.9332939125470245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d0bc1de2a6843c28a5b2676d6fee0e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "max_stc_length 121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94846abe9eff42c18bad7f5e9ad4038f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "106875ae42374e82976ceb9563f244b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411577189.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "['變得很喘', '我沒有哈哈哈他也沒有', '不然之前我想說奇怪怎麼換藥之後就是自己在懷疑']\n",
            "tensor([ 138,  112, 6365, 2533, 2523, 1596,  112,  117,  112, 2769, 3760, 3300,\n",
            "        1506, 1506, 1506,  800,  738, 3760, 3300,  112,  117,  112,  679, 4197,\n",
            "         722, 1184, 2769, 2682, 6303, 1936, 2597, 2582, 7938, 2994, 5973,  722,\n",
            "        2527, 2218, 3221, 5632, 2346, 1762, 2755, 4542,  112,  140,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0])\n",
            "tensor([[24, 24, 24, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [24, 24, 24, 24, 24, 24, 24, 24, 24, 24,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
            "         24, 24, 24, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
            "training stcs 總數: 6060\n",
            "num_iteration 95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPf2heKjCd7"
      },
      "source": [
        "# test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfjiko8GjBZD"
      },
      "source": [
        "def test(model, test_dataloader, device):\r\n",
        "\r\n",
        "  preds_epoch = []\r\n",
        "  gts_epoch = []\r\n",
        "  epoch_loss = 0\r\n",
        "  iteration = 0\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  for idx, batch_dict in enumerate(test_dataloader):\r\n",
        "\r\n",
        "    # print('idx: ',idx+1)\r\n",
        "    input_ids = batch_dict['input_ids'].to(device)\r\n",
        "    attention_mask = batch_dict['attention_mask'].to(device)\r\n",
        "    labels = batch_dict['labels'].to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      loss, pred_labels = model(input_ids, attention_mask.bool(), labels)\r\n",
        "\r\n",
        "    # mask gt labels \r\n",
        "    labels = batch_dict['labels'].numpy()\r\n",
        "    masks = batch_dict['attention_mask'].numpy()\r\n",
        "\r\n",
        "    labels_nopad = []\r\n",
        "    for label , seq_mask in zip(labels, masks):\r\n",
        "\r\n",
        "      seq = [tag for tag, mask in zip(label, seq_mask) if mask == 1]\r\n",
        "      labels_nopad.append(seq)\r\n",
        "\r\n",
        "    # one dim array \r\n",
        "    preds= [tag for seq in pred_labels for tag in seq]\r\n",
        "    gts= [tag for seq in labels_nopad for tag in seq]\r\n",
        "\r\n",
        "    preds_epoch += preds\r\n",
        "    gts_epoch += gts\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    iteration += 1\r\n",
        "\r\n",
        "  f1_macro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'macro')\r\n",
        "  f1_micro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'micro')\r\n",
        "  f1 = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= None)\r\n",
        "  avg_loss = epoch_loss / iteration\r\n",
        "  \r\n",
        "  print('test_f1(macro, micro) ({:.2f},{:.2f}) | test_avg_loss {:.2f} | f1 for each class{}'.format(f1_macro, f1_micro, avg_loss, f1))\r\n",
        "\r\n",
        "  return f1_macro, f1_micro, avg_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NSLpK9g7bp5"
      },
      "source": [
        "# test out function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2yAR0_67gGZ"
      },
      "source": [
        "class test_output():\r\n",
        "\tdef __init__(self, data, model, tokenizer, batch_size):\r\n",
        "\r\n",
        "\t\tself.model = model\r\n",
        "\t\tself.tokenizer = tokenizer\r\n",
        "\t\tself.batch_size = batch_size\r\n",
        "\t\tself.data_list = []\r\n",
        "\t\tself.word_id = []\r\n",
        "\t\tself.word_article_id = [] \r\n",
        "\t\tarticle_id = 0\r\n",
        "\t\tword_id = 0\r\n",
        "\t\tdata_list_tmp = []\r\n",
        "\t\tarticle_id_tmp = []\r\n",
        "\t\tword_id_tmp = []\r\n",
        "\t\t\r\n",
        "\t\tfor row in data:\r\n",
        "\t\t\t\r\n",
        "\t\t\tdata_tuple = tuple()\r\n",
        "\t\t\tif row == '\\n':\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\tarticle_id += 1 \r\n",
        "\t\t\t\tword_id = 0\r\n",
        "\t\t\t\tself.word_id.append(word_id)\r\n",
        "\t\t\t\tself.word_article_id.append(article_id_tmp)\r\n",
        "\t\t\t\tself.data_list.append(data_list_tmp)\r\n",
        "\t\t\t\tdata_list_tmp = []\r\n",
        "\t\t\t\tarticle_id_tmp = []\r\n",
        "\t\t\t\tword_id_tmp = []\r\n",
        "\r\n",
        "\t\t\telse:\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\trow = row.strip('\\n').split(' ')\r\n",
        "\r\n",
        "\t\t\t\tif row[0] in ['。', '？','！','，','～','：','‧']:\r\n",
        "\t\t\t\t\t\r\n",
        "\t\t\t\t\tself.word_id.append(word_id_tmp)\r\n",
        "\t\t\t\t\tself.word_article_id.append(article_id_tmp)\r\n",
        "\t\t\t\t\tself.data_list.append(data_list_tmp)\r\n",
        "\t\t\t\t\tdata_list_tmp = []\r\n",
        "\t\t\t\t\tarticle_id_tmp = []\r\n",
        "\t\t\t\t\tword_id_tmp = []\r\n",
        "\t\t\t\t\t\r\n",
        "\t\t\t\telif row[0] in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']:\r\n",
        "\t\t\t\t\t  \r\n",
        "\t\t\t\t\tdata_tuple = (row[0].lower(), article_id, word_id)\r\n",
        "\t\t\t\t\tdata_list_tmp.append(data_tuple)\r\n",
        "\t\t\t\t\tarticle_id_tmp.append(article_id)\r\n",
        "\t\t\t\t\tword_id_tmp.append(word_id)\r\n",
        "\r\n",
        "\t\t\t\telif row[0] not in ['摁','嗯','啦','喔','欸','啊','齁','嘿','…','...','、','，']:\r\n",
        "\t\t\t\t\t\r\n",
        "\t\t\t\t\tdata_tuple = (row[0], article_id, word_id)\r\n",
        "\t\t\t\t\tdata_list_tmp.append(data_tuple)\r\n",
        "\t\t\t\t\tarticle_id_tmp.append(article_id)\r\n",
        "\t\t\t\t\tword_id_tmp.append(word_id)\r\n",
        "\t\t\t\t\t\r\n",
        "\t\t\t\tword_id += 1\r\n",
        "\t\t\t\t\r\n",
        "\t\tif len(data_list_tmp) != 0:\r\n",
        "\t\t\tself.data_list.append(data_list_tmp)\r\n",
        "\t\t\tself.word_id.append(word_id_tmp)\r\n",
        "\t\t\tself.word_article_id.append(article_id_tmp)\r\n",
        "\t\t\t\r\n",
        "\tdef raw_output(self):\r\n",
        "\t\treturn self.data_list, self.word_id, self.word_article_id\r\n",
        "\r\n",
        "\tdef get_stcs(self):\r\n",
        "\t\t\r\n",
        "\t\tall_stcs = list()\r\n",
        "\t\tall_article_ids = list()\r\n",
        "\t\tall_word_ids = list()\r\n",
        "\r\n",
        "\t\tfor stc_list in self.data_list:\r\n",
        "\r\n",
        "\t\t\ttxt_len = len(stc_list) #(文章數，每個文章對應的總字數) (word, label)\r\n",
        "\t\t\tstc = str() #存字數= max_stc_len的字串\r\n",
        "\t\t\tarticle_ids = []\r\n",
        "\t\t\tword_ids = []\r\n",
        "\t\t\t\r\n",
        "\r\n",
        "\t\t\tfor idx, (word,article_id, word_id) in enumerate(stc_list):\r\n",
        "\r\n",
        "\t\t\t\tstc += word\r\n",
        "\t\t\t\tarticle_ids.append(article_id)\r\n",
        "\t\t\t\tword_ids.append(word_id)\r\n",
        "\r\n",
        "\t\t\tall_stcs.append(stc)\r\n",
        "\t\t\tall_article_ids.append(article_ids)\r\n",
        "\t\t\tall_word_ids.append(word_ids)\r\n",
        "\r\n",
        "\t\tassert len(all_stcs) > 0, 'all stcs len = 0' \r\n",
        "\r\n",
        "\t\tall_stcs_clean = []\r\n",
        "\t\tall_article_ids_clean = []\r\n",
        "\t\tall_word_ids_clean = []\r\n",
        "\t\tidx = 0\r\n",
        "\t\t\r\n",
        "\t\tfor stc, article_id, word_id in zip(all_stcs, all_article_ids, all_word_ids):\r\n",
        "\t\t\tstc_clean = re.sub(r'(醫師)|(個管師)|(民眾)|(家屬)|(護理師)', '', stc)\r\n",
        "\t\t\t# print(stc, stc_clean, label)\r\n",
        "\t\t\tif len(stc_clean) > 1:  \r\n",
        "\t\t\t# print(stc_clean, stc)\r\n",
        "\t\t\t\tall_stcs_clean.append(stc)\r\n",
        "\t\t\t\tall_article_ids_clean.append(article_id)\r\n",
        "\t\t\t\tall_word_ids_clean.append(word_id)\r\n",
        "\r\n",
        "\t\t\t# 這一步就先把label 做 0 padding\r\n",
        "\t\t\t\r\n",
        "\t\tmax_length = len(max(all_stcs_clean, key=len))\r\n",
        "\t\tassert max_length > 0, 'max length less than 1'\r\n",
        "\r\n",
        "\t\tprint('sentences總數: {}'.format(len(all_stcs_clean)))\r\n",
        "\t\t\t\r\n",
        "\t\t# return all_stcs_clean, all_article_ids_clean, all_word_ids_clean\r\n",
        "\r\n",
        "\t\tself.clean_stcs, self.clean_article_id, self.clean_word_id = [], [] ,[]\r\n",
        "\r\n",
        "\t\tfor stc, article_id, word_id in zip(stcs, article_ids, word_ids):\r\n",
        "\t\t#print(stc, article_id, word_id)\r\n",
        "\t\t\tif stc not in ['沒有','也沒有','哪個','那個','算了','不用','有','有有有','有嗎','一點點', '謝謝','不會','不好意思','對不對','好不好','要嗎','還好']:\r\n",
        "\t\t\t\tself.clean_stcs.append(stc)\r\n",
        "\t\t\t\tself.clean_article_id.append(article_id)\r\n",
        "\t\t\t\tself.clean_word_id.append(word_id)\r\n",
        "\t\treturn self.clean_stcs, self.clean_article_id, self.clean_word_id\r\n",
        "\r\n",
        "\tdef encoding(self):\r\n",
        "    \r\n",
        "\t\tclean_stcs, _, _ = self.get_stcs()\r\n",
        "\t\tmax_len = max(len(txt) for txt in clean_stcs)\r\n",
        "\r\n",
        "\t\tencoding = self.tokenizer.batch_encode_plus(clean_stcs, \r\n",
        "\t\t\tpadding=True,\r\n",
        "\t\t\tadd_special_tokens=False,\r\n",
        "\t\t\treturn_attention_mask= True,\r\n",
        "\t\t\treturn_token_type_ids= False,\r\n",
        "\t\t\t#  is_split_into_words=True,\r\n",
        "\t\t\treturn_tensors='pt')\r\n",
        "\r\n",
        "\t\t# batch_size= 32\r\n",
        "\t\tpred_labels = []\r\n",
        "\r\n",
        "\t\tfor idx in range(int((len(clean_stcs)/self.batch_size))):\r\n",
        "\t\t\tinput= encoding['input_ids'][idx*self.batch_size:(idx+1)*self.batch_size].to(device)\r\n",
        "\t\t\tmask = encoding['attention_mask'][idx*self.batch_size:(idx+1)*self.batch_size].to(device)\r\n",
        "\t\t\ttags= torch.zeros((input.size(0),input.size(1)), dtype=torch.long).to(device)\r\n",
        "\t\t\t_, preds = model(input, mask, tags)\r\n",
        "\t\t\tfor pred in preds:\r\n",
        "\t\t\t\tpred_labels.append(pred)\r\n",
        "\r\n",
        "\t\tidx = int((len(clean_stcs)/self.batch_size))\r\n",
        "\t\tinput= encoding['input_ids'][idx*self.batch_size:].to(device)\r\n",
        "\t\tmask = encoding['attention_mask'][idx*self.batch_size:].to(device)\r\n",
        "\t\ttags= torch.zeros((input.size(0),input.size(1)), dtype=torch.long).to(device)\r\n",
        "\t\t_, preds = model(input, mask, tags)\r\n",
        "\t\tfor pred in preds:\r\n",
        "\t\t\tpred_labels.append(pred)\r\n",
        "\r\n",
        "\t\ttag2id = {'[PAD]': 0, 'B-ID': 1, 'B-clinical_event': 2, 'B-contact': 3, 'B-education': 4, 'B-family': 5, 'B-location': 6, 'B-med_exam': 7, 'B-money': 8, 'B-name': 9, 'B-organization': 10, 'B-profession': 11, 'B-time': 12, 'I-ID': 13, 'I-clinical_event': 14, 'I-contact': 15, 'I-education': 16, 'I-family': 17, 'I-location': 18, 'I-med_exam': 19, 'I-money': 20, 'I-name': 21, 'I-organization': 22, 'I-profession': 23, 'I-time': 24, 'O': 25}\r\n",
        "\t\tid2tag ={v:k for k, v in tag2id.items()}\r\n",
        "\r\n",
        "\t\tself.pred_labels_tag = []\r\n",
        "\t\tfor label in pred_labels:\r\n",
        "\t\t\tstc_label = [id2tag[id] for id in label]\r\n",
        "\t\t\tself.pred_labels_tag.append(stc_label)\r\n",
        "\r\n",
        "\t\treturn self.pred_labels_tag\r\n",
        "\r\n",
        "\tdef pred_out_tsv(self):\r\n",
        "\t\t\r\n",
        "\t\tclean_stcs, clean_article_id, clean_word_id = self.get_stcs()\r\n",
        "\t\tpred_labels_tag = self.encoding()\r\n",
        "\r\n",
        "\t\tentity_text = []\r\n",
        "\r\n",
        "\t\tfor stc, labels, article_id, word_id in zip(clean_stcs, pred_labels_tag, clean_article_id, clean_word_id):\r\n",
        "\r\n",
        "\t\t\tentity = str()\r\n",
        "\r\n",
        "\t\t\tstart_pos = 0\r\n",
        "\t\t\tend_pos = 0\r\n",
        "\t\t\tarticle = 0\r\n",
        "\r\n",
        "\t\t\tentity_type = str()\r\n",
        "\r\n",
        "\r\n",
        "\t\t\tfor idx, label in enumerate(labels):\r\n",
        "\t\t\t\tif bool(re.match(r'B-', label)):\r\n",
        "\t\t\t\t\tentity += list(stc)[idx]\r\n",
        "\t\t\t\t\tstart_pos = word_id[idx]\r\n",
        "\t\t\t\t\tarticle = article_id[idx]\r\n",
        "\t\t\t\t\tentity_type = label.split('B-')[1]\r\n",
        "\r\n",
        "\t\t\t\telif bool(re.match(r'I-', label)):\r\n",
        "\t\t\t\t\tentity += list(stc)[idx]\r\n",
        "\t\t\t\t\tend_pos= word_id[idx]\r\n",
        "\t\t\t\t\ttry:\r\n",
        "\t\t\t\t\t\tif (labels[idx+1] == 'O') & (entity_type!=''):\r\n",
        "\t\t\t\t\t\t\tentity_text.append((article, start_pos, end_pos, entity, entity_type))\r\n",
        "\r\n",
        "\t\t\t\t\t\t\tentity = str()\r\n",
        "\t\t\t\t\t\t\tstart_pos = 0\r\n",
        "\t\t\t\t\t\t\tend_pos = 0\r\n",
        "\t\t\t\t\t\t\tarticle = 0\r\n",
        "\t\t\t\t\t\t\tentity_type = str()\r\n",
        "\t\t\t\t\texcept:\r\n",
        "\t\t\t\t\t\tpass\r\n",
        "\t\twith open('test_output.tsv', 'w', encoding='utf-8',newline='\\n') as f:\r\n",
        "\t\t\twriter = csv.writer(f, delimiter='\\t')\r\n",
        "\t\t\twriter.writerow(['article_id','start_position', 'end_position', 'entity_text', 'entity_type'])\r\n",
        "\t\t\tfor (article, start_pos, end_pos, entity, entity_type) in entity_text:\r\n",
        "\t\t\t\twriter.writerow([str(article), str(start_pos), str(end_pos), str(entity), str(entity_type)])\r\n",
        "\r\n",
        "\t\treturn entity_text\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTZoeeJLtl9K"
      },
      "source": [
        "# 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyZYZVdJhxFa",
        "outputId": "f11dd926-22a8-4e36-a30b-d84b6572860e"
      },
      "source": [
        "train_loss = {}\r\n",
        "test_loss = {}\r\n",
        "train_f1 = {}\r\n",
        "test_f1 = {}\r\n",
        "stop_epoch = 0\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "\r\n",
        "  preds_epoch = []\r\n",
        "  gts_epoch = []\r\n",
        "  epoch_loss = 0\r\n",
        "  iteration = 0\r\n",
        "\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  for idx, batch_dict in enumerate(train_dataloader):\r\n",
        "\r\n",
        "    # print('idx: ',idx+1)\r\n",
        "    input_ids = batch_dict['input_ids'].to(device)\r\n",
        "    attention_mask = batch_dict['attention_mask'].to(device)\r\n",
        "    labels = batch_dict['labels'].to(device)\r\n",
        "\r\n",
        "    loss, pred_labels = model(input_ids, attention_mask.bool(), labels)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "    scheduler.step()\r\n",
        "    model.zero_grad()\r\n",
        "\r\n",
        "    # mask gt labels \r\n",
        "    labels = batch_dict['labels'].numpy()\r\n",
        "    masks = batch_dict['attention_mask'].numpy()\r\n",
        "\r\n",
        "    labels_nopad = []\r\n",
        "    for label , seq_mask in zip(labels, masks):\r\n",
        "\r\n",
        "        seq = [tag for tag, mask in zip(label, seq_mask) if mask == 1]\r\n",
        "        labels_nopad.append(seq)\r\n",
        "\r\n",
        "    # one dim array \r\n",
        "    preds= [tag for seq in pred_labels for tag in seq]\r\n",
        "    gts= [tag for seq in labels_nopad for tag in seq]\r\n",
        "\r\n",
        "    preds_epoch += preds\r\n",
        "    gts_epoch += gts\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    iteration += 1\r\n",
        "\r\n",
        "  f1_macro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'macro')\r\n",
        "  f1_micro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'micro')\r\n",
        "  f1 = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= None)\r\n",
        "  avg_loss = epoch_loss / iteration\r\n",
        "  stop_epoch = epoch+1\r\n",
        "\r\n",
        "  print('epoch {}/{} | train_f1(macro, micro) ({:.2f},{:.2f}) | train_epoch_avg_loss {:.2f}| f1 for each class {}'.format(epoch+1, num_epochs, f1_macro, f1_micro, avg_loss, f1))\r\n",
        "\r\n",
        "  test_f1_macro, test_f1_micro, test_avg_loss = test(model= model, test_dataloader= test_dataloader, device= device)\r\n",
        "\r\n",
        "  train_loss[epoch+1] = avg_loss\r\n",
        "  test_loss[epoch+1] = test_avg_loss\r\n",
        "  train_f1[epoch+1] = f1_macro\r\n",
        "  test_f1[epoch+1] = test_f1_macro\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1/40 | train_f1(macro, micro) (0.03,0.48) | train_epoch_avg_loss 5.75| f1 for each class [0.00000000e+00 0.00000000e+00 1.86915888e-03 0.00000000e+00\n",
            " 0.00000000e+00 2.25225225e-03 3.32557366e-03 1.52322925e-03\n",
            " 2.21157390e-03 0.00000000e+00 0.00000000e+00 2.44295921e-02\n",
            " 5.54323725e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 5.56586271e-03 7.06713781e-03 3.94477318e-03\n",
            " 2.78940028e-03 0.00000000e+00 2.17450394e-03 8.97435897e-03\n",
            " 6.59549991e-01]\n",
            "test_f1(macro, micro) (0.04,0.86) | test_avg_loss 1.22 | f1 for each class[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.02425876\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.01169591 0.         0.01515152 0.         0.         0.\n",
            " 0.92651535]\n",
            "epoch 2/40 | train_f1(macro, micro) (0.04,0.87) | train_epoch_avg_loss 1.02| f1 for each class [0.         0.         0.         0.         0.         0.\n",
            " 0.01232033 0.         0.         0.         0.         0.08379447\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.06518519 0.00480769 0.         0.         0.         0.01756396\n",
            " 0.93563161]\n",
            "test_f1(macro, micro) (0.06,0.92) | test_avg_loss 0.55 | f1 for each class[0.         0.         0.         0.         0.         0.\n",
            " 0.05194805 0.         0.02816901 0.         0.         0.2955414\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.14925373 0.         0.         0.         0.         0.12198582\n",
            " 0.96352655]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hHf_PDUEPkg"
      },
      "source": [
        "# 訓練成果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAFcxDva2iGf"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows= 2, ncols= 1, figsize= (10,8), sharex= True)\r\n",
        "ax1.plot([*range(1, stop_epoch+1)], list(train_loss.values()), label= 'train loss')\r\n",
        "ax1.plot([*range(1, stop_epoch+1)], list(test_loss.values()), label= 'test loss')\r\n",
        "ax1.legend()\r\n",
        "\r\n",
        "ax2.plot([*range(1, stop_epoch+1)], list(train_f1.values()), label= 'train f1 (macro)')\r\n",
        "ax2.plot([*range(1, stop_epoch+1)], list(test_f1.values()), label= 'test f1 (macro)')\r\n",
        "ax2.legend()\r\n",
        "plt.savefig('fig.jpeg')\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pWa4TQhw5PI"
      },
      "source": [
        "# torch.save(model, 'ner_model_batch32_wup4000_lstmhd256_lr5e-5_40epoch_adam_wde-3.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1UTlctlqT8g"
      },
      "source": [
        "# !cp 'ner_model_batch32_wup4000_lstmhd256_lr5e-5_40epoch_adam_wde-3.pt' '/content/drive/My Drive/python檔/aicup'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvc6xWNC85De"
      },
      "source": [
        "with open('/content/drive/My Drive/python檔/aicup/test_input.data', 'r', encoding= 'utf-8') as f:\r\n",
        "    data = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApTe5VvOqO-P"
      },
      "source": [
        "pred_outs = test_output(data= data, model= model, tokenizer=tokenizer, batch_size= 32).pred_out_tsv()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4qmYVsB9GYp"
      },
      "source": [
        "pred_outs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
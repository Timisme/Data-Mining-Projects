{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "aicup_main_good.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk66K6AWaW1q"
      },
      "source": [
        "# !cp drive/MyDrive/python檔/aicup/run/dataset.py .\r\n",
        "# !cp drive/MyDrive/python檔/aicup/run "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsnrmjRWrSmN"
      },
      "source": [
        "# loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GHLkq1bcEox",
        "outputId": "9487bfbf-56ff-4161-e496-c7b50c5a3d3c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59rSMkbocYfI"
      },
      "source": [
        "import sys\r\n",
        "sys.path.insert(0,\"/content/drive/My Drive/python檔/aicup/run\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3D3ktlwcq1p",
        "outputId": "86255654-d8ee-4e74-9af1-94bf6123923b"
      },
      "source": [
        "pip install transformers==3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8.0rc4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3) (1.19.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.1.94)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3) (20.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6RsrpxBWe1H",
        "outputId": "56315b10-6e36-489c-e5e4-a48f648e9827"
      },
      "source": [
        "pip install pytorch-crf"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.6/dist-packages (0.7.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6eL0_ORc3lj",
        "outputId": "e70ce2c0-a8b8-43bb-b279-9c1801d0de2e"
      },
      "source": [
        "pip install pytorch_warmup"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_warmup in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_warmup) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (1.19.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNw4yCiwa1e2"
      },
      "source": [
        "# from dataset import bert_stc_dataset\r\n",
        "# from model2 import model_crf\r\n",
        "from train import train\r\n",
        "# from txt_preprocess2 import preprocess2\r\n",
        "import re\r\n",
        "import time\r\n",
        "import csv\r\n",
        "\r\n",
        "from transformers import BertModel, BertTokenizer, get_cosine_schedule_with_warmup\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchsummary import summary\r\n",
        "from torchcrf import CRF\r\n",
        "import pytorch_warmup as warmup\r\n",
        "# from torch.autograd import Variable\r\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Qnou0tbJfb",
        "outputId": "ed5bc330-4d16-4351-9602-bac553a26152"
      },
      "source": [
        "file_path = '/content/drive/My Drive/python檔/aicup/run/data/train2_input.data'\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "print('{} is being used'.format(device))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is being used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6sIQ8wbXGnc"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo2E2d2TU7dG"
      },
      "source": [
        "from torch.utils.data import Dataset\r\n",
        "import torch\r\n",
        "\r\n",
        "class bert_stc_dataset(Dataset):\r\n",
        "    \r\n",
        "    def __init__(self, stcs, labels, tokenizer, max_length):\r\n",
        "        \r\n",
        "        self.stcs = stcs\r\n",
        "        self.labels = labels\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        self.max_length = max_length\r\n",
        "        self.pad_labels = []\r\n",
        "\r\n",
        "        # 已經在preprocess2 做完label 0 padding\r\n",
        "        for i in range(len(labels)):\r\n",
        "            temp_label = [0]*max_length\r\n",
        "            temp_label[:len(labels[i])] = labels[i]\r\n",
        "            self.pad_labels.append(temp_label)\r\n",
        "            \r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.stcs)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        \r\n",
        "        txt = str(self.stcs[idx])\r\n",
        "        \r\n",
        "        txt = ' '.join(list(txt)) #中間要有空格，數字才會分類準確\r\n",
        "        # print(txt)\r\n",
        "        \r\n",
        "        encoding = self.tokenizer.encode_plus(\r\n",
        "            txt,\r\n",
        "#             truncation= True,\r\n",
        "            max_length= self.max_length,\r\n",
        "            padding = 'max_length',\r\n",
        "            add_special_tokens=False,\r\n",
        "#             pad_to_multiple_of=True,\r\n",
        "            return_attention_mask= True,\r\n",
        "            return_token_type_ids= False,\r\n",
        "            return_tensors='pt')\r\n",
        "        \r\n",
        "        return {\r\n",
        "            'input_ids': encoding['input_ids'].flatten(),\r\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\r\n",
        "            'labels' : torch.tensor(self.pad_labels[idx], dtype= torch.long)\r\n",
        "        }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfh42ir6I9FM"
      },
      "source": [
        "# preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr4UxdsTI8Y-"
      },
      "source": [
        "class preprocess2():\r\n",
        "  def __init__(self, data):\r\n",
        "    self.data = data\r\n",
        "    self.data_list= list()\r\n",
        "    data_list_tmp = list()\r\n",
        "\r\n",
        "    for row in data:\r\n",
        "      data_tuple = tuple()\r\n",
        "      if row == '\\n':\r\n",
        "        if (len(data_list_tmp) != 0):\r\n",
        "          self.data_list.append(data_list_tmp)\r\n",
        "          data_list_tmp = []\r\n",
        "\r\n",
        "      else:\r\n",
        "        row = row.strip('\\n').split(' ')\r\n",
        "\r\n",
        "        if (row[0] in ['。', '？','！','～','，', '：']) & (len(data_list_tmp) >= 128):\r\n",
        "          self.data_list.append(data_list_tmp)\r\n",
        "          data_list_tmp= []\r\n",
        "        \r\n",
        "        elif row[0] in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']:\r\n",
        "          data_tuple = (row[0].lower(), row[1])\r\n",
        "        #   print(row[0].lower())\r\n",
        "          data_list_tmp.append(data_tuple)\r\n",
        "\r\n",
        "        else: #row[0] not in ['欸','喔','诶','摁','嗯','齁','嗎','嘿','哦','？','！','。', '～', '：'] :\r\n",
        "          data_tuple = (row[0], row[1])\r\n",
        "          data_list_tmp.append(data_tuple)\r\n",
        "\r\n",
        "        #data_list_tmp 儲存暫時的data_tuple(token,label)\r\n",
        "    if len(data_list_tmp) != 0:\r\n",
        "      self.data_list.append(data_list_tmp)\r\n",
        "\r\n",
        "    # print(self.data_list[0])\r\n",
        "\r\n",
        "  def get_stc_label(self):\r\n",
        "\r\n",
        "    all_stcs = list()\r\n",
        "    all_labels = list()\r\n",
        "\r\n",
        "    for stc_tuples in self.data_list:\r\n",
        "\r\n",
        "      txt_len = len(stc_tuples) #(文章數，每個文章對應的總字數) (word, label)\r\n",
        "      stcs = str() #存字數= max_stc_len的字串\r\n",
        "      labels = []\r\n",
        "\r\n",
        "\r\n",
        "      for idx, (word, label) in enumerate(stc_tuples):\r\n",
        "\r\n",
        "        stcs += word\r\n",
        "        labels.append(label)\r\n",
        "\r\n",
        "    #   stcs = re.sub(r'(醫師：)|(個管師：)|(民眾：)|(家屬：)|(護理師：)', '', stcs)\r\n",
        "        \r\n",
        "    #   stc_split_list  = re.split(r'。|？|！|～', stcs)\r\n",
        "\r\n",
        "    #   clean_stc_list = [ stc for stc in stc_split_list if stc not in ['摁','嗯','啦','喔','欸','啊','齁','嘿','嘛','對','了解','對阿','是']]\r\n",
        "    #   # print(clean_stc_list)\r\n",
        "    #   stc = '。'.join(clean_stc_list)\r\n",
        "\r\n",
        "      if len(set(labels)) > 0: # downsamping\r\n",
        "\r\n",
        "        all_stcs.append(stcs)\r\n",
        "        all_labels.append(labels)\r\n",
        "\r\n",
        "    return all_stcs, all_labels\r\n",
        "\r\n",
        "\r\n",
        "  def tag2id(self, stcs_label):\r\n",
        "\r\n",
        "    all_label = list()\r\n",
        "    for stc_label in stcs_label:\r\n",
        "      for label in stc_label:\r\n",
        "        all_label.append(label)\r\n",
        "\r\n",
        "    labels_set = sorted(set(all_label))\r\n",
        "    tag2id_dict = {}\r\n",
        "\r\n",
        "    for idx, label in enumerate(labels_set):\r\n",
        "      tag2id_dict[label] = idx\r\n",
        "\r\n",
        "    return tag2id_dict\r\n",
        "\r\n",
        "  def label_to_ids(self, tag_to_id, raw_labels):\r\n",
        "\r\n",
        "    label2id = []\r\n",
        "    for stc_labels in raw_labels:\r\n",
        "      stc_label_ids = [tag_to_id[label] for label in stc_labels]\r\n",
        "      label2id.append(stc_label_ids)\r\n",
        "    return label2id\r\n",
        "\r\n",
        "  def get_stcs_label2ids(self):\r\n",
        "\r\n",
        "    stcs, labels = self.get_stc_label()\r\n",
        "    tag2id = self.tag2id(stcs_label= labels)\r\n",
        "    labels_ids= self.label_to_ids(tag_to_id= tag2id, raw_labels= labels)\r\n",
        "\r\n",
        "    return stcs, labels, labels_ids"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpu1QT-5tYsi"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48kSvtOFtQRg"
      },
      "source": [
        "class model_crf(nn.Module):\r\n",
        "\tdef __init__(self, n_tags, hidden_dim=768, batchsize= 32, num_layers= 1, lstm_dropout= 0, fc_dropout= 0.2):\r\n",
        "\t\tsuper(model_crf, self).__init__()\r\n",
        "\t\tself.num_layers = num_layers\r\n",
        "\t\tself.n_tags = n_tags\r\n",
        "\t\tself.lstm =  nn.LSTM(bidirectional=True, num_layers=num_layers, input_size=768, hidden_size=hidden_dim//2, dropout= lstm_dropout, batch_first=True)\t\t\r\n",
        "\t\tself.hidden_dim = hidden_dim\r\n",
        "\t\tself.fc = nn.Linear(hidden_dim, self.n_tags)\r\n",
        "\t\tself.bert = BertModel.from_pretrained('bert-base-chinese')\r\n",
        "\r\n",
        "\t\t# for param in self.bert.parameters():\r\n",
        "\t\t# \tparam.requires_grad = False\r\n",
        "\t\t# self.bert.eval()  # 知用来取bert embedding\r\n",
        "\r\n",
        "\t\tself.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "\t\tself.CRF = CRF(n_tags, batch_first= True)\r\n",
        "\t\tself.dropout = nn.Dropout(p= fc_dropout)\r\n",
        "\t\tself.hidden = self.init_hidden(batchsize)\r\n",
        "\r\n",
        "\tdef init_hidden(self, batch_size):\r\n",
        "\t\treturn (torch.randn(2*self.num_layers, batch_size, self.hidden_dim // 2).to(self.device),\r\n",
        "\t\t\t\ttorch.randn(2*self.num_layers, batch_size, self.hidden_dim // 2).to(self.device))\r\n",
        "\r\n",
        "\tdef forward(self, input_ids, attention_mask, tags):\r\n",
        "\r\n",
        "\t\tbatch_size = input_ids.size(0)\r\n",
        "\t\tmax_seq_len = input_ids.size(1)\r\n",
        "\t\tbert_output, _  = self.bert(input_ids.long(), attention_mask)\r\n",
        "\t\tseq_len = torch.sum(attention_mask, dim= 1).cpu().int()\r\n",
        "\t\t# print(seq_len)\r\n",
        "\t\tpack_input = pack_padded_sequence(input= bert_output, lengths= seq_len, batch_first= True, enforce_sorted= False)\r\n",
        "\t\tpacked_lstm_out, _ = self.lstm(pack_input,self.init_hidden(batch_size= batch_size))\r\n",
        "\t\tlstm_enc, _=  pad_packed_sequence(packed_lstm_out, batch_first=True)\r\n",
        "\t\t# print(lstm_enc.size())\r\n",
        "\t\tlstm_enc = self.dropout(lstm_enc)\r\n",
        "\t\tlstm_feats = self.fc(lstm_enc)\r\n",
        "\r\n",
        "\t\tlstm_max_seq_len = lstm_feats.size(1)\r\n",
        "\t\tpad = torch.zeros(size=(batch_size, max_seq_len-lstm_max_seq_len, self.n_tags), dtype= torch.float).to(self.device)\r\n",
        "\t\tlstm_feats= torch.cat((lstm_feats, pad), dim= 1)\r\n",
        "\r\n",
        "\t\t# focal loss 權重調整\r\n",
        "\t\tlstm_feats[:,:,:-2] = lstm_feats[:,:,:-2]*100\r\n",
        "\t\tlstm_feats[:,:,-2] = lstm_feats[:,:,-2]*100\r\n",
        "\r\n",
        "\t\tloss = -self.CRF(lstm_feats, tags, attention_mask.bool(), reduction= 'mean')\r\n",
        "\t\tpred_seqs = self.CRF.decode(emissions= lstm_feats, mask= attention_mask.bool())\r\n",
        "  \r\n",
        "\t\treturn loss, pred_seqs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYEi_mFctfCR"
      },
      "source": [
        "# 載入stcs, tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "id": "TWEzS06NtqJZ",
        "outputId": "75da443c-aa6f-40d7-847f-380dc94e0627"
      },
      "source": [
        "# ---------------前處理---------------\r\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\r\n",
        "\tdata=f.readlines()#.encode('utf-8').decode('utf-8-sig')\r\n",
        "\r\n",
        "preprocessor = preprocess2(data)\r\n",
        "\r\n",
        "stcs, original_labels, labels = preprocessor.get_stcs_label2ids()\r\n",
        "tag2id_dict = preprocessor.tag2id(original_labels)\r\n",
        "id2tag_dict = {v:k for k,v in tag2id_dict.items()}\r\n",
        "\r\n",
        "n_tags = len(tag2id_dict)\r\n",
        "print(tag2id_dict)\r\n",
        "print('tags數: {}'.format(n_tags))\r\n",
        "\r\n",
        "gt_tags = [tag for label in labels for tag in label]\r\n",
        "\r\n",
        "for tag in set(gt_tags):\r\n",
        "  print('{}|{:.6f}'.format(tag, gt_tags.count(tag)/len(gt_tags)))\r\n",
        "# plt.hist(gt_tags)\r\n",
        "plt.hist([len(stc) for stc in stcs])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\r\n",
        "max_length = len(max(stcs, key=len)) \r\n",
        "print('max_length', max_length)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-ID': 0, 'B-clinical_event': 1, 'B-contact': 2, 'B-education': 3, 'B-family': 4, 'B-location': 5, 'B-med_exam': 6, 'B-money': 7, 'B-name': 8, 'B-organization': 9, 'B-others': 10, 'B-profession': 11, 'B-time': 12, 'I-ID': 13, 'I-clinical_event': 14, 'I-contact': 15, 'I-education': 16, 'I-family': 17, 'I-location': 18, 'I-med_exam': 19, 'I-money': 20, 'I-name': 21, 'I-organization': 22, 'I-others': 23, 'I-profession': 24, 'I-time': 25, 'O': 26}\n",
            "tags數: 27\n",
            "0|0.000051\n",
            "1|0.000012\n",
            "2|0.000125\n",
            "3|0.000014\n",
            "4|0.000120\n",
            "5|0.000667\n",
            "6|0.001067\n",
            "7|0.000303\n",
            "8|0.000672\n",
            "9|0.000002\n",
            "10|0.000007\n",
            "11|0.000101\n",
            "12|0.006081\n",
            "13|0.000154\n",
            "14|0.000036\n",
            "15|0.000520\n",
            "16|0.000029\n",
            "17|0.000132\n",
            "18|0.001016\n",
            "19|0.002054\n",
            "20|0.000754\n",
            "21|0.001216\n",
            "22|0.000005\n",
            "23|0.000014\n",
            "24|0.000210\n",
            "25|0.013227\n",
            "26|0.971407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "max_length 179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F72vtVN9tbhD"
      },
      "source": [
        "# 參數設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTvRlmOldMGf",
        "outputId": "35407271-bb02-4fba-8bbe-f26158187d2c"
      },
      "source": [
        "# --------------- 現在model只有單層 ---------------\r\n",
        "batchsize= 32\r\n",
        "hidden_dim= 256\r\n",
        "num_epochs= 20\r\n",
        "lr = 1e-4\r\n",
        "weight_decay = 1e-2\r\n",
        "warmup_ratio = 0.3\r\n",
        "lstm_dropout = 0 # No dropout better?\r\n",
        "fc_dropout = 0.5\r\n",
        "num_layers = 2\r\n",
        "\r\n",
        "model = model_crf(n_tags= n_tags, hidden_dim= hidden_dim, batchsize= batchsize, num_layers= num_layers, lstm_dropout= lstm_dropout, fc_dropout= fc_dropout).to(device)\r\n",
        "# print(summary(model,[(128, 300), (128,300)]))\r\n",
        "\r\n",
        "train_x, test_x, train_y, test_y = train_test_split(stcs, labels, test_size= 0.2, shuffle= True, random_state= 42)\r\n",
        "print('training size: {}'.format(len(train_x)))\r\n",
        "print('test size: {}'.format(len(test_x)))\r\n",
        "print('test gt tags unique數 :{}'.format(len(set([tag for label in test_y for tag in label]))))\r\n",
        "\r\n",
        "train_dataset = bert_stc_dataset(stcs= train_x, labels= train_y, tokenizer= tokenizer, max_length= max_length)\r\n",
        "# print('train stcs ',train_x[0:3])\r\n",
        "# print(train_dataset[0:3]['input_ids'])\r\n",
        "# print(train_dataset[0:3]['labels'])\r\n",
        "test_dataset = bert_stc_dataset(stcs= test_x, labels= test_y, tokenizer= tokenizer, max_length= max_length)\r\n",
        "\r\n",
        "# print('training stcs 總數: {}'.format(len(train_dataset)))\r\n",
        "train_dataloader = DataLoader(train_dataset, batch_size= batchsize, shuffle= True, num_workers= 4)\r\n",
        "test_dataloader = DataLoader(test_dataset, batch_size= batchsize, shuffle= False, num_workers= 4)\r\n",
        "\r\n",
        "num_iteration = len(train_dataloader)\r\n",
        "print('num_iteration',num_iteration)\r\n",
        "total_iter = num_iteration * num_epochs\r\n",
        "warmup = total_iter * warmup_ratio\r\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = lr, weight_decay= weight_decay)\r\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps= warmup, num_training_steps=total_iter)\r\n",
        "# warmup_scheduler = warmup.ExponentialWarmup(optimizer, warmup_period=150)\r\n",
        "\r\n",
        "# ---------------訓練---------------\r\n",
        "# train_model = train(model= model, optimizer= optimizer, train_loader= train_dataloader, test_loader= 0, num_epochs= 5, device= device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training size: 2590\n",
            "test size: 648\n",
            "test gt tags unique數 :19\n",
            "num_iteration 81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPf2heKjCd7"
      },
      "source": [
        "# test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfjiko8GjBZD"
      },
      "source": [
        "def test(model, test_dataloader, device):\r\n",
        "\r\n",
        "  preds_epoch = []\r\n",
        "  gts_epoch = []\r\n",
        "  epoch_loss = 0\r\n",
        "  iteration = 0\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  for idx, batch_dict in enumerate(test_dataloader):\r\n",
        "\r\n",
        "    # print('idx: ',idx+1)\r\n",
        "    input_ids = batch_dict['input_ids'].to(device)\r\n",
        "    attention_mask = batch_dict['attention_mask'].to(device)\r\n",
        "    labels = batch_dict['labels'].to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      loss, pred_labels = model(input_ids, attention_mask.bool(), labels)\r\n",
        "\r\n",
        "    # mask gt labels \r\n",
        "    labels = batch_dict['labels'].numpy()\r\n",
        "    masks = batch_dict['attention_mask'].numpy()\r\n",
        "\r\n",
        "    labels_nopad = []\r\n",
        "    for label , seq_mask in zip(labels, masks):\r\n",
        "\r\n",
        "      seq = [tag for tag, mask in zip(label, seq_mask) if mask == 1]\r\n",
        "      labels_nopad.append(seq)\r\n",
        "\r\n",
        "    # one dim array \r\n",
        "    preds= [tag for seq in pred_labels for tag in seq]\r\n",
        "    gts= [tag for seq in labels_nopad for tag in seq]\r\n",
        "\r\n",
        "    preds_epoch += preds\r\n",
        "    gts_epoch += gts\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    iteration += 1\r\n",
        "\r\n",
        "  target_names = sorted([id for id in set(gts_epoch).union(set(preds_epoch))], reverse= False)\r\n",
        "  target_names = [id2tag_dict[id] for id in target_names]\r\n",
        "  f1_macro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'macro')\r\n",
        "  f1_micro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'micro')\r\n",
        "  f1 = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= None)\r\n",
        "  print(classification_report(y_true= gts_epoch, y_pred= preds_epoch, target_names= target_names))\r\n",
        "  \r\n",
        "  avg_loss = epoch_loss / iteration\r\n",
        "\r\n",
        "  print('gt tag unique 數: {}'.format(len(set(gts_epoch))))\r\n",
        "  print('pred tag unique 數: {}'.format(len(set(preds_epoch))))\r\n",
        "  print('test_f1(macro, micro) ({:.2f},{:.2f}) | test_avg_loss {:.3f} | f1 for each class\\n{}\\n'.format(f1_macro, f1_micro, avg_loss, f1))\r\n",
        "\r\n",
        "  return f1_macro, f1_micro, avg_loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NSLpK9g7bp5"
      },
      "source": [
        "# test out function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2yAR0_67gGZ"
      },
      "source": [
        "class test_output():\r\n",
        "\tdef __init__(self, data, model, tokenizer, batch_size):\r\n",
        "\r\n",
        "\t\tself.model = model\r\n",
        "\t\tself.model.eval()\r\n",
        "\t\tself.tokenizer = tokenizer\r\n",
        "\t\tself.batch_size = batch_size\r\n",
        "\t\tself.data_list = []\r\n",
        "\t\tself.word_id = []\r\n",
        "\t\tself.word_article_id = [] \r\n",
        "\t\tarticle_id = 0\r\n",
        "\t\tword_id = 0\r\n",
        "\t\tdata_list_tmp = []\r\n",
        "\t\tarticle_id_tmp = []\r\n",
        "\t\tword_id_tmp = []\r\n",
        "\t\t\r\n",
        "\t\tfor row in data:\r\n",
        "\t\t\t\r\n",
        "\t\t\tdata_tuple = tuple()\r\n",
        "\t\t\tif row == '\\n':\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\tarticle_id += 1 \r\n",
        "\t\t\t\tword_id = 0\r\n",
        "\r\n",
        "\t\t\t\tif len(data_list_tmp) != 0:\r\n",
        "\r\n",
        "\t\t\t\t\tself.word_id.append(word_id_tmp)\r\n",
        "\t\t\t\t\tself.word_article_id.append(article_id_tmp)\r\n",
        "\t\t\t\t\tself.data_list.append(data_list_tmp)\r\n",
        "\t\t\t\tdata_list_tmp = []\r\n",
        "\t\t\t\tarticle_id_tmp = []\r\n",
        "\t\t\t\tword_id_tmp = []\r\n",
        "\r\n",
        "\t\t\telse:\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\trow = row.strip('\\n').split(' ')\r\n",
        "\r\n",
        "\t\t\t\t# if (row[0] in ['，', '：']) & (len(data_list_tmp) > 136):\r\n",
        "\t\t\t\t# \tself.word_id.append(word_id_tmp)\r\n",
        "\t\t\t\t# \tself.word_article_id.append(article_id_tmp)\r\n",
        "\t\t\t\t# \tself.data_list.append(data_list_tmp)\r\n",
        "\t\t\t\t# \tdata_list_tmp = []\r\n",
        "\t\t\t\t# \tarticle_id_tmp = []\r\n",
        "\t\t\t\t# \tword_id_tmp = []\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\tif (row[0] in ['。', '？','！','～','‧','，', '：']) & (len(data_list_tmp) > 128):\r\n",
        "\t\t\t\t\t\r\n",
        "\t\t\t\t\tself.word_id.append(word_id_tmp)\r\n",
        "\t\t\t\t\tself.word_article_id.append(article_id_tmp)\r\n",
        "\t\t\t\t\tself.data_list.append(data_list_tmp)\r\n",
        "\t\t\t\t\tdata_list_tmp = []\r\n",
        "\t\t\t\t\tarticle_id_tmp = []\r\n",
        "\t\t\t\t\tword_id_tmp = []\r\n",
        "\t\t\t\t\t\r\n",
        "\t\t\t\telif row[0] in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']:\r\n",
        "\t\t\t\t\t  \r\n",
        "\t\t\t\t\tdata_tuple = (row[0].lower(), article_id, word_id)\r\n",
        "\t\t\t\t\tdata_list_tmp.append(data_tuple)\r\n",
        "\t\t\t\t\tarticle_id_tmp.append(article_id)\r\n",
        "\t\t\t\t\tword_id_tmp.append(word_id)\r\n",
        "\r\n",
        "\t\t\t\telse: #row[0] not in ['欸','喔','诶','摁','嗯','齁','嗎','嘿','哦','？','！','。', '～', '：']:\r\n",
        "\t\t\t\t\t\r\n",
        "\t\t\t\t\tdata_tuple = (row[0], article_id, word_id)\r\n",
        "\t\t\t\t\tdata_list_tmp.append(data_tuple)\r\n",
        "\t\t\t\t\tarticle_id_tmp.append(article_id)\r\n",
        "\t\t\t\t\tword_id_tmp.append(word_id)\r\n",
        "\t\t\t\t\t\r\n",
        "\t\t\t\tword_id += 1\r\n",
        "\t\t\t\t\r\n",
        "\t\tif len(data_list_tmp) != 0:\r\n",
        "\t\t\tself.data_list.append(data_list_tmp)\r\n",
        "\t\t\tself.word_id.append(word_id_tmp)\r\n",
        "\t\t\tself.word_article_id.append(article_id_tmp)\r\n",
        "\t\tmax_len = len(max(self.data_list, key= len))\r\n",
        "\t\tprint('max_len: ', max_len)\r\n",
        "  \r\n",
        "\tdef raw_output(self):\r\n",
        "\t\treturn self.data_list, self.word_id, self.word_article_id\r\n",
        "\r\n",
        "\tdef get_stcs(self):\r\n",
        "\t\t\r\n",
        "\t\tall_stcs = list()\r\n",
        "\t\tall_article_ids = list()\r\n",
        "\t\tall_word_ids = list()\r\n",
        "\r\n",
        "\t\tfor idx, stc_list in enumerate(self.data_list):\r\n",
        "\r\n",
        "\t\t\ttxt_len = len(stc_list) #(文章數，每個文章對應的總字數) (word, label)\r\n",
        "\t\t\tstc = str() #存字數= max_stc_len的字串\r\n",
        "\t\t\tarticle_ids = []\r\n",
        "\t\t\tword_ids = []\r\n",
        "\t\t\t\r\n",
        "\r\n",
        "\t\t\tfor i, (word,article_id, word_id) in enumerate(stc_list):\r\n",
        "\r\n",
        "\t\t\t\tstc += word\r\n",
        "\t\t\t\tarticle_ids.append(article_id)\r\n",
        "\t\t\t\tword_ids.append(word_id)\r\n",
        "\r\n",
        "\t\t\tif len(stc) > 0:\r\n",
        "\t\t\t\tall_stcs.append(stc)\r\n",
        "\t\t\t\tall_article_ids.append(article_ids)\r\n",
        "\t\t\t\tall_word_ids.append(word_ids)\r\n",
        "\r\n",
        "\t\t\telse: \r\n",
        "\t\t\t\tprint(stc)\r\n",
        "\t\t\t\tprint(idx)\r\n",
        "\t\t\t\tprint(article_ids)\r\n",
        "\t\t\t\tprint(word_ids)\r\n",
        "\t\t\t\tprint('stc len = 0')\r\n",
        "\t\tassert len(all_stcs) > 0, 'all stcs len = 0' \r\n",
        "\t\t\r\n",
        "\t\treturn all_stcs, all_article_ids, all_word_ids\r\n",
        "\r\n",
        "\tdef encoding(self):\r\n",
        "    \r\n",
        "\t\tclean_stcs, _, _ = self.get_stcs()\r\n",
        "\t\tmax_len = len(max(clean_stcs, key= len))\r\n",
        "\r\n",
        "\t\tclean_stcs = [' '.join(list(stc)) for stc in clean_stcs]\r\n",
        "\r\n",
        "        encoding = self.tokenizer.batch_encode_plus(clean_stcs, \r\n",
        "\t\t\tpadding=True,\r\n",
        "\t\t\tadd_special_tokens=False,\r\n",
        "\t\t\treturn_attention_mask= True,\r\n",
        "\t\t\treturn_token_type_ids= False,\r\n",
        "\t\t\t#  is_split_into_words=True,\r\n",
        "\t\t\treturn_tensors='pt')\r\n",
        "\r\n",
        "\t\t# batch_size= 32\r\n",
        "\t\tpred_labels = []\r\n",
        "        \r\n",
        "\t\tself.model.eval()\r\n",
        "\t\tfor idx in range(int((len(clean_stcs)/self.batch_size))):\r\n",
        "\t\t\tinput= encoding['input_ids'][idx*self.batch_size:(idx+1)*self.batch_size].to(device)\r\n",
        "\t\t\tmask = encoding['attention_mask'][idx*self.batch_size:(idx+1)*self.batch_size].to(device)\r\n",
        "\t\t\ttags= torch.zeros((input.size(0),input.size(1)), dtype=torch.long).to(device)\r\n",
        "\t\t\twith torch.no_grad():\r\n",
        "\t\t\t\t_, preds = self.model(input, mask, tags)\r\n",
        "\t\t\tfor pred in preds:\r\n",
        "\t\t\t\tpred_labels.append(pred)\r\n",
        "\r\n",
        "\t\tif (len(clean_stcs) % self.batch_size) != 0:\r\n",
        "\t\t\tidx = int((len(clean_stcs)/self.batch_size))\r\n",
        "\t\t\tinput= encoding['input_ids'][idx*self.batch_size:].to(device)\r\n",
        "\t\t\tmask = encoding['attention_mask'][idx*self.batch_size:].to(device)\r\n",
        "\t\t\ttags= torch.zeros((input.size(0),input.size(1)), dtype=torch.long).to(device)\r\n",
        "\t\t\twith torch.no_grad():\r\n",
        "\t\t\t\t_, preds = self.model(input, mask, tags)\r\n",
        "\t\t\tfor pred in preds:\r\n",
        "\t\t\t\tpred_labels.append(pred)\r\n",
        "\r\n",
        "\t\ttag2id = {'B-ID': 0, 'B-clinical_event': 1, 'B-contact': 2, 'B-education': 3, 'B-family': 4, 'B-location': 5, 'B-med_exam': 6, 'B-money': 7, 'B-name': 8, 'B-organization': 9, 'B-others': 10, 'B-profession': 11, 'B-time': 12, 'I-ID': 13, 'I-clinical_event': 14, 'I-contact': 15, 'I-education': 16, 'I-family': 17, 'I-location': 18, 'I-med_exam': 19, 'I-money': 20, 'I-name': 21, 'I-organization': 22, 'I-others': 23, 'I-profession': 24, 'I-time': 25, 'O': 26}\r\n",
        "\t\tid2tag ={v:k for k, v in tag2id.items()}\r\n",
        "\r\n",
        "\t\tself.pred_labels_tag = []\r\n",
        "\t\tfor stc, label in zip(clean_stcs, pred_labels):\r\n",
        "\t\t\t# print(stc)\r\n",
        "\t\t\t# print(label)\r\n",
        "\t\t\tstc_label = [id2tag[id] for id in label]\r\n",
        "\t\t\tself.pred_labels_tag.append(stc_label)\r\n",
        "\r\n",
        "\t\treturn self.pred_labels_tag\r\n",
        "\r\n",
        "\tdef pred_out_tsv(self, pred_labels_tag):\r\n",
        "\t\t\r\n",
        "\t\tclean_stcs, clean_article_id, clean_word_id = self.get_stcs()\r\n",
        "\t\t# pred_labels_tag = self.encoding()\r\n",
        "\r\n",
        "\t\tentity_text = []\r\n",
        "\r\n",
        "\t\tfor stc, labels, article_id, word_id in zip(clean_stcs, pred_labels_tag, clean_article_id, clean_word_id):\r\n",
        "\r\n",
        "\t\t\tentity = str()\r\n",
        "\t\t\tstart_pos = 0\r\n",
        "\t\t\tend_pos = 0\r\n",
        "\t\t\tarticle = 0\r\n",
        "\t\t\tentity_type = str()\r\n",
        "\t\t\tpointer = 0\r\n",
        "\r\n",
        "\t\t\tfor idx, label in enumerate(labels):\r\n",
        "\r\n",
        "\t\t\t\tif bool(re.match(r'B-', label)):\r\n",
        "\r\n",
        "\t\t\t\t\tentity = list(stc)[idx]\r\n",
        "\t\t\t\t\tstart_pos = word_id[idx]\r\n",
        "\t\t\t\t\tarticle = article_id[idx]\r\n",
        "\t\t\t\t\tentity_type = label.split('B-')[1]\r\n",
        "\t\t\t\t\tpointer = idx\r\n",
        "\r\n",
        "\t\t\t\telif bool(re.match(r'I-', label)):\r\n",
        "\t\t\t\t\tif (idx - pointer) == 1:\r\n",
        "\t\t\t\t\t\tentity += list(stc)[idx]\r\n",
        "\t\t\t\t\t\tend_pos= word_id[idx]+1\r\n",
        "\t\t\t\t\t\ttry:\r\n",
        "\t\t\t\t\t\t\tif ((labels[idx+1] == 'O')|(bool(re.match(r'B-', labels[idx+1])))) & (entity_type!=''):\r\n",
        "\t\t\t\t\t\t\t\tentity_text.append((article, start_pos, end_pos, entity, entity_type))\r\n",
        "\t\t\t\t\t\t\t\tentity = str()\r\n",
        "\t\t\t\t\t\t\t\tstart_pos = 0\r\n",
        "\t\t\t\t\t\t\t\tend_pos = 0\r\n",
        "\t\t\t\t\t\t\t\tarticle = 0\r\n",
        "\t\t\t\t\t\t\t\tentity_type = str()\r\n",
        "\t\t\t\t\t\t\telif bool(re.match(r'I-', labels[idx+1])):\r\n",
        "\t\t\t\t\t\t\t\tpointer= idx\r\n",
        "\t\t\t\t\t\texcept:\r\n",
        "\t\t\t\t\t\t\tpass\r\n",
        "\r\n",
        "\t\twith open('test_output.tsv', 'w', encoding='utf-8',newline='\\n') as f:\r\n",
        "\t\t\twriter = csv.writer(f, delimiter='\\t')\r\n",
        "\t\t\twriter.writerow(['article_id','start_position', 'end_position', 'entity_text', 'entity_type'])\r\n",
        "\t\t\tfor (article, start_pos, end_pos, entity, entity_type) in entity_text:\r\n",
        "\t\t\t\twriter.writerow([str(article), str(start_pos), str(end_pos), str(entity), str(entity_type)])\r\n",
        "\r\n",
        "\t\treturn entity_text\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTZoeeJLtl9K"
      },
      "source": [
        "# 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyZYZVdJhxFa",
        "outputId": "4dbcbabd-02ce-4987-bcc4-24f2c3d1e86b"
      },
      "source": [
        "train_loss = {}\r\n",
        "test_loss = {}\r\n",
        "train_f1 = {}\r\n",
        "test_f1 = {}\r\n",
        "stop_epoch = 0\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "\r\n",
        "  preds_epoch = []\r\n",
        "  gts_epoch = []\r\n",
        "  epoch_loss = 0\r\n",
        "  iteration = 0\r\n",
        "  st = time.time()\r\n",
        "\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  for idx, batch_dict in enumerate(train_dataloader):\r\n",
        "\r\n",
        "    # print('idx: ',idx+1)\r\n",
        "    input_ids = batch_dict['input_ids'].to(device)\r\n",
        "    attention_mask = batch_dict['attention_mask'].to(device)\r\n",
        "    labels = batch_dict['labels'].to(device)\r\n",
        "\r\n",
        "    loss, pred_labels = model(input_ids, attention_mask.bool(), labels)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "    scheduler.step()\r\n",
        "    model.zero_grad()\r\n",
        "\r\n",
        "    # mask gt labels \r\n",
        "    labels = batch_dict['labels'].numpy()\r\n",
        "    masks = batch_dict['attention_mask'].numpy()\r\n",
        "\r\n",
        "    labels_nopad = []\r\n",
        "    for label , seq_mask in zip(labels, masks):\r\n",
        "\r\n",
        "        seq = [tag for tag, mask in zip(label, seq_mask) if mask == 1]\r\n",
        "        labels_nopad.append(seq)\r\n",
        "\r\n",
        "    # one dim array \r\n",
        "    preds= [tag for seq in pred_labels for tag in seq]\r\n",
        "    gts= [tag for seq in labels_nopad for tag in seq]\r\n",
        "\r\n",
        "    preds_epoch += preds\r\n",
        "    gts_epoch += gts\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    iteration += 1\r\n",
        "\r\n",
        "  target_names = sorted([id for id in set(gts_epoch).union(set(preds_epoch))], reverse= False)\r\n",
        "  target_names = [id2tag_dict[id] for id in target_names]\r\n",
        "  f1_macro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'macro')\r\n",
        "  f1_micro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'micro')\r\n",
        "  f1 = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= None)\r\n",
        "  print(classification_report(y_true= gts_epoch, y_pred= preds_epoch, target_names= target_names))\r\n",
        "  \r\n",
        "  avg_loss = epoch_loss / iteration\r\n",
        "  stop_epoch = epoch+1\r\n",
        "  en = time.time()\r\n",
        "  \r\n",
        "  print('training time :{:.2f}'.format(en-st))\r\n",
        "  print('epoch {}/{} | train_f1(macro, micro) ({:.2f},{:.2f}) | train_epoch_avg_loss {:.3f}| f1 for each class \\n{}\\n'.format(epoch+1, num_epochs, f1_macro, f1_micro, avg_loss, f1))\r\n",
        "\r\n",
        "  test_f1_macro, test_f1_micro, test_avg_loss = test(model= model, test_dataloader= test_dataloader, device= device)\r\n",
        "\r\n",
        "  train_loss[epoch+1] = avg_loss\r\n",
        "  test_loss[epoch+1] = test_avg_loss\r\n",
        "  train_f1[epoch+1] = f1_macro\r\n",
        "  test_f1[epoch+1] = test_f1_macro\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.00      0.05      0.00        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.00      0.02      0.00        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.00      0.03      0.00        32\n",
            "      B-location       0.00      0.01      0.00       223\n",
            "      B-med_exam       0.00      0.01      0.00       329\n",
            "         B-money       0.00      0.01      0.00        95\n",
            "          B-name       0.00      0.03      0.00       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.00      0.03      0.00        33\n",
            "          B-time       0.00      0.02      0.01      2031\n",
            "            I-ID       0.00      0.11      0.00        64\n",
            "I-clinical_event       0.00      0.07      0.00        15\n",
            "       I-contact       0.00      0.03      0.00       198\n",
            "     I-education       0.00      0.00      0.00         8\n",
            "        I-family       0.00      0.06      0.00        34\n",
            "      I-location       0.00      0.02      0.00       346\n",
            "      I-med_exam       0.00      0.01      0.01       638\n",
            "         I-money       0.00      0.01      0.00       236\n",
            "          I-name       0.00      0.01      0.00       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.00      0.07      0.00        73\n",
            "          I-time       0.01      0.06      0.02      4414\n",
            "               O       0.97      0.46      0.62    322493\n",
            "\n",
            "        accuracy                           0.45    331933\n",
            "       macro avg       0.04      0.04      0.03    331933\n",
            "    weighted avg       0.95      0.45      0.61    331933\n",
            "\n",
            "training time :108.88\n",
            "epoch 1/20 | train_f1(macro, micro) (0.03,0.45) | train_epoch_avg_loss 761.719| f1 for each class \n",
            "[3.29978551e-04 0.00000000e+00 6.65114732e-04 0.00000000e+00\n",
            " 2.51698968e-04 3.80916103e-04 1.90885230e-03 5.68828214e-04\n",
            " 1.41757797e-03 0.00000000e+00 0.00000000e+00 1.53964588e-03\n",
            " 7.69368402e-03 1.12803158e-03 4.04858300e-04 1.31613583e-03\n",
            " 0.00000000e+00 2.39736290e-04 1.83462194e-03 5.25106662e-03\n",
            " 1.51937199e-03 9.38086304e-04 0.00000000e+00 0.00000000e+00\n",
            " 1.35263087e-03 2.33813752e-02 6.23299608e-01]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.00      0.00      0.00         0\n",
            "B-clinical_event       0.00      0.00      0.00         0\n",
            "       B-contact       0.00      0.00      0.00         5\n",
            "     B-education       0.00      0.00      0.00         1\n",
            "        B-family       0.00      0.00      0.00        18\n",
            "      B-location       0.00      0.00      0.00        54\n",
            "      B-med_exam       0.00      0.00      0.00       114\n",
            "         B-money       0.00      0.00      0.00        31\n",
            "          B-name       0.00      0.00      0.00        72\n",
            "  B-organization       0.00      0.00      0.00         0\n",
            "        B-others       0.00      0.00      0.00         0\n",
            "    B-profession       0.00      0.00      0.00         9\n",
            "          B-time       0.00      0.00      0.00       494\n",
            "            I-ID       0.00      0.00      0.00         0\n",
            "I-clinical_event       0.00      0.00      0.00         0\n",
            "       I-contact       0.00      0.00      0.00        18\n",
            "     I-education       0.00      0.00      0.00         4\n",
            "        I-family       0.00      0.00      0.00        21\n",
            "      I-location       0.00      0.00      0.00        76\n",
            "      I-med_exam       0.00      0.00      0.00       215\n",
            "         I-money       0.00      0.00      0.00        77\n",
            "          I-name       0.00      0.00      0.00       131\n",
            "  I-organization       0.00      0.00      0.00         0\n",
            "        I-others       0.00      0.00      0.00         0\n",
            "    I-profession       0.00      0.00      0.00        14\n",
            "          I-time       0.04      0.01      0.01      1078\n",
            "               O       0.97      0.98      0.97     80844\n",
            "\n",
            "        accuracy                           0.95     83276\n",
            "       macro avg       0.04      0.04      0.04     83276\n",
            "    weighted avg       0.94      0.95      0.95     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 27\n",
            "test_f1(macro, micro) (0.04,0.95) | test_avg_loss 72.237 | f1 for each class\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.00966962 0.97468775]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.00      0.00      0.00        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.00      0.00      0.00        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.00      0.00      0.00        32\n",
            "      B-location       0.00      0.01      0.01       223\n",
            "      B-med_exam       0.01      0.04      0.02       329\n",
            "         B-money       0.00      0.00      0.00        95\n",
            "          B-name       0.00      0.00      0.00       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.00      0.00      0.00        33\n",
            "          B-time       0.14      0.14      0.14      2031\n",
            "            I-ID       0.00      0.02      0.00        64\n",
            "I-clinical_event       0.00      0.00      0.00        15\n",
            "       I-contact       0.00      0.01      0.00       198\n",
            "     I-education       0.00      0.00      0.00         8\n",
            "        I-family       0.00      0.00      0.00        34\n",
            "      I-location       0.00      0.01      0.00       346\n",
            "      I-med_exam       0.07      0.08      0.08       638\n",
            "         I-money       0.00      0.00      0.00       236\n",
            "          I-name       0.00      0.01      0.00       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.00      0.00      0.00        73\n",
            "          I-time       0.29      0.31      0.30      4414\n",
            "               O       0.98      0.94      0.96    322493\n",
            "\n",
            "        accuracy                           0.92    331933\n",
            "       macro avg       0.06      0.06      0.06    331933\n",
            "    weighted avg       0.96      0.92      0.94    331933\n",
            "\n",
            "training time :116.75\n",
            "epoch 2/20 | train_f1(macro, micro) (0.06,0.92) | train_epoch_avg_loss 81.696| f1 for each class \n",
            "[0.         0.         0.         0.         0.         0.00604839\n",
            " 0.02093398 0.         0.00225225 0.         0.         0.\n",
            " 0.13864734 0.0021254  0.         0.0025413  0.         0.\n",
            " 0.00422386 0.07568325 0.00240096 0.00387597 0.         0.\n",
            " 0.         0.29778805 0.9606936 ]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.00      0.00      0.00         0\n",
            "B-clinical_event       0.00      0.00      0.00         0\n",
            "       B-contact       0.00      0.00      0.00         5\n",
            "     B-education       0.00      0.00      0.00         1\n",
            "        B-family       0.00      0.00      0.00        18\n",
            "      B-location       0.00      0.00      0.00        54\n",
            "      B-med_exam       0.44      0.35      0.39       114\n",
            "         B-money       0.00      0.00      0.00        31\n",
            "          B-name       0.00      0.00      0.00        72\n",
            "  B-organization       0.00      0.00      0.00         0\n",
            "        B-others       0.00      0.00      0.00         0\n",
            "    B-profession       0.00      0.00      0.00         9\n",
            "          B-time       0.53      0.68      0.59       494\n",
            "            I-ID       0.00      0.00      0.00         0\n",
            "I-clinical_event       0.00      0.00      0.00         0\n",
            "       I-contact       0.00      0.00      0.00        18\n",
            "     I-education       0.00      0.00      0.00         4\n",
            "        I-family       0.00      0.00      0.00        21\n",
            "      I-location       0.00      0.00      0.00        76\n",
            "      I-med_exam       0.63      0.68      0.65       215\n",
            "         I-money       0.00      0.00      0.00        77\n",
            "          I-name       0.00      0.00      0.00       131\n",
            "  I-organization       0.00      0.00      0.00         0\n",
            "        I-others       0.00      0.00      0.00         0\n",
            "    I-profession       0.00      0.00      0.00        14\n",
            "          I-time       0.70      0.72      0.71      1078\n",
            "               O       0.99      0.99      0.99     80844\n",
            "\n",
            "        accuracy                           0.97     83276\n",
            "       macro avg       0.12      0.13      0.12     83276\n",
            "    weighted avg       0.97      0.97      0.97     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 27\n",
            "test_f1(macro, micro) (0.12,0.97) | test_avg_loss 19.585 | f1 for each class\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.3902439  0.         0.         0.         0.         0.\n",
            " 0.59167405 0.         0.         0.         0.         0.\n",
            " 0.         0.65470852 0.         0.         0.         0.\n",
            " 0.         0.71395881 0.98719631]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.00      0.00      0.00        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.00      0.00      0.00        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.00      0.00      0.00        32\n",
            "      B-location       0.15      0.25      0.19       223\n",
            "      B-med_exam       0.20      0.33      0.25       329\n",
            "         B-money       0.03      0.07      0.04        95\n",
            "          B-name       0.11      0.19      0.14       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.00      0.00      0.00        33\n",
            "          B-time       0.53      0.55      0.54      2031\n",
            "            I-ID       0.00      0.00      0.00        64\n",
            "I-clinical_event       0.00      0.00      0.00        15\n",
            "       I-contact       0.06      0.10      0.08       198\n",
            "     I-education       0.00      0.00      0.00         8\n",
            "        I-family       0.00      0.00      0.00        34\n",
            "      I-location       0.28      0.35      0.31       346\n",
            "      I-med_exam       0.39      0.45      0.42       638\n",
            "         I-money       0.15      0.20      0.17       236\n",
            "          I-name       0.25      0.45      0.32       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.00      0.01      0.01        73\n",
            "          I-time       0.67      0.71      0.69      4414\n",
            "               O       0.99      0.98      0.99    322493\n",
            "\n",
            "        accuracy                           0.97    331933\n",
            "       macro avg       0.14      0.17      0.15    331933\n",
            "    weighted avg       0.98      0.97      0.97    331933\n",
            "\n",
            "training time :116.57\n",
            "epoch 3/20 | train_f1(macro, micro) (0.15,0.97) | train_epoch_avg_loss 26.091| f1 for each class \n",
            "[0.         0.         0.         0.         0.         0.18635607\n",
            " 0.24913495 0.04093567 0.13854352 0.         0.         0.\n",
            " 0.53678606 0.         0.         0.07575758 0.         0.\n",
            " 0.3126615  0.41793203 0.17090909 0.32463768 0.         0.\n",
            " 0.00682594 0.68699276 0.98503029]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "B-clinical_event       0.00      0.00      0.00         0\n",
            "       B-contact       0.00      0.00      0.00         5\n",
            "     B-education       0.00      0.00      0.00         1\n",
            "        B-family       0.00      0.00      0.00        18\n",
            "      B-location       0.95      0.72      0.82        54\n",
            "      B-med_exam       0.87      0.36      0.51       114\n",
            "         B-money       0.00      0.00      0.00        31\n",
            "          B-name       0.80      0.54      0.64        72\n",
            "  B-organization       0.00      0.00      0.00         0\n",
            "        B-others       0.00      0.00      0.00         0\n",
            "    B-profession       0.00      0.00      0.00         9\n",
            "          B-time       0.67      0.81      0.73       494\n",
            "            I-ID       0.00      0.00      0.00         0\n",
            "I-clinical_event       0.00      0.00      0.00         0\n",
            "       I-contact       0.00      0.00      0.00        18\n",
            "     I-education       0.00      0.00      0.00         4\n",
            "        I-family       0.00      0.00      0.00        21\n",
            "      I-location       0.94      0.62      0.75        76\n",
            "      I-med_exam       0.79      0.56      0.65       215\n",
            "         I-money       0.75      0.19      0.31        77\n",
            "          I-name       0.81      0.60      0.69       131\n",
            "  I-organization       0.00      0.00      0.00         0\n",
            "    I-profession       0.00      0.00      0.00        14\n",
            "          I-time       0.72      0.84      0.78      1078\n",
            "               O       0.99      0.99      0.99     80844\n",
            "\n",
            "        accuracy                           0.98     83276\n",
            "       macro avg       0.33      0.25      0.28     83276\n",
            "    weighted avg       0.98      0.98      0.98     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 22\n",
            "test_f1(macro, micro) (0.28,0.98) | test_avg_loss 10.329 | f1 for each class\n",
            "[0.         0.         0.         0.         0.82105263 0.50931677\n",
            " 0.         0.6446281  0.         0.         0.         0.73242009\n",
            " 0.         0.         0.         0.         0.         0.74603175\n",
            " 0.65395095 0.30927835 0.69298246 0.         0.         0.77640017\n",
            " 0.99207546]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.00      0.00      0.00        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.00      0.00      0.00        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.01      0.03      0.02        32\n",
            "      B-location       0.56      0.65      0.61       223\n",
            "      B-med_exam       0.48      0.53      0.50       329\n",
            "         B-money       0.18      0.21      0.19        95\n",
            "          B-name       0.50      0.54      0.52       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.00      0.00      0.00        33\n",
            "          B-time       0.69      0.70      0.69      2031\n",
            "            I-ID       0.05      0.08      0.06        64\n",
            "I-clinical_event       0.00      0.00      0.00        15\n",
            "       I-contact       0.19      0.15      0.17       198\n",
            "     I-education       0.00      0.00      0.00         8\n",
            "        I-family       0.01      0.03      0.02        34\n",
            "      I-location       0.70      0.71      0.71       346\n",
            "      I-med_exam       0.67      0.66      0.66       638\n",
            "         I-money       0.34      0.39      0.37       236\n",
            "          I-name       0.60      0.72      0.66       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.03      0.03      0.03        73\n",
            "          I-time       0.77      0.77      0.77      4414\n",
            "               O       0.99      0.99      0.99    322493\n",
            "\n",
            "        accuracy                           0.98    331933\n",
            "       macro avg       0.25      0.27      0.26    331933\n",
            "    weighted avg       0.98      0.98      0.98    331933\n",
            "\n",
            "training time :116.32\n",
            "epoch 4/20 | train_f1(macro, micro) (0.26,0.98) | train_epoch_avg_loss 11.888| f1 for each class \n",
            "[0.         0.         0.         0.         0.01652893 0.60580913\n",
            " 0.50144092 0.19417476 0.51972158 0.         0.         0.\n",
            " 0.6932814  0.05952381 0.         0.16901408 0.         0.01666667\n",
            " 0.70503597 0.66246057 0.36686391 0.65525672 0.         0.\n",
            " 0.02614379 0.76910936 0.99220816]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "B-clinical_event       0.00      0.00      0.00         0\n",
            "       B-contact       0.00      0.00      0.00         5\n",
            "     B-education       0.00      0.00      0.00         1\n",
            "        B-family       0.00      0.00      0.00        18\n",
            "      B-location       0.85      0.20      0.33        54\n",
            "      B-med_exam       0.80      0.80      0.80       114\n",
            "         B-money       0.62      0.65      0.63        31\n",
            "          B-name       0.77      0.69      0.73        72\n",
            "        B-others       0.00      0.00      0.00         0\n",
            "    B-profession       0.00      0.00      0.00         9\n",
            "          B-time       0.71      0.74      0.73       494\n",
            "            I-ID       0.00      0.00      0.00         0\n",
            "       I-contact       0.00      0.00      0.00        18\n",
            "     I-education       0.00      0.00      0.00         4\n",
            "        I-family       0.00      0.00      0.00        21\n",
            "      I-location       0.89      0.42      0.57        76\n",
            "      I-med_exam       0.74      0.85      0.79       215\n",
            "         I-money       0.80      0.36      0.50        77\n",
            "          I-name       0.69      0.73      0.71       131\n",
            "        I-others       0.00      0.00      0.00         0\n",
            "    I-profession       0.00      0.00      0.00        14\n",
            "          I-time       0.81      0.76      0.78      1078\n",
            "               O       0.99      0.99      0.99     80844\n",
            "\n",
            "        accuracy                           0.99     83276\n",
            "       macro avg       0.38      0.31      0.33     83276\n",
            "    weighted avg       0.98      0.99      0.98     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 21\n",
            "test_f1(macro, micro) (0.33,0.99) | test_avg_loss 9.914 | f1 for each class\n",
            "[0.         0.         0.         0.         0.32835821 0.79824561\n",
            " 0.63492063 0.72992701 0.         0.         0.72512315 0.\n",
            " 0.         0.         0.         0.57142857 0.79049676 0.5\n",
            " 0.70848708 0.         0.         0.78219244 0.9930928 ]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.03      0.05      0.04        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.17      0.19      0.18        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.17      0.28      0.21        32\n",
            "      B-location       0.74      0.79      0.77       223\n",
            "      B-med_exam       0.65      0.71      0.68       329\n",
            "         B-money       0.35      0.42      0.38        95\n",
            "          B-name       0.69      0.69      0.69       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.00      0.00      0.00        33\n",
            "          B-time       0.75      0.76      0.76      2031\n",
            "            I-ID       0.04      0.03      0.03        64\n",
            "I-clinical_event       0.00      0.00      0.00        15\n",
            "       I-contact       0.35      0.30      0.32       198\n",
            "     I-education       0.00      0.00      0.00         8\n",
            "        I-family       0.15      0.21      0.17        34\n",
            "      I-location       0.81      0.78      0.80       346\n",
            "      I-med_exam       0.74      0.75      0.74       638\n",
            "         I-money       0.54      0.55      0.54       236\n",
            "          I-name       0.72      0.79      0.75       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.12      0.07      0.09        73\n",
            "          I-time       0.82      0.82      0.82      4414\n",
            "               O       0.99      0.99      0.99    322493\n",
            "\n",
            "        accuracy                           0.99    331933\n",
            "       macro avg       0.33      0.34      0.33    331933\n",
            "    weighted avg       0.99      0.99      0.99    331933\n",
            "\n",
            "training time :115.83\n",
            "epoch 5/20 | train_f1(macro, micro) (0.33,0.99) | train_epoch_avg_loss 7.712| f1 for each class \n",
            "[0.04       0.         0.18181818 0.         0.21176471 0.76623377\n",
            " 0.67919075 0.38277512 0.68915663 0.         0.         0.\n",
            " 0.75750916 0.03333333 0.         0.32065217 0.         0.17073171\n",
            " 0.79528719 0.74476338 0.5408805  0.75318066 0.         0.\n",
            " 0.08695652 0.8171215  0.99445092]\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          B-ID       0.00      0.00      0.00         0\n",
            "     B-contact       1.00      0.20      0.33         5\n",
            "   B-education       0.00      0.00      0.00         1\n",
            "      B-family       1.00      0.11      0.20        18\n",
            "    B-location       0.91      0.91      0.91        54\n",
            "    B-med_exam       0.86      0.68      0.75       114\n",
            "       B-money       0.80      0.90      0.85        31\n",
            "        B-name       0.75      0.82      0.78        72\n",
            "B-organization       0.00      0.00      0.00         0\n",
            "  B-profession       0.00      0.00      0.00         9\n",
            "        B-time       0.77      0.62      0.68       494\n",
            "          I-ID       0.00      0.00      0.00         0\n",
            "     I-contact       0.86      0.33      0.48        18\n",
            "   I-education       0.00      0.00      0.00         4\n",
            "      I-family       0.00      0.00      0.00        21\n",
            "    I-location       0.81      0.83      0.82        76\n",
            "    I-med_exam       0.79      0.69      0.74       215\n",
            "       I-money       0.84      0.84      0.84        77\n",
            "        I-name       0.84      0.79      0.82       131\n",
            "      I-others       0.00      0.00      0.00         0\n",
            "  I-profession       0.00      0.00      0.00        14\n",
            "        I-time       0.84      0.68      0.75      1078\n",
            "             O       0.99      1.00      0.99     80844\n",
            "\n",
            "      accuracy                           0.99     83276\n",
            "     macro avg       0.52      0.41      0.43     83276\n",
            "  weighted avg       0.99      0.99      0.99     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 21\n",
            "test_f1(macro, micro) (0.43,0.99) | test_avg_loss 7.619 | f1 for each class\n",
            "[0.         0.33333333 0.         0.2        0.90740741 0.75490196\n",
            " 0.84848485 0.78145695 0.         0.         0.68391451 0.\n",
            " 0.48       0.         0.         0.81818182 0.73762376 0.84415584\n",
            " 0.81568627 0.         0.         0.75064267 0.99338704]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.00      0.00      0.00        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.36      0.34      0.35        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.27      0.41      0.33        32\n",
            "      B-location       0.84      0.84      0.84       223\n",
            "      B-med_exam       0.72      0.78      0.75       329\n",
            "         B-money       0.72      0.67      0.70        95\n",
            "          B-name       0.79      0.78      0.79       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.16      0.09      0.12        33\n",
            "          B-time       0.79      0.79      0.79      2031\n",
            "            I-ID       0.11      0.09      0.10        64\n",
            "I-clinical_event       0.00      0.00      0.00        15\n",
            "       I-contact       0.60      0.66      0.63       198\n",
            "     I-education       0.00      0.00      0.00         8\n",
            "        I-family       0.28      0.44      0.34        34\n",
            "      I-location       0.82      0.76      0.79       346\n",
            "      I-med_exam       0.80      0.80      0.80       638\n",
            "         I-money       0.77      0.83      0.80       236\n",
            "          I-name       0.78      0.84      0.81       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.14      0.14      0.14        73\n",
            "          I-time       0.84      0.85      0.84      4414\n",
            "               O       1.00      1.00      1.00    322493\n",
            "\n",
            "        accuracy                           0.99    331933\n",
            "       macro avg       0.40      0.41      0.40    331933\n",
            "    weighted avg       0.99      0.99      0.99    331933\n",
            "\n",
            "training time :115.46\n",
            "epoch 6/20 | train_f1(macro, micro) (0.40,0.99) | train_epoch_avg_loss 5.925| f1 for each class \n",
            "[0.         0.         0.34782609 0.         0.325      0.83928571\n",
            " 0.74744526 0.69565217 0.78832117 0.         0.         0.11538462\n",
            " 0.78921569 0.1        0.         0.62650602 0.         0.34482759\n",
            " 0.78978979 0.8015625  0.79591837 0.81032258 0.         0.\n",
            " 0.13888889 0.8443843  0.9955678 ]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.00      0.00      0.00         0\n",
            "B-clinical_event       0.00      0.00      0.00         0\n",
            "       B-contact       0.25      0.40      0.31         5\n",
            "     B-education       0.00      0.00      0.00         1\n",
            "        B-family       1.00      0.06      0.11        18\n",
            "      B-location       0.70      0.93      0.80        54\n",
            "      B-med_exam       0.88      0.74      0.80       114\n",
            "         B-money       0.67      0.90      0.77        31\n",
            "          B-name       0.89      0.71      0.79        72\n",
            "  B-organization       0.00      0.00      0.00         0\n",
            "        B-others       0.00      0.00      0.00         0\n",
            "    B-profession       1.00      0.11      0.20         9\n",
            "          B-time       0.66      0.82      0.73       494\n",
            "            I-ID       0.00      0.00      0.00         0\n",
            "       I-contact       0.39      0.61      0.48        18\n",
            "     I-education       0.00      0.00      0.00         4\n",
            "        I-family       0.00      0.00      0.00        21\n",
            "      I-location       0.82      0.87      0.85        76\n",
            "      I-med_exam       0.86      0.73      0.79       215\n",
            "         I-money       0.69      0.88      0.78        77\n",
            "          I-name       0.86      0.69      0.76       131\n",
            "        I-others       0.00      0.00      0.00         0\n",
            "    I-profession       0.00      0.00      0.00        14\n",
            "          I-time       0.73      0.87      0.79      1078\n",
            "               O       1.00      0.99      0.99     80844\n",
            "\n",
            "        accuracy                           0.99     83276\n",
            "       macro avg       0.46      0.41      0.40     83276\n",
            "    weighted avg       0.99      0.99      0.99     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 23\n",
            "test_f1(macro, micro) (0.40,0.99) | test_avg_loss 7.991 | f1 for each class\n",
            "[0.         0.         0.30769231 0.         0.10526316 0.8\n",
            " 0.8        0.76712329 0.79069767 0.         0.         0.2\n",
            " 0.73087309 0.         0.47826087 0.         0.         0.84615385\n",
            " 0.79197995 0.77714286 0.76271186 0.         0.         0.79354291\n",
            " 0.99363215]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.19      0.14      0.16        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.45      0.38      0.41        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.39      0.53      0.45        32\n",
            "      B-location       0.81      0.83      0.82       223\n",
            "      B-med_exam       0.77      0.81      0.79       329\n",
            "         B-money       0.64      0.62      0.63        95\n",
            "          B-name       0.79      0.79      0.79       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.36      0.24      0.29        33\n",
            "          B-time       0.83      0.85      0.84      2031\n",
            "            I-ID       0.20      0.11      0.14        64\n",
            "I-clinical_event       0.09      0.07      0.08        15\n",
            "       I-contact       0.60      0.63      0.61       198\n",
            "     I-education       0.00      0.00      0.00         8\n",
            "        I-family       0.44      0.53      0.48        34\n",
            "      I-location       0.85      0.87      0.86       346\n",
            "      I-med_exam       0.87      0.87      0.87       638\n",
            "         I-money       0.74      0.69      0.71       236\n",
            "          I-name       0.84      0.85      0.84       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.34      0.27      0.30        73\n",
            "          I-time       0.87      0.88      0.88      4414\n",
            "               O       1.00      1.00      1.00    322493\n",
            "\n",
            "        accuracy                           0.99    331933\n",
            "       macro avg       0.45      0.44      0.44    331933\n",
            "    weighted avg       0.99      0.99      0.99    331933\n",
            "\n",
            "training time :115.39\n",
            "epoch 7/20 | train_f1(macro, micro) (0.44,0.99) | train_epoch_avg_loss 4.574| f1 for each class \n",
            "[0.16216216 0.         0.4137931  0.         0.44736842 0.81938326\n",
            " 0.78518519 0.63101604 0.79227053 0.         0.         0.29090909\n",
            " 0.83940357 0.14141414 0.07692308 0.61386139 0.         0.48\n",
            " 0.86       0.87038492 0.71491228 0.84350133 0.         0.\n",
            " 0.3030303  0.8782138  0.99664146]\n",
            "\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          B-ID       0.00      0.00      0.00         0\n",
            "     B-contact       0.29      0.40      0.33         5\n",
            "   B-education       0.00      0.00      0.00         1\n",
            "      B-family       0.25      0.06      0.09        18\n",
            "    B-location       0.75      0.93      0.83        54\n",
            "    B-med_exam       0.74      0.92      0.82       114\n",
            "       B-money       0.79      0.71      0.75        31\n",
            "        B-name       0.79      0.78      0.78        72\n",
            "B-organization       0.00      0.00      0.00         0\n",
            "  B-profession       0.00      0.00      0.00         9\n",
            "        B-time       0.63      0.88      0.74       494\n",
            "     I-contact       0.19      0.39      0.26        18\n",
            "   I-education       0.00      0.00      0.00         4\n",
            "      I-family       0.32      0.29      0.30        21\n",
            "    I-location       0.66      0.88      0.76        76\n",
            "    I-med_exam       0.75      0.88      0.81       215\n",
            "       I-money       0.78      0.66      0.72        77\n",
            "        I-name       0.73      0.75      0.74       131\n",
            "  I-profession       0.00      0.00      0.00        14\n",
            "        I-time       0.71      0.91      0.80      1078\n",
            "             O       1.00      0.99      0.99     80844\n",
            "\n",
            "      accuracy                           0.99     83276\n",
            "     macro avg       0.45      0.50      0.46     83276\n",
            "  weighted avg       0.99      0.99      0.99     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 19\n",
            "test_f1(macro, micro) (0.46,0.99) | test_avg_loss 9.045 | f1 for each class\n",
            "[0.         0.33333333 0.         0.09090909 0.82644628 0.8203125\n",
            " 0.74576271 0.78321678 0.         0.         0.73835732 0.25925926\n",
            " 0.         0.3        0.75706215 0.8137045  0.71830986 0.73684211\n",
            " 0.         0.79788101 0.99335899]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.11      0.05      0.07        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.71      0.62      0.66        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.50      0.53      0.52        32\n",
            "      B-location       0.85      0.83      0.84       223\n",
            "      B-med_exam       0.85      0.88      0.86       329\n",
            "         B-money       0.66      0.71      0.68        95\n",
            "          B-name       0.83      0.84      0.83       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.58      0.45      0.51        33\n",
            "          B-time       0.86      0.86      0.86      2031\n",
            "            I-ID       0.38      0.23      0.29        64\n",
            "I-clinical_event       0.00      0.00      0.00        15\n",
            "       I-contact       0.80      0.80      0.80       198\n",
            "     I-education       0.00      0.00      0.00         8\n",
            "        I-family       0.53      0.59      0.56        34\n",
            "      I-location       0.88      0.88      0.88       346\n",
            "      I-med_exam       0.91      0.91      0.91       638\n",
            "         I-money       0.73      0.77      0.75       236\n",
            "          I-name       0.82      0.88      0.85       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.50      0.49      0.50        73\n",
            "          I-time       0.90      0.89      0.89      4414\n",
            "               O       1.00      1.00      1.00    322493\n",
            "\n",
            "        accuracy                           0.99    331933\n",
            "       macro avg       0.50      0.49      0.49    331933\n",
            "    weighted avg       0.99      0.99      0.99    331933\n",
            "\n",
            "training time :115.55\n",
            "epoch 8/20 | train_f1(macro, micro) (0.49,0.99) | train_epoch_avg_loss 4.048| f1 for each class \n",
            "[0.06666667 0.         0.65909091 0.         0.51515152 0.84090909\n",
            " 0.86309524 0.68020305 0.83173077 0.         0.         0.50847458\n",
            " 0.85833538 0.29126214 0.         0.8        0.         0.55555556\n",
            " 0.88184438 0.90837901 0.75051546 0.85122898 0.         0.\n",
            " 0.49655172 0.89458754 0.99719685]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-contact       0.75      0.60      0.67         5\n",
            " B-education       0.00      0.00      0.00         1\n",
            "    B-family       0.36      0.22      0.28        18\n",
            "  B-location       0.89      0.91      0.90        54\n",
            "  B-med_exam       0.73      0.94      0.82       114\n",
            "     B-money       0.62      0.16      0.26        31\n",
            "      B-name       0.84      0.65      0.73        72\n",
            "B-profession       0.00      0.00      0.00         9\n",
            "      B-time       0.67      0.83      0.74       494\n",
            "   I-contact       1.00      0.39      0.56        18\n",
            " I-education       0.00      0.00      0.00         4\n",
            "    I-family       0.45      0.24      0.31        21\n",
            "  I-location       0.87      0.80      0.84        76\n",
            "  I-med_exam       0.71      0.93      0.81       215\n",
            "     I-money       0.60      0.08      0.14        77\n",
            "      I-name       0.81      0.54      0.65       131\n",
            "    I-others       0.00      0.00      0.00         0\n",
            "I-profession       0.00      0.00      0.00        14\n",
            "      I-time       0.77      0.82      0.80      1078\n",
            "           O       0.99      0.99      0.99     80844\n",
            "\n",
            "    accuracy                           0.99     83276\n",
            "   macro avg       0.55      0.46      0.47     83276\n",
            "weighted avg       0.99      0.99      0.99     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 18\n",
            "test_f1(macro, micro) (0.47,0.99) | test_avg_loss 10.425 | f1 for each class\n",
            "[0.66666667 0.         0.27586207 0.89908257 0.82307692 0.25641026\n",
            " 0.734375   0.         0.73779385 0.56       0.         0.3125\n",
            " 0.83561644 0.80885312 0.13793103 0.64840183 0.         0.\n",
            " 0.79585399 0.99362632]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.33      0.10      0.15        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.69      0.79      0.73        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.80      0.88      0.84        32\n",
            "      B-location       0.88      0.89      0.89       223\n",
            "      B-med_exam       0.90      0.87      0.89       329\n",
            "         B-money       0.81      0.77      0.79        95\n",
            "          B-name       0.89      0.86      0.87       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.70      0.48      0.57        33\n",
            "          B-time       0.88      0.88      0.88      2031\n",
            "            I-ID       0.43      0.36      0.39        64\n",
            "I-clinical_event       0.20      0.13      0.16        15\n",
            "       I-contact       0.86      0.87      0.86       198\n",
            "     I-education       0.27      0.38      0.32         8\n",
            "        I-family       0.77      0.79      0.78        34\n",
            "      I-location       0.90      0.87      0.89       346\n",
            "      I-med_exam       0.94      0.93      0.94       638\n",
            "         I-money       0.83      0.76      0.79       236\n",
            "          I-name       0.90      0.88      0.89       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.68      0.74      0.71        73\n",
            "          I-time       0.90      0.91      0.91      4414\n",
            "               O       1.00      1.00      1.00    322493\n",
            "\n",
            "        accuracy                           0.99    331933\n",
            "       macro avg       0.58      0.56      0.56    331933\n",
            "    weighted avg       0.99      0.99      0.99    331933\n",
            "\n",
            "training time :115.54\n",
            "epoch 9/20 | train_f1(macro, micro) (0.56,0.99) | train_epoch_avg_loss 3.130| f1 for each class \n",
            "[0.14814815 0.         0.73267327 0.         0.8358209  0.88590604\n",
            " 0.88580247 0.78918919 0.87469287 0.         0.         0.57142857\n",
            " 0.8773399  0.38983051 0.16       0.86432161 0.31578947 0.7826087\n",
            " 0.88659794 0.93522907 0.7920354  0.88948787 0.         0.\n",
            " 0.71052632 0.90545126 0.99769942]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "       B-contact       0.40      0.80      0.53         5\n",
            "     B-education       0.00      0.00      0.00         1\n",
            "        B-family       0.47      0.44      0.46        18\n",
            "      B-location       0.85      0.85      0.85        54\n",
            "      B-med_exam       0.79      0.91      0.85       114\n",
            "         B-money       0.85      0.71      0.77        31\n",
            "          B-name       0.81      0.76      0.79        72\n",
            "    B-profession       0.25      0.11      0.15         9\n",
            "          B-time       0.72      0.79      0.75       494\n",
            "I-clinical_event       0.00      0.00      0.00         0\n",
            "       I-contact       0.38      0.72      0.50        18\n",
            "     I-education       0.00      0.00      0.00         4\n",
            "        I-family       0.48      0.52      0.50        21\n",
            "      I-location       0.78      0.82      0.80        76\n",
            "      I-med_exam       0.74      0.93      0.83       215\n",
            "         I-money       0.87      0.71      0.79        77\n",
            "          I-name       0.81      0.75      0.78       131\n",
            "    I-profession       0.14      0.14      0.14        14\n",
            "          I-time       0.79      0.80      0.80      1078\n",
            "               O       0.99      0.99      0.99     80844\n",
            "\n",
            "        accuracy                           0.99     83276\n",
            "       macro avg       0.56      0.59      0.56     83276\n",
            "    weighted avg       0.99      0.99      0.99     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 18\n",
            "test_f1(macro, micro) (0.56,0.99) | test_avg_loss 9.118 | f1 for each class\n",
            "[0.53333333 0.         0.45714286 0.85185185 0.84897959 0.77192982\n",
            " 0.78571429 0.15384615 0.74903475 0.         0.5        0.\n",
            " 0.5        0.8        0.82546201 0.78571429 0.77777778 0.14285714\n",
            " 0.79852467 0.99421922]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.56      0.24      0.33        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.78      0.89      0.83        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.74      0.78      0.76        32\n",
            "      B-location       0.93      0.90      0.91       223\n",
            "      B-med_exam       0.89      0.91      0.90       329\n",
            "         B-money       0.94      0.80      0.86        95\n",
            "          B-name       0.88      0.92      0.90       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.61      0.58      0.59        33\n",
            "          B-time       0.91      0.91      0.91      2031\n",
            "            I-ID       0.59      0.30      0.40        64\n",
            "I-clinical_event       0.00      0.00      0.00        15\n",
            "       I-contact       0.80      0.93      0.86       198\n",
            "     I-education       0.14      0.12      0.13         8\n",
            "        I-family       0.71      0.74      0.72        34\n",
            "      I-location       0.94      0.93      0.93       346\n",
            "      I-med_exam       0.94      0.95      0.95       638\n",
            "         I-money       0.91      0.82      0.86       236\n",
            "          I-name       0.89      0.92      0.91       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.70      0.82      0.75        73\n",
            "          I-time       0.94      0.94      0.94      4414\n",
            "               O       1.00      1.00      1.00    322493\n",
            "\n",
            "        accuracy                           1.00    331933\n",
            "       macro avg       0.59      0.57      0.57    331933\n",
            "    weighted avg       1.00      1.00      1.00    331933\n",
            "\n",
            "training time :115.56\n",
            "epoch 10/20 | train_f1(macro, micro) (0.57,1.00) | train_epoch_avg_loss 2.180| f1 for each class \n",
            "[0.33333333 0.         0.83168317 0.         0.75757576 0.91363636\n",
            " 0.90225564 0.86363636 0.9009434  0.         0.         0.59375\n",
            " 0.91316113 0.39583333 0.         0.8618267  0.13333333 0.72463768\n",
            " 0.93313953 0.94548287 0.86222222 0.90645586 0.         0.\n",
            " 0.75471698 0.94156285 0.99837521]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-contact       0.50      0.80      0.62         5\n",
            " B-education       0.00      0.00      0.00         1\n",
            "    B-family       0.42      0.28      0.33        18\n",
            "  B-location       0.78      0.91      0.84        54\n",
            "  B-med_exam       0.83      0.88      0.85       114\n",
            "     B-money       0.83      0.81      0.82        31\n",
            "      B-name       0.81      0.78      0.79        72\n",
            "B-profession       0.00      0.00      0.00         9\n",
            "      B-time       0.76      0.79      0.78       494\n",
            "   I-contact       0.52      0.72      0.60        18\n",
            " I-education       0.00      0.00      0.00         4\n",
            "    I-family       0.57      0.38      0.46        21\n",
            "  I-location       0.71      0.91      0.80        76\n",
            "  I-med_exam       0.82      0.90      0.86       215\n",
            "     I-money       0.89      0.82      0.85        77\n",
            "      I-name       0.83      0.75      0.79       131\n",
            "I-profession       0.00      0.00      0.00        14\n",
            "      I-time       0.80      0.86      0.83      1078\n",
            "           O       1.00      0.99      0.99     80844\n",
            "\n",
            "    accuracy                           0.99     83276\n",
            "   macro avg       0.58      0.61      0.59     83276\n",
            "weighted avg       0.99      0.99      0.99     83276\n",
            "\n",
            "gt tag unique 數: 19\n",
            "pred tag unique 數: 17\n",
            "test_f1(macro, micro) (0.59,0.99) | test_avg_loss 8.824 | f1 for each class\n",
            "[0.61538462 0.         0.33333333 0.83760684 0.85106383 0.81967213\n",
            " 0.79432624 0.         0.77623762 0.60465116 0.         0.45714286\n",
            " 0.79768786 0.85587583 0.85135135 0.78714859 0.         0.83027318\n",
            " 0.99477658]\n",
            "\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            B-ID       0.38      0.24      0.29        21\n",
            "B-clinical_event       0.00      0.00      0.00         5\n",
            "       B-contact       0.83      0.85      0.84        47\n",
            "     B-education       0.00      0.00      0.00         5\n",
            "        B-family       0.83      0.78      0.81        32\n",
            "      B-location       0.91      0.93      0.92       223\n",
            "      B-med_exam       0.92      0.92      0.92       329\n",
            "         B-money       0.88      0.87      0.88        95\n",
            "          B-name       0.93      0.92      0.93       207\n",
            "  B-organization       0.00      0.00      0.00         1\n",
            "        B-others       0.00      0.00      0.00         3\n",
            "    B-profession       0.67      0.61      0.63        33\n",
            "          B-time       0.93      0.94      0.94      2031\n",
            "            I-ID       0.55      0.28      0.37        64\n",
            "I-clinical_event       0.14      0.07      0.09        15\n",
            "       I-contact       0.96      0.96      0.96       198\n",
            "     I-education       0.40      0.25      0.31         8\n",
            "        I-family       0.61      0.74      0.67        34\n",
            "      I-location       0.93      0.96      0.94       346\n",
            "      I-med_exam       0.90      0.93      0.92       638\n",
            "         I-money       0.88      0.91      0.90       236\n",
            "          I-name       0.92      0.93      0.93       374\n",
            "  I-organization       0.00      0.00      0.00         2\n",
            "        I-others       0.00      0.00      0.00         6\n",
            "    I-profession       0.79      0.52      0.63        73\n",
            "          I-time       0.95      0.96      0.96      4414\n",
            "               O       1.00      1.00      1.00    322493\n",
            "\n",
            "        accuracy                           1.00    331933\n",
            "       macro avg       0.60      0.58      0.59    331933\n",
            "    weighted avg       1.00      1.00      1.00    331933\n",
            "\n",
            "training time :115.57\n",
            "epoch 11/20 | train_f1(macro, micro) (0.59,1.00) | train_epoch_avg_loss 1.888| f1 for each class \n",
            "[0.29411765 0.         0.84210526 0.         0.80645161 0.92\n",
            " 0.92097264 0.87830688 0.92718447 0.         0.         0.63492063\n",
            " 0.93632593 0.37113402 0.09090909 0.96202532 0.30769231 0.66666667\n",
            " 0.94318182 0.91666667 0.89539749 0.92695883 0.         0.\n",
            " 0.62809917 0.95682561 0.99875958]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hHf_PDUEPkg"
      },
      "source": [
        "# 訓練成果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAFcxDva2iGf"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows= 2, ncols= 1, figsize= (10,8), sharex= True)\r\n",
        "ax1.plot([*range(1, stop_epoch+1)], list(train_loss.values()), label= 'train loss')\r\n",
        "ax1.plot([*range(1, stop_epoch+1)], list(test_loss.values()), label= 'test loss')\r\n",
        "ax1.legend()\r\n",
        "\r\n",
        "ax2.plot([*range(1, stop_epoch+1)], list(train_f1.values()), label= 'train f1 (macro)')\r\n",
        "ax2.plot([*range(1, stop_epoch+1)], list(test_f1.values()), label= 'test f1 (macro)')\r\n",
        "ax2.legend()\r\n",
        "plt.savefig('0.74.jpeg')\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pWa4TQhw5PI"
      },
      "source": [
        "# torch.save(model, '0.74.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1UTlctlqT8g"
      },
      "source": [
        "# !cp '0.74.pt' '/content/drive/My Drive/python檔/aicup'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvc6xWNC85De"
      },
      "source": [
        "with open('/content/drive/My Drive/python檔/aicup/test_input.data', 'r', encoding= 'utf-8') as f:\r\n",
        "    data = f.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39YIDKYsH8CZ"
      },
      "source": [
        "test_outputer = test_output(data= data, model= model, tokenizer=tokenizer, batch_size= 16)\r\n",
        "data_list, word_ids, article_ids = test_outputer.raw_output()\r\n",
        "stcs, article_ids_list, word_ids_list = test_outputer.get_stcs()\r\n",
        "\r\n",
        "print(len(stcs))\r\n",
        "print(len(article_ids_list))\r\n",
        "print(len(word_ids_list))\r\n",
        "\r\n",
        "idx = 0\r\n",
        "for stc, article_id, word_id in zip(stcs, article_ids_list, word_ids_list):\r\n",
        "    if idx<100:\r\n",
        "        print(stc,'\\n', article_id,'\\n', word_id, '\\n\\n')\r\n",
        "    idx+=1\r\n",
        "# idx = 0\r\n",
        "# for stc in data_list:\r\n",
        "#     if idx < 100:\r\n",
        "#         print(stc, '\\n')\r\n",
        "#         idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApTe5VvOqO-P"
      },
      "source": [
        "pred_labels_tag = test_outputer.encoding()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEU5Wiw7Pkfx"
      },
      "source": [
        "for stc, article_ids, word_ids, stc_tags in zip(stcs, article_ids_list, word_ids_list, pred_labels_tag):\r\n",
        "    stc_tags_list = []\r\n",
        "    if len(set(stc_tags)) > 1:\r\n",
        "        for word, article_id, word_id, tag in zip(stc, article_ids, word_ids, stc_tags):\r\n",
        "            if tag != 'O':\r\n",
        "                stc_tags_list.append((word, article_id, word_id, tag))\r\n",
        "        print(stc_tags_list)\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i5Ll6U7Uig5"
      },
      "source": [
        "preds_ = test_outputer.pred_out_tsv(pred_labels_tag= pred_labels_tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4qmYVsB9GYp"
      },
      "source": [
        "preds_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t_35QlYM6Hl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
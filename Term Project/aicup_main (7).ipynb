{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "aicup_main",
      "provenance": [],
      "collapsed_sections": [
        "cfh42ir6I9FM",
        "5rPf2heKjCd7"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d3b0d8cb81d47ec8ebacadfa01ca87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b3ce6e651670490b8335ba5e13c0d69e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac1ff9bf30b640fd9ee45ec4217e8c16",
              "IPY_MODEL_b8694acd4f82404bbe1e4bfbc12d53b4"
            ]
          }
        },
        "b3ce6e651670490b8335ba5e13c0d69e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac1ff9bf30b640fd9ee45ec4217e8c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9f418246c814b458afe71346f397ae8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78f31867bc0c46128b1290ea9f7ca945"
          }
        },
        "b8694acd4f82404bbe1e4bfbc12d53b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b38fb3c2c274d9e941c927273d997fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:00&lt;00:00, 1.64MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3136dd02f8bb405f85b17f57e2254ef2"
          }
        },
        "b9f418246c814b458afe71346f397ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78f31867bc0c46128b1290ea9f7ca945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b38fb3c2c274d9e941c927273d997fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3136dd02f8bb405f85b17f57e2254ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4543996770754c069b754b33ef094f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c624837b2c64ec5af1c5bdbc85b9b51",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b782f3cc80e544a7afee8cf9882e0b49",
              "IPY_MODEL_2f175fc9bb2141498c1b3a466ecf5fc7"
            ]
          }
        },
        "9c624837b2c64ec5af1c5bdbc85b9b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b782f3cc80e544a7afee8cf9882e0b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc16db1294154f6e8fbadd65643eb5d1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de5036d6e24849d6974dc00c1a2bb280"
          }
        },
        "2f175fc9bb2141498c1b3a466ecf5fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6de585685364395910527d9da2e1d5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:00&lt;00:00, 1.90kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f8c1c76f0924ed396a03c6e91086a35"
          }
        },
        "cc16db1294154f6e8fbadd65643eb5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de5036d6e24849d6974dc00c1a2bb280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6de585685364395910527d9da2e1d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f8c1c76f0924ed396a03c6e91086a35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c2ad88a645a43b5990e00e4e8580bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a102f5eb6a7436198ec047e8971dbf9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32aaf19e52ea420a9825b041ee53b40c",
              "IPY_MODEL_91d4a4ff567b47028727fee091d727ea"
            ]
          }
        },
        "5a102f5eb6a7436198ec047e8971dbf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32aaf19e52ea420a9825b041ee53b40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_81a36432fa4d4a65a0592fea770d4cf9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411577189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411577189,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19ddb93b4684474e883e1c8795ef3edf"
          }
        },
        "91d4a4ff567b47028727fee091d727ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78ac602b86ea421c9f88c0bfe677ba49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 412M/412M [00:09&lt;00:00, 44.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d286421dc64e4421ba03ab0103695b51"
          }
        },
        "81a36432fa4d4a65a0592fea770d4cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19ddb93b4684474e883e1c8795ef3edf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78ac602b86ea421c9f88c0bfe677ba49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d286421dc64e4421ba03ab0103695b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk66K6AWaW1q"
      },
      "source": [
        "# !cp drive/MyDrive/python檔/aicup/run/dataset.py .\r\n",
        "# !cp drive/MyDrive/python檔/aicup/run "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GHLkq1bcEox",
        "outputId": "ccef6826-03ea-43d3-ac94-5be7fadd445e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59rSMkbocYfI"
      },
      "source": [
        "import sys\r\n",
        "sys.path.insert(0,\"/content/drive/My Drive/python檔/aicup/run\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3D3ktlwcq1p",
        "outputId": "671457ff-628e-4aab-ae2d-269def909522"
      },
      "source": [
        "pip install transformers==3"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\r\u001b[K     |▍                               | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 30.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 34.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 31.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 32.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 35.2MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 22.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 21.0MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 22.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 20.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 409kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 419kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 491kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 501kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 512kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 522kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 532kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 552kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 593kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 604kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 624kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 645kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 655kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 665kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 696kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 706kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 716kB 20.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 727kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 737kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 747kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 20.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/bd/e5abec46af977c8a1375c1dca7cb1e5b3ec392ef279067af7f6bc50491a0/tokenizers-0.8.0rc4-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3) (20.7)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=7bd66ccecc78a47f06885169192802a06216d9986908aab55cd2d8f74a68616f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6RsrpxBWe1H",
        "outputId": "358510b8-c21d-40c1-fbcc-12a8c1f36bdf"
      },
      "source": [
        "pip install pytorch-crf"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6eL0_ORc3lj",
        "outputId": "ca78e1af-142e-4058-8c5c-d35d4200d6e3"
      },
      "source": [
        "pip install pytorch_warmup"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_warmup\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/22/2fb600a06a1d1b493d54ac8fa6c41e96870985992fc504104e0620bc2ea4/pytorch_warmup-0.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_warmup) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_warmup) (3.7.4.3)\n",
            "Installing collected packages: pytorch-warmup\n",
            "Successfully installed pytorch-warmup-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNw4yCiwa1e2"
      },
      "source": [
        "# from dataset import bert_stc_dataset\r\n",
        "# from model2 import model_crf\r\n",
        "from train import train\r\n",
        "# from txt_preprocess2 import preprocess2\r\n",
        "import re\r\n",
        "\r\n",
        "from transformers import BertModel, BertTokenizer, get_cosine_schedule_with_warmup\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torchsummary import summary\r\n",
        "from torchcrf import CRF\r\n",
        "import pytorch_warmup as warmup\r\n",
        "# from torch.autograd import Variable\r\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Qnou0tbJfb",
        "outputId": "f61d4e15-e390-4a17-c77e-1ea377ba58c9"
      },
      "source": [
        "file_path = '/content/drive/My Drive/python檔/aicup/run/data/train_input.data'\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "print('{} is being used'.format(device))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda is being used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6sIQ8wbXGnc"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo2E2d2TU7dG"
      },
      "source": [
        "from torch.utils.data import Dataset\r\n",
        "import torch\r\n",
        "\r\n",
        "class bert_stc_dataset(Dataset):\r\n",
        "    \r\n",
        "    def __init__(self, stcs, labels, tokenizer, max_length):\r\n",
        "        \r\n",
        "        self.stcs = stcs\r\n",
        "        self.labels = labels\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        self.max_length = max_length\r\n",
        "        self.pad_labels = []\r\n",
        "\r\n",
        "        # 已經在preprocess2 做完label 0 padding\r\n",
        "        for i in range(len(labels)):\r\n",
        "            temp_label = [0]*max_length\r\n",
        "            temp_label[:len(labels[i])] = labels[i]\r\n",
        "            self.pad_labels.append(temp_label)\r\n",
        "            \r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.stcs)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        \r\n",
        "        txt = str(self.stcs[idx])\r\n",
        "        \r\n",
        "        txt = ' '.join(list(txt))\r\n",
        "        # print(txt)\r\n",
        "        \r\n",
        "        encoding = self.tokenizer.encode_plus(\r\n",
        "            txt,\r\n",
        "#             truncation= True,\r\n",
        "            max_length= self.max_length,\r\n",
        "            padding = 'max_length',\r\n",
        "            add_special_tokens=False,\r\n",
        "#             pad_to_multiple_of=True,\r\n",
        "            return_attention_mask= True,\r\n",
        "            return_token_type_ids= False,\r\n",
        "            return_tensors='pt')\r\n",
        "        \r\n",
        "        return {\r\n",
        "            'input_ids': encoding['input_ids'].flatten(),\r\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\r\n",
        "            'labels' : torch.tensor(self.pad_labels[idx], dtype= torch.long)\r\n",
        "        }"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfh42ir6I9FM"
      },
      "source": [
        "# preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr4UxdsTI8Y-"
      },
      "source": [
        "class preprocess2():\r\n",
        "  def __init__(self, data):\r\n",
        "    self.data = data\r\n",
        "    self.article_id_list = list()\r\n",
        "    self.data_list= list()\r\n",
        "    data_list_tmp = list()\r\n",
        "    idx = 0\r\n",
        "\r\n",
        "    for row in data:\r\n",
        "      data_tuple = tuple()\r\n",
        "      if row == '\\n':\r\n",
        "        self.article_id_list.append(idx)\r\n",
        "        idx+=1\r\n",
        "        self.data_list.append(data_list_tmp)\r\n",
        "        data_list_tmp = []\r\n",
        "\r\n",
        "      else:\r\n",
        "        row = row.strip('\\n').split(' ')\r\n",
        "\r\n",
        "        if row[0] in ['。', '？','！','～','：','，']:\r\n",
        "          self.article_id_list.append(idx)\r\n",
        "          self.data_list.append(data_list_tmp)\r\n",
        "          data_list_tmp= []\r\n",
        "        \r\n",
        "        elif row[0] in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']:\r\n",
        "          data_tuple = (row[0].lower(), row[1])\r\n",
        "          data_list_tmp.append(data_tuple)\r\n",
        "\r\n",
        "        elif row[0] not in ['摁','嗯','啦','喔','欸','啊','齁','嘿','…','...']:\r\n",
        "          data_tuple = (row[0], row[1])\r\n",
        "          data_list_tmp.append(data_tuple)\r\n",
        "        #data_list_tmp 儲存暫時的data_tuple(token,label)\r\n",
        "    if len(data_list_tmp) != 0:\r\n",
        "      self.data_list.append(data_list_tmp)\r\n",
        "\r\n",
        "  def get_stc_label(self):\r\n",
        "    all_stcs = list()\r\n",
        "    all_labels = list()\r\n",
        "\r\n",
        "    for article_txt_tuple, article_id in zip(self.data_list, self.article_id_list):\r\n",
        "\r\n",
        "      txt_len = len(article_txt_tuple) #(文章數，每個文章對應的總字數) (word, label)\r\n",
        "      stc = str() #存字數= max_stc_len的字串\r\n",
        "      # labels = ['[CLS]'] # 存該字串對應的label # pytorch crf不需要\r\n",
        "      labels = []\r\n",
        "\r\n",
        "      for idx, (word, label) in enumerate(article_txt_tuple):\r\n",
        "\r\n",
        "        stc += word\r\n",
        "        labels.append(label)\r\n",
        "\r\n",
        "      all_stcs.append(stc)\r\n",
        "      all_labels.append(labels)\r\n",
        "\r\n",
        "    all_stcs_clean = []\r\n",
        "    all_labels_clean = []\r\n",
        "\r\n",
        "    idx = 0\r\n",
        "    for stc, label in zip(all_stcs,all_labels): #前處理 & downsampling\r\n",
        "      \r\n",
        "      stc_clean = re.sub(r'(醫師)|(個管師)|(民眾)|(家屬)|(護理師)', '', stc)\r\n",
        "      # print(stc, stc_clean, label)\r\n",
        "      if (len(stc_clean)>=2) & (len(set(label)) >= 2):  \r\n",
        "        # print(stc_clean, stc)\r\n",
        "        all_stcs_clean.append(stc)\r\n",
        "        all_labels_clean.append(label)\r\n",
        "    \r\n",
        "      elif (len(stc_clean)>=2) & (((idx+1) % 5) == 0):\r\n",
        "        all_stcs_clean.append(stc)\r\n",
        "        all_labels_clean.append(label)\r\n",
        "      idx += 1\r\n",
        "\r\n",
        "    # 這一步就先把label 做 0 padding\r\n",
        "\r\n",
        "    # max_length = len(max(all_stcs_clean, key=len)) \r\n",
        "    # pad_labels = []\r\n",
        "\r\n",
        "    # for i in range(len(all_labels_clean)):\r\n",
        "    #   temp_label = [0]*max_length\r\n",
        "    #   temp_label[:len(all_labels_clean[i])] = all_labels_clean[i]\r\n",
        "    #   pad_labels.append(temp_label)\r\n",
        "\r\n",
        "    # print('sentences總數: {}'.format(len(all_stcs_clean)))\r\n",
        "    # print('labels總數: {}'.format(len(all_labels_clean)))\r\n",
        "    # return all_stcs_clean, pad_labels\r\n",
        "    return all_stcs_clean, all_labels_clean\r\n",
        "\r\n",
        "  def tag2id(self, stcs_label):\r\n",
        "\r\n",
        "    all_label = list()\r\n",
        "    for stc_label in stcs_label:\r\n",
        "      for label in stc_label:\r\n",
        "        all_label.append(label)\r\n",
        "\r\n",
        "    labels_set = sorted(set(all_label))\r\n",
        "    tag2id_dict = {}\r\n",
        "    # tag2id_dict = {'[PAD]':0} #固定將PAD id設為0\r\n",
        "\r\n",
        "    # labels_set.remove('[PAD]')\r\n",
        "\r\n",
        "    for idx, label in enumerate(labels_set):\r\n",
        "      tag2id_dict[label] = idx\r\n",
        "\r\n",
        "    return tag2id_dict\r\n",
        "\r\n",
        "  def label_to_ids(self, tag_to_id, raw_labels):\r\n",
        "\r\n",
        "    label2id = []\r\n",
        "    for stc_labels in raw_labels:\r\n",
        "      stc_label_ids = [tag_to_id[label] for label in stc_labels]\r\n",
        "      label2id.append(stc_label_ids)\r\n",
        "    return label2id\r\n",
        "\r\n",
        "  def get_stcs_label2ids(self):\r\n",
        "\r\n",
        "    stcs, labels = self.get_stc_label()\r\n",
        "    tag2id = self.tag2id(stcs_label= labels)\r\n",
        "    labels_ids= self.label_to_ids(tag_to_id= tag2id, raw_labels= labels)\r\n",
        "\r\n",
        "    return stcs, labels_ids"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpu1QT-5tYsi"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48kSvtOFtQRg"
      },
      "source": [
        "class model_crf(nn.Module):\r\n",
        "\tdef __init__(self, n_tags, hidden_dim=768, batchsize= 32):\r\n",
        "\t\tsuper(model_crf, self).__init__()\r\n",
        "\t\tself.n_tags = n_tags\r\n",
        "\t\tself.lstm =  nn.LSTM(bidirectional=True, num_layers=2, input_size=768, hidden_size=hidden_dim//2, dropout= 0.3, batch_first=True)\t\t\r\n",
        "\t\tself.hidden_dim = hidden_dim\r\n",
        "\t\tself.fc = nn.Linear(hidden_dim, self.n_tags)\r\n",
        "\t\tself.bert = BertModel.from_pretrained('bert-base-chinese')\r\n",
        "\r\n",
        "\t\t# for param in self.bert.parameters():\r\n",
        "\t\t# \tparam.requires_grad = False\r\n",
        "\t\t# self.bert.eval()  # 知用来取bert embedding\r\n",
        "\r\n",
        "\t\tself.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "\t\tself.CRF = CRF(n_tags, batch_first= True)\r\n",
        "\t\tself.hidden = self.init_hidden(batchsize)\r\n",
        "\r\n",
        "\tdef init_hidden(self, batch_size):\r\n",
        "\t\treturn (torch.randn(2*2, batch_size, self.hidden_dim // 2).to(self.device),\r\n",
        "\t\t\t\ttorch.randn(2*2, batch_size, self.hidden_dim // 2).to(self.device))\r\n",
        "\r\n",
        "\tdef forward(self, input_ids, attention_mask, tags):\r\n",
        "\r\n",
        "\t\tbatch_size = input_ids.size(0)\r\n",
        "\t\tmax_seq_len = input_ids.size(1)\r\n",
        "\t\tbert_output, _  = self.bert(input_ids.long(), attention_mask)\r\n",
        "\t\t\r\n",
        "\t\tseq_len = torch.sum(attention_mask, dim= 1).cpu().int()\r\n",
        "\t\t# print(seq_len)\r\n",
        "\t\tpack_input = pack_padded_sequence(input= bert_output, lengths= seq_len, batch_first= True, enforce_sorted= False)\r\n",
        "\t\tpacked_lstm_out, _ = self.lstm(pack_input,self.init_hidden(batch_size= batch_size))\r\n",
        "\t\tlstm_enc, _=  pad_packed_sequence(packed_lstm_out, batch_first=True, padding_value=0)\r\n",
        "\t\t# print(lstm_enc.size())\r\n",
        "\t\tlstm_feats = self.fc(lstm_enc)\r\n",
        "\r\n",
        "\t\tlstm_max_seq_len = lstm_feats.size(1)\r\n",
        "\t\tpad = torch.zeros(size=(batch_size, max_seq_len-lstm_max_seq_len, self.n_tags), dtype= torch.float).to(self.device)\r\n",
        "\t\tlstm_feats= torch.cat((lstm_feats, pad), dim= 1)\r\n",
        "  \r\n",
        "\t\tlstm_feats[:,:,1:-1] = lstm_feats[:,:,1:-1]*100\r\n",
        "\t\tloss = -self.CRF(lstm_feats, tags, attention_mask.bool(), reduction= 'token_mean')\r\n",
        "\t\tpred_seqs = self.CRF.decode(emissions= lstm_feats, mask= attention_mask.bool())\r\n",
        "  \r\n",
        "\t\treturn loss, pred_seqs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F72vtVN9tbhD"
      },
      "source": [
        "# 參數設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7d3b0d8cb81d47ec8ebacadfa01ca87e",
            "b3ce6e651670490b8335ba5e13c0d69e",
            "ac1ff9bf30b640fd9ee45ec4217e8c16",
            "b8694acd4f82404bbe1e4bfbc12d53b4",
            "b9f418246c814b458afe71346f397ae8",
            "78f31867bc0c46128b1290ea9f7ca945",
            "0b38fb3c2c274d9e941c927273d997fc",
            "3136dd02f8bb405f85b17f57e2254ef2",
            "4543996770754c069b754b33ef094f04",
            "9c624837b2c64ec5af1c5bdbc85b9b51",
            "b782f3cc80e544a7afee8cf9882e0b49",
            "2f175fc9bb2141498c1b3a466ecf5fc7",
            "cc16db1294154f6e8fbadd65643eb5d1",
            "de5036d6e24849d6974dc00c1a2bb280",
            "c6de585685364395910527d9da2e1d5e",
            "0f8c1c76f0924ed396a03c6e91086a35",
            "7c2ad88a645a43b5990e00e4e8580bd7",
            "5a102f5eb6a7436198ec047e8971dbf9",
            "32aaf19e52ea420a9825b041ee53b40c",
            "91d4a4ff567b47028727fee091d727ea",
            "81a36432fa4d4a65a0592fea770d4cf9",
            "19ddb93b4684474e883e1c8795ef3edf",
            "78ac602b86ea421c9f88c0bfe677ba49",
            "d286421dc64e4421ba03ab0103695b51"
          ]
        },
        "id": "zTvRlmOldMGf",
        "outputId": "00bb7511-8dee-490b-c228-fee310af8f18"
      },
      "source": [
        "# ---------------前處理---------------\r\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\r\n",
        "\tdata=f.readlines()#.encode('utf-8').decode('utf-8-sig')\r\n",
        "\r\n",
        "preprocessor = preprocess2(data)\r\n",
        "\r\n",
        "stcs, original_labels= preprocessor.get_stc_label()\r\n",
        "stcs, labels = preprocessor.get_stcs_label2ids()\r\n",
        "tag2id_dict = preprocessor.tag2id(original_labels)\r\n",
        "n_tags = len(tag2id_dict)\r\n",
        "print(tag2id_dict)\r\n",
        "print('tags數: {}'.format(n_tags))\r\n",
        "\r\n",
        "gt_tags = [tag for label in labels for tag in label]\r\n",
        "\r\n",
        "for tag in set(gt_tags):\r\n",
        "  print('{}|{}'.format(tag, gt_tags.count(tag)/len(gt_tags)))\r\n",
        "# plt.hist(gt_tags)\r\n",
        "plt.hist([len(stc) for stc in stcs])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\r\n",
        "max_length = len(max(stcs, key=len)) \r\n",
        "print('max_stc_length', max_length)\r\n",
        "\r\n",
        "# ---------------模型---------------\r\n",
        "batchsize= 32\r\n",
        "model = model_crf(n_tags= n_tags, hidden_dim= 128, batchsize= batchsize).to(device)\r\n",
        "# print(summary(model,[(128, 300), (128,300)]))\r\n",
        "\r\n",
        "train_x, test_x, train_y, test_y = train_test_split(stcs, labels, test_size= 0.2, shuffle= True, random_state= 42)\r\n",
        "\r\n",
        "train_dataset = bert_stc_dataset(stcs= train_x, labels= train_y, tokenizer= tokenizer, max_length= max_length)\r\n",
        "print(train_x[0])\r\n",
        "print(train_dataset[0]['input_ids'])\r\n",
        "print(train_dataset[0]['labels'])\r\n",
        "test_dataset = bert_stc_dataset(stcs= test_x, labels= test_y, tokenizer= tokenizer, max_length= max_length)\r\n",
        "\r\n",
        "print('training stcs 總數: {}'.format(len(train_dataset)))\r\n",
        "train_dataloader = DataLoader(train_dataset, batch_size= batchsize, shuffle= True, num_workers= 0)\r\n",
        "test_dataloader = DataLoader(test_dataset, batch_size= batchsize, shuffle= False, num_workers= 0)\r\n",
        "\r\n",
        "num_epochs = 40\r\n",
        "num_iteration = len(train_dataloader)\r\n",
        "print('num_iteration',num_iteration)\r\n",
        "total_iter = num_iteration * num_epochs\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-5, weight_decay= 0.01)\r\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=4000, num_training_steps=total_iter)\r\n",
        "# warmup_scheduler = warmup.ExponentialWarmup(optimizer, warmup_period=150)\r\n",
        "\r\n",
        "# ---------------訓練---------------\r\n",
        "# train_model = train(model= model, optimizer= optimizer, train_loader= train_dataloader, test_loader= 0, num_epochs= 5, device= device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-ID': 0, 'B-clinical_event': 1, 'B-contact': 2, 'B-education': 3, 'B-family': 4, 'B-location': 5, 'B-med_exam': 6, 'B-money': 7, 'B-name': 8, 'B-organization': 9, 'B-profession': 10, 'B-time': 11, 'I-ID': 12, 'I-clinical_event': 13, 'I-contact': 14, 'I-education': 15, 'I-family': 16, 'I-location': 17, 'I-med_exam': 18, 'I-money': 19, 'I-name': 20, 'I-organization': 21, 'I-profession': 22, 'I-time': 23, 'O': 24}\n",
            "tags數: 25\n",
            "0|0.0001676551333906155\n",
            "1|0.00010478445836913469\n",
            "2|0.0003981809418027118\n",
            "3|6.287067502148081e-05\n",
            "4|0.0005239222918456734\n",
            "5|0.003374059559486137\n",
            "6|0.004589559276568099\n",
            "7|0.0016346375505585011\n",
            "8|0.003415973342833791\n",
            "9|2.095689167382694e-05\n",
            "10|0.00027243959175975017\n",
            "11|0.029884527526877213\n",
            "12|0.0003143533751074041\n",
            "13|0.0003143533751074041\n",
            "14|0.001655594442232328\n",
            "15|6.287067502148081e-05\n",
            "16|0.0005867929668671543\n",
            "17|0.005029654001718465\n",
            "18|0.008089360186097199\n",
            "19|0.004065636984722426\n",
            "20|0.005700274535280927\n",
            "21|4.191378334765388e-05\n",
            "22|0.0008382756669530775\n",
            "23|0.06586751053083807\n",
            "24|0.8629838422365195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d3b0d8cb81d47ec8ebacadfa01ca87e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "max_stc_length 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4543996770754c069b754b33ef094f04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c2ad88a645a43b5990e00e4e8580bd7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411577189.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "還是天氣太熱\n",
            "tensor([6917, 3221, 1921, 3706, 1922, 4229,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0])\n",
            "tensor([24, 24, 24, 24, 24, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0])\n",
            "training stcs 總數: 4855\n",
            "num_iteration 152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rPf2heKjCd7"
      },
      "source": [
        "# test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfjiko8GjBZD"
      },
      "source": [
        "def test(model, test_dataloader, device):\r\n",
        "\r\n",
        "  preds_epoch = []\r\n",
        "  gts_epoch = []\r\n",
        "  epoch_loss = 0\r\n",
        "  iteration = 0\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  for idx, batch_dict in enumerate(test_dataloader):\r\n",
        "\r\n",
        "    # print('idx: ',idx+1)\r\n",
        "    input_ids = batch_dict['input_ids'].to(device)\r\n",
        "    attention_mask = batch_dict['attention_mask'].to(device)\r\n",
        "    labels = batch_dict['labels'].to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      loss, pred_labels = model(input_ids, attention_mask.bool(), labels)\r\n",
        "\r\n",
        "    # mask gt labels \r\n",
        "    labels = batch_dict['labels'].numpy()\r\n",
        "    masks = batch_dict['attention_mask'].numpy()\r\n",
        "\r\n",
        "    labels_nopad = []\r\n",
        "    for label , seq_mask in zip(labels, masks):\r\n",
        "\r\n",
        "      seq = [tag for tag, mask in zip(label, seq_mask) if mask == 1]\r\n",
        "      labels_nopad.append(seq)\r\n",
        "\r\n",
        "    # one dim array \r\n",
        "    preds= [tag for seq in pred_labels for tag in seq]\r\n",
        "    gts= [tag for seq in labels_nopad for tag in seq]\r\n",
        "\r\n",
        "    preds_epoch += preds\r\n",
        "    gts_epoch += gts\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    iteration += 1\r\n",
        "\r\n",
        "  f1_macro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'macro')\r\n",
        "  f1_micro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'micro')\r\n",
        "  f1 = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= None)\r\n",
        "  avg_loss = epoch_loss / iteration\r\n",
        "  \r\n",
        "  print('test_f1(macro, micro) ({:.2f},{:.2f}) | test_avg_loss {:.2f} | f1 for each class{}'.format(f1_macro, f1_micro, avg_loss, f1))\r\n",
        "\r\n",
        "  return f1_macro, f1_micro, avg_loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTZoeeJLtl9K"
      },
      "source": [
        "# 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyZYZVdJhxFa",
        "outputId": "ab432711-9880-414c-e2c0-e379fb4976ba"
      },
      "source": [
        "train_loss = {}\r\n",
        "test_loss = {}\r\n",
        "train_f1 = {}\r\n",
        "test_f1 = {}\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "\r\n",
        "  preds_epoch = []\r\n",
        "  gts_epoch = []\r\n",
        "  epoch_loss = 0\r\n",
        "  iteration = 0\r\n",
        "\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  for idx, batch_dict in enumerate(train_dataloader):\r\n",
        "\r\n",
        "    # print('idx: ',idx+1)\r\n",
        "    input_ids = batch_dict['input_ids'].to(device)\r\n",
        "    attention_mask = batch_dict['attention_mask'].to(device)\r\n",
        "    labels = batch_dict['labels'].to(device)\r\n",
        "\r\n",
        "    loss, pred_labels = model(input_ids, attention_mask.bool(), labels)\r\n",
        "\r\n",
        "    # loss = model.neg_log_likelihood(input_ids, attention_mask, labels)\r\n",
        "    loss.backward()\r\n",
        "    # torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\r\n",
        "\r\n",
        "    # if (idx+1) % 5 == 0:\r\n",
        "    optimizer.step()\r\n",
        "    scheduler.step()\r\n",
        "    # warmup_scheduler.dampen()\r\n",
        "    model.zero_grad()\r\n",
        "\r\n",
        "    # mask gt labels \r\n",
        "    labels = batch_dict['labels'].numpy()\r\n",
        "    masks = batch_dict['attention_mask'].numpy()\r\n",
        "    # masked_list = (labels*mask).numpy()\r\n",
        "\r\n",
        "    labels_nopad = []\r\n",
        "    for label , seq_mask in zip(labels, masks):\r\n",
        "\r\n",
        "      seq = [tag for tag, mask in zip(label, seq_mask) if mask == 1]\r\n",
        "      labels_nopad.append(seq)\r\n",
        "\r\n",
        "    # one dim array \r\n",
        "    preds= [tag for seq in pred_labels for tag in seq]\r\n",
        "    gts= [tag for seq in labels_nopad for tag in seq]\r\n",
        "\r\n",
        "    preds_epoch += preds\r\n",
        "    gts_epoch += gts\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "    iteration += 1\r\n",
        "\r\n",
        "    # print('pred_labels', pred_labels)\r\n",
        "    # # print('preds:', preds)\r\n",
        "    # print('gts:',gts)\r\n",
        "    # print(round(f1_score(y_true= gts, y_pred= preds, average= 'macro'),2))\r\n",
        "    # # print(f1_score(y_true= gts, y_pred= preds, average= 'micro'))\r\n",
        "    # print(round(loss.item(),2))\r\n",
        "\r\n",
        "    # print('idx:{} loss:{}'.format(idx, loss))\r\n",
        "\r\n",
        "  f1_macro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'macro')\r\n",
        "  f1_micro = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= 'micro')\r\n",
        "  f1 = f1_score(y_true= gts_epoch, y_pred= preds_epoch, average= None)\r\n",
        "  avg_loss = epoch_loss / iteration\r\n",
        "  \r\n",
        "\r\n",
        "  print('epoch {}/{} | train_f1(macro, micro) ({:.2f},{:.2f}) | train_epoch_avg_loss {:.2f}| f1 for each class {}'.format(epoch+1, num_epochs, f1_macro, f1_micro, avg_loss, f1))\r\n",
        "\r\n",
        "  test_f1_macro, test_f1_micro, test_avg_loss = test(model= model, test_dataloader= test_dataloader, device= device)\r\n",
        "\r\n",
        "  train_loss[epoch+1] = avg_loss\r\n",
        "  test_loss[epoch+1] = test_avg_loss\r\n",
        "  train_f1[epoch+1] = f1_macro\r\n",
        "  test_f1[epoch+1] = test_f1_macro\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1/40 | train_f1(macro, micro) (0.01,0.01) | train_epoch_avg_loss 13.41| f1 for each class [0.         0.         0.         0.         0.00091891 0.00218341\n",
            " 0.01020625 0.00214669 0.00751228 0.         0.         0.03569835\n",
            " 0.         0.         0.00671817 0.         0.         0.00982801\n",
            " 0.01197605 0.00809717 0.01023018 0.         0.00142552 0.07306094\n",
            " 0.01342972]\n",
            "test_f1(macro, micro) (0.02,0.17) | test_avg_loss 7.33 | f1 for each class[0.         0.         0.         0.         0.         0.00687285\n",
            " 0.         0.00280505 0.0060423  0.         0.         0.03947368\n",
            " 0.         0.         0.0056338  0.         0.         0.0060241\n",
            " 0.01282051 0.         0.01282051 0.         0.         0.10967742\n",
            " 0.30468827]\n",
            "epoch 2/40 | train_f1(macro, micro) (0.03,0.29) | train_epoch_avg_loss 6.30| f1 for each class [0.00118694 0.         0.         0.         0.         0.00878156\n",
            " 0.01340646 0.         0.00779221 0.         0.         0.04312518\n",
            " 0.         0.         0.00709849 0.         0.         0.00787789\n",
            " 0.03614458 0.01024765 0.01381693 0.         0.         0.10121304\n",
            " 0.47145053]\n",
            "test_f1(macro, micro) (0.04,0.50) | test_avg_loss 4.62 | f1 for each class[0.         0.         0.01538462 0.         0.         0.\n",
            " 0.02575107 0.         0.         0.         0.         0.03977273\n",
            " 0.02185792 0.         0.         0.         0.         0.01351351\n",
            " 0.01403509 0.         0.         0.         0.01092896 0.05389222\n",
            " 0.68950532]\n",
            "epoch 3/40 | train_f1(macro, micro) (0.04,0.47) | train_epoch_avg_loss 4.79| f1 for each class [0.         0.         0.         0.         0.         0.\n",
            " 0.01056338 0.         0.02538071 0.         0.         0.04533333\n",
            " 0.         0.         0.         0.         0.         0.01251956\n",
            " 0.02236422 0.00255102 0.00342466 0.         0.         0.09838586\n",
            " 0.66371581]\n",
            "test_f1(macro, micro) (0.04,0.60) | test_avg_loss 3.84 | f1 for each class[0.         0.         0.         0.         0.         0.\n",
            " 0.01176471 0.         0.02409639 0.         0.         0.05424955\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.02985075 0.02030457 0.         0.         0.         0.12050534\n",
            " 0.76459078]\n",
            "epoch 4/40 | train_f1(macro, micro) (0.04,0.57) | train_epoch_avg_loss 3.97| f1 for each class [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0052356  0.01092896 0.         0.         0.05174198\n",
            " 0.         0.         0.         0.         0.         0.00855615\n",
            " 0.01981982 0.01221374 0.00317965 0.         0.00375235 0.21489758\n",
            " 0.73892654]\n",
            "test_f1(macro, micro) (0.06,0.67) | test_avg_loss 3.09 | f1 for each class[0.         0.         0.         0.         0.         0.\n",
            " 0.03333333 0.         0.02439024 0.         0.         0.0582878\n",
            " 0.         0.         0.         0.         0.         0.01886792\n",
            " 0.07692308 0.01481481 0.01282051 0.         0.         0.39285714\n",
            " 0.81353692]\n",
            "epoch 5/40 | train_f1(macro, micro) (0.05,0.64) | train_epoch_avg_loss 3.22| f1 for each class [0.         0.         0.         0.         0.         0.00928074\n",
            " 0.02522936 0.         0.01120448 0.         0.         0.0931085\n",
            " 0.         0.         0.         0.         0.         0.00251572\n",
            " 0.03018109 0.0069808  0.00714286 0.         0.         0.32485981\n",
            " 0.79547306]\n",
            "test_f1(macro, micro) (0.06,0.72) | test_avg_loss 2.53 | f1 for each class[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.11599297\n",
            " 0.         0.         0.02564103 0.         0.         0.01081081\n",
            " 0.         0.01526718 0.         0.         0.         0.41341654\n",
            " 0.8497449 ]\n",
            "epoch 6/40 | train_f1(macro, micro) (0.06,0.70) | train_epoch_avg_loss 2.71| f1 for each class [0.         0.         0.         0.         0.         0.\n",
            " 0.01048493 0.00552486 0.         0.         0.         0.11760063\n",
            " 0.         0.         0.         0.         0.         0.00868307\n",
            " 0.03752759 0.00417537 0.00346021 0.         0.         0.40431467\n",
            " 0.8361139 ]\n",
            "test_f1(macro, micro) (0.07,0.78) | test_avg_loss 2.11 | f1 for each class[0.         0.         0.         0.         0.         0.\n",
            " 0.03007519 0.         0.         0.         0.         0.19965577\n",
            " 0.         0.         0.         0.         0.         0.02777778\n",
            " 0.08433735 0.02173913 0.         0.         0.         0.53363568\n",
            " 0.88641202]\n",
            "epoch 7/40 | train_f1(macro, micro) (0.07,0.77) | train_epoch_avg_loss 2.12| f1 for each class [0.         0.         0.00787402 0.         0.         0.\n",
            " 0.04094488 0.         0.01365188 0.         0.         0.21248986\n",
            " 0.         0.         0.         0.         0.         0.00986842\n",
            " 0.1080402  0.03669725 0.00380952 0.         0.         0.56141673\n",
            " 0.88019049]\n",
            "test_f1(macro, micro) (0.10,0.83) | test_avg_loss 1.66 | f1 for each class[0.         0.         0.         0.         0.         0.\n",
            " 0.05769231 0.         0.03174603 0.         0.         0.37234043\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.24875622 0.1025641  0.         0.         0.         0.66470588\n",
            " 0.91648556]\n",
            "epoch 8/40 | train_f1(macro, micro) (0.10,0.82) | train_epoch_avg_loss 1.69| f1 for each class [0.         0.         0.         0.         0.         0.\n",
            " 0.07706422 0.         0.         0.         0.         0.33725172\n",
            " 0.         0.         0.         0.         0.         0.02836879\n",
            " 0.17902098 0.19570406 0.01503759 0.         0.         0.67567568\n",
            " 0.91060568]\n",
            "test_f1(macro, micro) (0.12,0.87) | test_avg_loss 1.35 | f1 for each class[0.         0.         0.         0.         0.         0.03571429\n",
            " 0.1875     0.         0.03773585 0.         0.         0.48330059\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.31914894 0.23684211 0.         0.         0.         0.76107595\n",
            " 0.94094155]\n",
            "epoch 9/40 | train_f1(macro, micro) (0.12,0.85) | train_epoch_avg_loss 1.31| f1 for each class [0.         0.         0.         0.         0.         0.04635762\n",
            " 0.10434783 0.03305785 0.00694444 0.         0.         0.43726395\n",
            " 0.         0.         0.04608295 0.         0.         0.10408922\n",
            " 0.28231798 0.34825871 0.04780876 0.         0.         0.7286288\n",
            " 0.93165659]\n",
            "test_f1(macro, micro) (0.18,0.90) | test_avg_loss 1.00 | f1 for each class[0.         0.         0.         0.         0.         0.14117647\n",
            " 0.28947368 0.15789474 0.09090909 0.         0.         0.57821782\n",
            " 0.         0.         0.44897959 0.         0.         0.29230769\n",
            " 0.23188406 0.42696629 0.05217391 0.         0.         0.80062305\n",
            " 0.95711335]\n",
            "epoch 10/40 | train_f1(macro, micro) (0.17,0.88) | train_epoch_avg_loss 1.03| f1 for each class [0.         0.         0.         0.         0.         0.204947\n",
            " 0.14868106 0.09569378 0.13194444 0.         0.         0.49170566\n",
            " 0.         0.         0.12716763 0.         0.         0.23404255\n",
            " 0.33534743 0.45730028 0.19747899 0.         0.05797101 0.76534157\n",
            " 0.95033195]\n",
            "test_f1(macro, micro) (0.22,0.91) | test_avg_loss 0.85 | f1 for each class[0.         0.         0.         0.         0.         0.27160494\n",
            " 0.21359223 0.08       0.23376623 0.         0.         0.64504505\n",
            " 0.         0.         0.25641026 0.         0.         0.5\n",
            " 0.42458101 0.53465347 0.52525253 0.         0.         0.81415929\n",
            " 0.9662853 ]\n",
            "epoch 11/40 | train_f1(macro, micro) (0.23,0.91) | train_epoch_avg_loss 0.80| f1 for each class [0.         0.         0.         0.         0.         0.3197026\n",
            " 0.2565445  0.21989529 0.25429553 0.         0.         0.56135881\n",
            " 0.         0.         0.31707317 0.         0.         0.43645084\n",
            " 0.46105919 0.58064516 0.38723404 0.         0.10084034 0.79930596\n",
            " 0.96392007]\n",
            "test_f1(macro, micro) (0.27,0.93) | test_avg_loss 0.80 | f1 for each class[0.         0.         0.         0.         0.         0.48648649\n",
            " 0.28169014 0.35294118 0.36111111 0.         0.         0.6042065\n",
            " 0.         0.         0.61016949 0.         0.         0.59183673\n",
            " 0.47204969 0.63043478 0.59259259 0.         0.         0.79407407\n",
            " 0.97419472]\n",
            "epoch 12/40 | train_f1(macro, micro) (0.27,0.92) | train_epoch_avg_loss 0.66| f1 for each class [0.         0.         0.03030303 0.         0.         0.42857143\n",
            " 0.29708223 0.28387097 0.34615385 0.         0.         0.60951565\n",
            " 0.         0.         0.45086705 0.         0.         0.54501217\n",
            " 0.51384615 0.62048193 0.55251142 0.         0.26530612 0.82026398\n",
            " 0.97060721]\n",
            "test_f1(macro, micro) (0.33,0.94) | test_avg_loss 0.62 | f1 for each class[0.         0.         0.         0.         0.         0.57142857\n",
            " 0.36781609 0.48648649 0.56666667 0.         0.68952381 0.\n",
            " 0.         0.73170732 0.         0.         0.64864865 0.5177665\n",
            " 0.52173913 0.71929825 0.         0.84429642 0.97993652]\n",
            "epoch 13/40 | train_f1(macro, micro) (0.29,0.93) | train_epoch_avg_loss 0.59| f1 for each class [0.         0.         0.04166667 0.         0.         0.5210728\n",
            " 0.34120735 0.34437086 0.36090226 0.         0.         0.6515411\n",
            " 0.         0.         0.48920863 0.         0.         0.66\n",
            " 0.55757576 0.71473354 0.53738318 0.         0.2745098  0.83007169\n",
            " 0.97509388]\n",
            "test_f1(macro, micro) (0.32,0.94) | test_avg_loss 0.58 | f1 for each class[0.         0.         0.15384615 0.         0.         0.52173913\n",
            " 0.32967033 0.5        0.64705882 0.         0.         0.7\n",
            " 0.         0.         0.66666667 0.         0.         0.63716814\n",
            " 0.3539823  0.64367816 0.76388889 0.         0.82818686 0.97780718]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAFcxDva2iGf"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(nrows= 2, ncols= 1, figsize= (10,8), sharex= True)\r\n",
        "ax1.plot([*range(1, num_epochs+1)], list(train_loss.values()), label= 'train loss')\r\n",
        "ax1.plot([*range(1, num_epochs+1)], list(test_loss.values()), label= 'test loss')\r\n",
        "ax1.legend()\r\n",
        "\r\n",
        "ax2.plot([*range(1, num_epochs+1)], list(train_f1.values()), label= 'train f1 (macro)')\r\n",
        "ax2.plot([*range(1, num_epochs+1)], list(test_f1.values()), label= 'test f1 (macro)')\r\n",
        "ax2.legend()\r\n",
        "\r\n",
        "plt.tight_layout()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.savefig('fig.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pWa4TQhw5PI"
      },
      "source": [
        "# torch.save(model, 'ner_model_batch32_wup4000_lstmhd256_lr5e-5_40epoch_adam_wde-3.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1UTlctlqT8g"
      },
      "source": [
        "# !cp 'ner_model_batch32_wup4000_lstmhd256_lr5e-5_40epoch_adam_wde-3.pt' '/content/drive/My Drive/python檔/aicup'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApTe5VvOqO-P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}